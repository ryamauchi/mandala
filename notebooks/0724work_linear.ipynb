{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from mandala.nodecore import Node\n",
    "from mandala.nodecore import Variable\n",
    "from mandala.autodiff import autodiff\n",
    "from mandala.autodiff.linear import Linear\n",
    "from mandala.autodiff.relu import relu\n",
    "from mandala.autodiff import initializers\n",
    "from mandala import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mandala.autodiff import basic_math_ho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_math_ho.install_node_arithmetics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp = cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_forward(x):\n",
    "    xp = cuda.get_array_module(x)\n",
    "    return xp.sum(x)\n",
    "\n",
    "\n",
    "def sum_backward(x, gy):\n",
    "    xp = cuda.get_array_module(x)\n",
    "    return xp.ones_like(x) * gy\n",
    "\n",
    "\n",
    "class SumFunction(autodiff.AutoDiff):\n",
    "    def forward(self, xs):\n",
    "        x = xs[0]\n",
    "        y = Node(sum_forward, [x])\n",
    "        return y\n",
    "\n",
    "    def backward(self, xs, gy):\n",
    "        x = xs[0]\n",
    "        gx = Node(sum_backward, [x, gy])\n",
    "        return gx,\n",
    "\n",
    "\n",
    "def _sum(x):\n",
    "    return SumFunction()([x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "l0 = Linear(   5, 1000)\n",
    "l1 = Linear(1000, 1000)\n",
    "l2 = Linear(1000, 1000)\n",
    "l3 = Linear(1000, 1000)\n",
    "l4 = Linear(1000, 1000)\n",
    "l5 = Linear(1000, 1000)\n",
    "l6 = Linear(1000,    3)\n",
    "\n",
    "layer_list = [l0, l1, l2, l3, l4, l5, l6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in layer_list:\n",
    "    l.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 真の係数\n",
    "W = xp.arange(15, dtype=np.float32).reshape(3, 5)\n",
    "b = xp.arange(3, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 32\n",
    "x = Variable(xp.random.random((batchsize, 5)).astype(np.float32))\n",
    "t = Variable(xp.matmul(x.data, W.T) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = relu(l0(x))\n",
    "h1 = relu(l1(h0))\n",
    "h2 = relu(l2(h1))\n",
    "h3 = relu(l3(h2))\n",
    "h4 = relu(l4(h3))\n",
    "h5 = relu(l5(h4))\n",
    "y  = relu(l6(h5))\n",
    "loss = (y - t) ** 2 / batchsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5._reference_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "None\n",
      "2\n",
      "[[ 0.64860862  0.28967083  1.13119984 ...,  0.          0.25194496  0.        ]\n",
      " [ 0.35686362  0.          0.71489704 ...,  0.11941893  0.29779166  0.        ]\n",
      " [ 0.          0.07290179  1.27660513 ...,  0.          0.          0.        ]\n",
      " ..., \n",
      " [ 0.20193653  0.          1.21434498 ...,  0.          0.01959161  0.        ]\n",
      " [ 0.          0.4635005   0.20899332 ...,  0.54076755  0.          0.        ]\n",
      " [ 0.22650175  0.24522282  1.46314657 ...,  0.          0.          0.        ]]\n",
      "2\n",
      "[[ 0.64860862  0.28967083  1.13119984 ...,  0.          0.25194496  0.        ]\n",
      " [ 0.35686362  0.          0.71489704 ...,  0.11941893  0.29779166  0.        ]\n",
      " [ 0.          0.07290179  1.27660513 ...,  0.          0.          0.        ]\n",
      " ..., \n",
      " [ 0.20193653  0.          1.21434498 ...,  0.          0.01959161  0.        ]\n",
      " [ 0.          0.4635005   0.20899332 ...,  0.54076755  0.          0.        ]\n",
      " [ 0.22650175  0.24522282  1.46314657 ...,  0.          0.          0.        ]]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(h0._reference_count)\n",
    "print(h0._data)\n",
    "l0.b.grad.data\n",
    "\n",
    "print(h0._reference_count)\n",
    "print(h0._data)\n",
    "l1.W.grad.data\n",
    "\n",
    "print(h0._reference_count)\n",
    "print(h0._data)\n",
    "l2.W.grad.data\n",
    "\n",
    "print(h0._reference_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1378.634033203125\n",
      "1577.5926513671875\n",
      "1508.54638671875\n",
      "1440.867919921875\n",
      "1214.9478759765625\n",
      "1073.578125\n",
      "1086.6549072265625\n",
      "1011.872314453125\n",
      "1114.7161865234375\n",
      "906.729736328125\n",
      "930.90869140625\n",
      "714.5150146484375\n",
      "627.3939208984375\n",
      "538.3048706054688\n",
      "601.6226806640625\n",
      "488.2144775390625\n",
      "413.9114074707031\n",
      "357.665771484375\n",
      "266.42926025390625\n",
      "247.65594482421875\n",
      "162.33644104003906\n",
      "140.4581298828125\n",
      "108.37310791015625\n",
      "71.75572204589844\n",
      "59.47739791870117\n",
      "38.98833465576172\n",
      "35.296478271484375\n",
      "17.604759216308594\n",
      "14.492101669311523\n",
      "10.682107925415039\n",
      "8.7097806930542\n",
      "7.2034502029418945\n",
      "6.685288906097412\n",
      "5.958806991577148\n",
      "4.1995158195495605\n",
      "4.69024658203125\n",
      "5.342360496520996\n",
      "4.324943542480469\n",
      "5.834258556365967\n",
      "4.883648872375488\n",
      "6.356687545776367\n",
      "4.239684104919434\n",
      "4.648891448974609\n",
      "3.93034029006958\n",
      "3.7006022930145264\n",
      "3.360018491744995\n",
      "4.683257102966309\n",
      "2.8244776725769043\n",
      "3.436717987060547\n",
      "3.113896369934082\n",
      "4.188852310180664\n",
      "4.472102165222168\n",
      "4.18264627456665\n",
      "2.925189971923828\n",
      "2.7946431636810303\n",
      "3.0143485069274902\n",
      "3.6882457733154297\n",
      "4.4403839111328125\n",
      "4.128091812133789\n",
      "3.942208766937256\n",
      "3.1777772903442383\n",
      "3.2192068099975586\n",
      "4.728485107421875\n",
      "3.1720876693725586\n",
      "3.6827588081359863\n",
      "2.8048300743103027\n",
      "2.8049349784851074\n",
      "2.953395128250122\n",
      "3.8693408966064453\n",
      "5.035249710083008\n",
      "2.8129143714904785\n",
      "2.3847856521606445\n",
      "2.904873847961426\n",
      "2.968200206756592\n",
      "3.706244707107544\n",
      "3.486262798309326\n",
      "2.4621193408966064\n",
      "3.0161242485046387\n",
      "2.683945655822754\n",
      "3.439152479171753\n",
      "3.0827088356018066\n",
      "3.172464370727539\n",
      "3.778116226196289\n",
      "2.3376777172088623\n",
      "2.5136568546295166\n",
      "2.698643207550049\n",
      "3.058022975921631\n",
      "2.1912620067596436\n",
      "2.485856771469116\n",
      "2.287200927734375\n",
      "1.8238346576690674\n",
      "1.9560620784759521\n",
      "2.7051548957824707\n",
      "3.121002435684204\n",
      "2.8414077758789062\n",
      "2.4983813762664795\n",
      "2.4336822032928467\n",
      "2.2881526947021484\n",
      "2.171384811401367\n",
      "2.7420132160186768\n",
      "time: 0.6452319622039795\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "lr = 1e-5\n",
    "\n",
    "for i in range(100):\n",
    "    # make batch\n",
    "    x = Variable(xp.random.random((batchsize, 5)).astype(np.float32))\n",
    "    t = Variable(xp.matmul(x.data, W.T) + b)\n",
    "    \n",
    "    # forward\n",
    "    h0 = relu(l0(x))\n",
    "    h1 = relu(l1(h0))\n",
    "    h2 = relu(l2(h1))\n",
    "    h3 = relu(l3(h2))\n",
    "    h4 = relu(l4(h3))\n",
    "    h5 = relu(l5(h4))\n",
    "    y  = l6(h5)\n",
    "    loss = (y - t) ** 2 / batchsize\n",
    "\n",
    "    # loss\n",
    "    loss = _sum((y - t) ** 2) / batchsize\n",
    "    \n",
    "    for l in layer_list:\n",
    "        l.W.grad = 0\n",
    "        if l.b is not None:\n",
    "            l.b.grad = 0.\n",
    "\n",
    "    # backward\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    for l in layer_list[::-1]:\n",
    "        l.W.data -= lr * l.W.grad.data\n",
    "        if l.b is not None:\n",
    "            l.b.data -= lr * l.b.grad.data\n",
    "\n",
    "    print(loss.data)\n",
    "\n",
    "print('time:', time.time() - s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chainer との速度比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer import optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(chainer.Chain):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        with self.init_scope():\n",
    "            self.l0 = L.Linear(   5, 1000)\n",
    "            self.l1 = L.Linear(1000, 1000)\n",
    "            self.l2 = L.Linear(1000, 1000)\n",
    "            self.l3 = L.Linear(1000, 1000)\n",
    "            self.l4 = L.Linear(1000, 1000)\n",
    "            self.l5 = L.Linear(1000, 1000)\n",
    "            self.l6 = L.Linear(1000,    3)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h  = F.relu(self.l0(x))\n",
    "        h  = F.relu(self.l1(h))\n",
    "        h  = F.relu(self.l2(h))\n",
    "        h  = F.relu(self.l3(h))\n",
    "        h  = F.relu(self.l4(h))\n",
    "        h  = F.relu(self.l5(h))\n",
    "        y  = self.l6(h)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Model at 0x7f0670c1a7b8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model()\n",
    "model.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<chainer.optimizers.sgd.SGD at 0x7f0670b40048>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = chainer.optimizers.SGD(lr=1e-4)\n",
    "opt.setup(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549.1631469726562\n",
      "471.0884704589844\n",
      "376.5736083984375\n",
      "517.8898315429688\n",
      "453.1171875\n",
      "467.7423095703125\n",
      "435.8872985839844\n",
      "462.77392578125\n",
      "458.2810363769531\n",
      "460.0186767578125\n",
      "501.9132385253906\n",
      "451.4162292480469\n",
      "471.0533752441406\n",
      "461.5989685058594\n",
      "445.4179992675781\n",
      "396.8384704589844\n",
      "503.6466979980469\n",
      "411.8832092285156\n",
      "391.8820495605469\n",
      "477.526123046875\n",
      "367.99462890625\n",
      "458.1058654785156\n",
      "490.9054870605469\n",
      "397.1836853027344\n",
      "485.1408996582031\n",
      "420.5108337402344\n",
      "427.3149719238281\n",
      "392.0328674316406\n",
      "409.8675842285156\n",
      "380.3116149902344\n",
      "421.8919982910156\n",
      "341.1537780761719\n",
      "260.7998962402344\n",
      "304.8304748535156\n",
      "288.5037536621094\n",
      "245.0092315673828\n",
      "213.2000732421875\n",
      "202.4524688720703\n",
      "151.91368103027344\n",
      "126.92919158935547\n",
      "68.91231536865234\n",
      "70.22505950927734\n",
      "32.596317291259766\n",
      "20.18245506286621\n",
      "12.99322509765625\n",
      "4.969906330108643\n",
      "3.6021602153778076\n",
      "0.9478638768196106\n",
      "1.2193830013275146\n",
      "1.3530960083007812\n",
      "1.4127308130264282\n",
      "2.0905981063842773\n",
      "1.2113178968429565\n",
      "1.327100157737732\n",
      "1.20295250415802\n",
      "0.8615207076072693\n",
      "1.235176682472229\n",
      "0.9443656802177429\n",
      "1.0598057508468628\n",
      "1.17713463306427\n",
      "0.9412800669670105\n",
      "0.9385240077972412\n",
      "0.8311726450920105\n",
      "1.545000672340393\n",
      "0.8808194994926453\n",
      "1.4696354866027832\n",
      "1.2238786220550537\n",
      "1.2715600728988647\n",
      "1.2680611610412598\n",
      "1.154462218284607\n",
      "0.8823739886283875\n",
      "1.175349473953247\n",
      "1.0062265396118164\n",
      "0.9121255278587341\n",
      "0.8217899203300476\n",
      "1.3817353248596191\n",
      "0.8409619927406311\n",
      "1.2031620740890503\n",
      "0.7426636815071106\n",
      "1.0249851942062378\n",
      "1.2706598043441772\n",
      "1.385501742362976\n",
      "0.9613051414489746\n",
      "1.0189050436019897\n",
      "1.2383371591567993\n",
      "1.2112680673599243\n",
      "0.6417593359947205\n",
      "0.9830037951469421\n",
      "1.1052602529525757\n",
      "1.0799623727798462\n",
      "0.5976153016090393\n",
      "1.2093734741210938\n",
      "0.7461769580841064\n",
      "1.234284520149231\n",
      "0.8751792907714844\n",
      "0.9394170641899109\n",
      "0.7917386889457703\n",
      "0.7955794334411621\n",
      "0.7283719182014465\n",
      "0.998126208782196\n",
      "0.7164573669433594\n"
     ]
    }
   ],
   "source": [
    "batchsize = 32\n",
    "s = time.time()\n",
    "\n",
    "for i in range(100):\n",
    "    # make batch\n",
    "    x = xp.random.random((batchsize, 5)).astype(np.float32)\n",
    "    t = xp.matmul(x, W.T) + b\n",
    "    \n",
    "    # forward\n",
    "    y = model(x)\n",
    "\n",
    "    # loss\n",
    "    loss = F.mean_squared_error(y, t)\n",
    "\n",
    "    # backward\n",
    "    model.cleargrads()\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    opt.update()\n",
    "\n",
    "    print(loss.data)\n",
    "\n",
    "print(time.time() - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9415384027439404"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.3876018524169922 / 0.19963645935058594"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7228536962537975"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.584319829940796 / 0.5818600654602051"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chainer の 2.7 倍の計算時間がかかっている……\n",
    "\n",
    "推論に限定しても 1.9 倍。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390 ns ± 0.122 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "cuda.get_array_module(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = xp.arange(15, dtype=np.float32).reshape(3, 5)\n",
    "b = xp.arange(3, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(xp.random.random((batchsize, 5)).astype(np.float32))\n",
    "t = Variable(xp.matmul(x.data, W.T) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.36 ms ± 1.05 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "x = Variable(xp.random.random((batchsize, 5)).astype(np.float32))\n",
    "t = Variable(xp.matmul(x.data, W.T) + b)\n",
    "h0 = l0(x)\n",
    "h1 = l1(h0)\n",
    "h2 = l2(h1)\n",
    "h3 = l3(h2)\n",
    "h4 = l4(h3)\n",
    "h5 = l5(h4)\n",
    "y  = l6(h5)\n",
    "y.data.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = xp.random.random((batchsize, 5)).astype(np.float32)\n",
    "t = xp.matmul(x, W.T) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.02 ms ± 20.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "x = xp.random.random((batchsize, 5)).astype(np.float32)\n",
    "t = xp.matmul(x, W.T) + b\n",
    "\n",
    "y = model(x)\n",
    "y.data.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chainer よりほんのちょっと早くなった（type check などやっていないせいかな。）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.cuda.cudnn.CUDNN_ACTIVATION_TANH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cupy.cuda.cudnn' from '/home/ubuntu/anaconda3/lib/python3.6/site-packages/cupy/cuda/cudnn.cpython-36m-x86_64-linux-gnu.so'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.cuda.cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
