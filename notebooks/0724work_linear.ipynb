{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from mandala.nodecore import Node\n",
    "from mandala.nodecore import Variable\n",
    "from mandala.autodiff import autodiff\n",
    "from mandala.autodiff import layer\n",
    "from mandala.autodiff import initializers\n",
    "from mandala import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(x, W, b, xp):\n",
    "    y = xp.matmul(x, W.T)\n",
    "    if b is not None:\n",
    "        y += b\n",
    "    return y\n",
    "\n",
    "\n",
    "def linear_backward_W(x, gy, xp):\n",
    "    gW = xp.matmul(gy.T, x)\n",
    "    return gW\n",
    "\n",
    "\n",
    "def linear_backward_x(W, gy, xp):\n",
    "    gx = np.matmul(gy, W, xp)\n",
    "    return gx\n",
    "\n",
    "\n",
    "class LinearFunction(autodiff.AutoDiff):\n",
    "\n",
    "    def forward(self, xs):\n",
    "        xp = cuda.get_array_module(xs)\n",
    "        x, W = xs\n",
    "        y = Node(linear_forward, [x, W, xp])\n",
    "        return y\n",
    "\n",
    "    def backward(self, xs, gy):\n",
    "        xp = cuda.get_array_module(xs)\n",
    "        x, W = xs\n",
    "        gW = Node(linear_backward_W, [x, gy, xp])\n",
    "        gx = Node(linear_backward_x, [W, gy, xp])\n",
    "        return gx, gW\n",
    "\n",
    "\n",
    "class Linear(layer.Layer):\n",
    "    def __init__(self, in_ch, out_ch, nobias=False,\n",
    "                 initializer=initializers.HeNormal):\n",
    "        self.W = Variable(initializer((out_ch, in_ch)))\n",
    "        if nobias:\n",
    "            self.b = None\n",
    "        else:\n",
    "            self.b = Variable(numpy.zeros(out_ch, dtype=np.float32))\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return LinearFunction()([x, self.W])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainer import links as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.Linear(3, 3).b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Linear(5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "\n",
    "def HeNormal(shape, scale=1.0):\n",
    "    fan_in = numpy.prod(shape[1:])\n",
    "    std = scale * numpy.sqrt(2 / fan_in)\n",
    "    init_W = numpy.random.normal(0, std, shape)\n",
    "    return init_W.astype(numpy.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.prod((1, 3, 10, 2)[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
