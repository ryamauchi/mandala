{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from mandala.nodecore import Node\n",
    "from mandala.nodecore import Variable\n",
    "from mandala.autodiff import autodiff\n",
    "from mandala.autodiff.linear import Linear\n",
    "from mandala.autodiff.relu import relu\n",
    "from mandala.autodiff import initializers\n",
    "from mandala import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mandala.autodiff.under_development import basic_math_ho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_math_ho.install_node_arithmetics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp = cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_forward(x):\n",
    "    xp = cuda.get_array_module(x)\n",
    "    return xp.sum(x)\n",
    "\n",
    "\n",
    "def sum_backward(x, gy):\n",
    "    xp = cuda.get_array_module(x)\n",
    "    return xp.ones_like(x) * gy\n",
    "\n",
    "\n",
    "class SumFunction(autodiff.AutoDiff):\n",
    "    def forward(self, xs):\n",
    "        x = xs[0]\n",
    "        y = Node(sum_forward, [x])\n",
    "        return y\n",
    "\n",
    "    def backward(self, xs, gy):\n",
    "        x = xs[0]\n",
    "        gx = Node(sum_backward, [x, gy])\n",
    "        return gx,\n",
    "\n",
    "\n",
    "def _sum(x):\n",
    "    return SumFunction()([x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "l0 = Linear(   5, 1000)\n",
    "l1 = Linear(1000, 1000)\n",
    "l2 = Linear(1000, 1000)\n",
    "l3 = Linear(1000, 1000)\n",
    "l4 = Linear(1000, 1000)\n",
    "l5 = Linear(1000, 1000)\n",
    "l6 = Linear(1000,    3)\n",
    "\n",
    "layer_list = [l0, l1, l2, l3, l4, l5, l6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in layer_list:\n",
    "    l.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 真の係数\n",
    "W = xp.arange(15, dtype=np.float32).reshape(3, 5)\n",
    "b = xp.arange(3, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 32\n",
    "x = Variable(xp.random.random((batchsize, 5)).astype(np.float32))\n",
    "t = Variable(xp.matmul(x.data, W.T) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = relu(l0(x))\n",
    "h1 = relu(l1(h0))\n",
    "h2 = relu(l2(h1))\n",
    "h3 = relu(l3(h2))\n",
    "h4 = relu(l4(h3))\n",
    "h5 = relu(l5(h4))\n",
    "y  = relu(l6(h5))\n",
    "loss = (y - t) ** 2 / batchsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5._reference_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "None\n",
      "2\n",
      "[[ 0.59670782  1.09020698  0.30631328 ...,  0.          0.          0.        ]\n",
      " [ 0.6659686   1.36422372  1.55435622 ...,  0.          0.          0.        ]\n",
      " [ 0.45300755  0.99499518  0.47963625 ...,  0.          0.          0.        ]\n",
      " ..., \n",
      " [ 0.26698124  1.20601308  0.58078444 ...,  0.          0.          0.        ]\n",
      " [ 0.05644015  1.67113698  0.9623642  ...,  0.          0.          0.        ]\n",
      " [ 0.69267452  0.52235496  0.69640452 ...,  0.          0.          0.        ]]\n",
      "2\n",
      "[[ 0.59670782  1.09020698  0.30631328 ...,  0.          0.          0.        ]\n",
      " [ 0.6659686   1.36422372  1.55435622 ...,  0.          0.          0.        ]\n",
      " [ 0.45300755  0.99499518  0.47963625 ...,  0.          0.          0.        ]\n",
      " ..., \n",
      " [ 0.26698124  1.20601308  0.58078444 ...,  0.          0.          0.        ]\n",
      " [ 0.05644015  1.67113698  0.9623642  ...,  0.          0.          0.        ]\n",
      " [ 0.69267452  0.52235496  0.69640452 ...,  0.          0.          0.        ]]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(h0._reference_count)\n",
    "print(h0._data)\n",
    "l0.b.grad.data\n",
    "\n",
    "print(h0._reference_count)\n",
    "print(h0._data)\n",
    "l1.W.grad.data\n",
    "\n",
    "print(h0._reference_count)\n",
    "print(h0._data)\n",
    "l2.W.grad.data\n",
    "\n",
    "print(h0._reference_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1396.805419921875\n",
      "1305.3095703125\n",
      "1256.254150390625\n",
      "1312.8984375\n",
      "1181.73095703125\n",
      "1146.4600830078125\n",
      "1029.11865234375\n",
      "975.6500244140625\n",
      "1043.843994140625\n",
      "1033.31982421875\n",
      "759.9957275390625\n",
      "674.3994140625\n",
      "674.7313232421875\n",
      "669.4490966796875\n",
      "621.3905029296875\n",
      "467.6435546875\n",
      "437.77301025390625\n",
      "334.9789733886719\n",
      "323.18743896484375\n",
      "268.540283203125\n",
      "219.34317016601562\n",
      "172.913818359375\n",
      "127.12586975097656\n",
      "77.21531677246094\n",
      "57.07967758178711\n",
      "54.84688186645508\n",
      "32.645809173583984\n",
      "38.06387710571289\n",
      "21.330846786499023\n",
      "13.694775581359863\n",
      "9.410962104797363\n",
      "11.974480628967285\n",
      "7.110748291015625\n",
      "7.429330825805664\n",
      "5.900032043457031\n",
      "4.2625885009765625\n",
      "5.156417369842529\n",
      "2.918550491333008\n",
      "3.675497531890869\n",
      "2.483914613723755\n",
      "3.2017428874969482\n",
      "2.0841445922851562\n",
      "1.7912100553512573\n",
      "3.3450913429260254\n",
      "2.7417564392089844\n",
      "3.0529346466064453\n",
      "3.971822738647461\n",
      "2.085923671722412\n",
      "2.0216760635375977\n",
      "2.335366725921631\n",
      "2.7088687419891357\n",
      "2.5782241821289062\n",
      "2.4556870460510254\n",
      "2.569121837615967\n",
      "1.1891124248504639\n",
      "2.4143364429473877\n",
      "2.7264604568481445\n",
      "2.072486639022827\n",
      "2.1538326740264893\n",
      "1.9047929048538208\n",
      "2.5396595001220703\n",
      "1.5856289863586426\n",
      "3.4564990997314453\n",
      "2.4621291160583496\n",
      "2.008122444152832\n",
      "1.391202449798584\n",
      "2.4544315338134766\n",
      "1.6414506435394287\n",
      "2.9203996658325195\n",
      "1.7186657190322876\n",
      "2.8738155364990234\n",
      "2.4204087257385254\n",
      "2.31453800201416\n",
      "1.8944121599197388\n",
      "1.744275689125061\n",
      "1.7328119277954102\n",
      "2.2092125415802\n",
      "1.8743681907653809\n",
      "2.33065128326416\n",
      "1.7132318019866943\n",
      "2.2665958404541016\n",
      "1.8456846475601196\n",
      "2.086726188659668\n",
      "2.1101837158203125\n",
      "2.0446038246154785\n",
      "2.6973206996917725\n",
      "1.9011343717575073\n",
      "1.525785207748413\n",
      "1.8977082967758179\n",
      "1.8355321884155273\n",
      "1.7172679901123047\n",
      "2.2011377811431885\n",
      "1.9056273698806763\n",
      "1.8238210678100586\n",
      "1.8498640060424805\n",
      "2.0703940391540527\n",
      "1.6012160778045654\n",
      "1.5590336322784424\n",
      "2.8697800636291504\n",
      "2.1006336212158203\n",
      "time: 0.5999472141265869\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "lr = 1e-5\n",
    "\n",
    "for i in range(100):\n",
    "    # make batch\n",
    "    x = Variable(xp.random.random((batchsize, 5)).astype(np.float32))\n",
    "    t = Variable(xp.matmul(x.data, W.T) + b)\n",
    "    \n",
    "    # forward\n",
    "    h0 = relu(l0(x))\n",
    "    h1 = relu(l1(h0))\n",
    "    h2 = relu(l2(h1))\n",
    "    h3 = relu(l3(h2))\n",
    "    h4 = relu(l4(h3))\n",
    "    h5 = relu(l5(h4))\n",
    "    y  = l6(h5)\n",
    "    loss = (y - t) ** 2 / batchsize\n",
    "\n",
    "    # loss\n",
    "    loss = _sum((y - t) ** 2) / batchsize\n",
    "    \n",
    "    for l in layer_list:\n",
    "        l.W.grad = 0\n",
    "        if l.b is not None:\n",
    "            l.b.grad = 0.\n",
    "\n",
    "    # backward\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    for l in layer_list[::-1]:\n",
    "        l.W.data -= lr * l.W.grad.data\n",
    "        if l.b is not None:\n",
    "            l.b.data -= lr * l.b.grad.data\n",
    "\n",
    "    print(loss.data)\n",
    "\n",
    "print('time:', time.time() - s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chainer との速度比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer import optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(chainer.Chain):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        with self.init_scope():\n",
    "            self.l0 = L.Linear(   5, 1000)\n",
    "            self.l1 = L.Linear(1000, 1000)\n",
    "            self.l2 = L.Linear(1000, 1000)\n",
    "            self.l3 = L.Linear(1000, 1000)\n",
    "            self.l4 = L.Linear(1000, 1000)\n",
    "            self.l5 = L.Linear(1000, 1000)\n",
    "            self.l6 = L.Linear(1000,    3)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h  = F.relu(self.l0(x))\n",
    "        h  = F.relu(self.l1(h))\n",
    "        h  = F.relu(self.l2(h))\n",
    "        h  = F.relu(self.l3(h))\n",
    "        h  = F.relu(self.l4(h))\n",
    "        h  = F.relu(self.l5(h))\n",
    "        y  = self.l6(h)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Model at 0x7f852ac013c8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model()\n",
    "model.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<chainer.optimizers.sgd.SGD at 0x7f852ac14cf8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = chainer.optimizers.SGD(lr=1e-4)\n",
    "opt.setup(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423.5740661621094\n",
      "531.382080078125\n",
      "443.461669921875\n",
      "420.7068176269531\n",
      "506.3071594238281\n",
      "423.91015625\n",
      "510.5898742675781\n",
      "517.8383178710938\n",
      "551.9871826171875\n",
      "456.3919982910156\n",
      "474.23291015625\n",
      "436.4140319824219\n",
      "444.9059753417969\n",
      "567.0789184570312\n",
      "448.3560485839844\n",
      "467.77392578125\n",
      "550.9495239257812\n",
      "545.7780151367188\n",
      "497.3526916503906\n",
      "474.7747497558594\n",
      "445.9039001464844\n",
      "414.466796875\n",
      "457.751953125\n",
      "442.871337890625\n",
      "384.0526428222656\n",
      "282.5722961425781\n",
      "286.8321838378906\n",
      "389.83642578125\n",
      "381.3673400878906\n",
      "302.9704895019531\n",
      "308.5923156738281\n",
      "299.9503479003906\n",
      "221.6492462158203\n",
      "242.1636962890625\n",
      "204.03977966308594\n",
      "176.8579559326172\n",
      "109.96512603759766\n",
      "80.73186492919922\n",
      "46.962066650390625\n",
      "21.91271209716797\n",
      "9.370952606201172\n",
      "5.117706298828125\n",
      "2.2746541500091553\n",
      "1.0506415367126465\n",
      "0.46438512206077576\n",
      "0.6512341499328613\n",
      "0.6124750971794128\n",
      "0.4400928318500519\n",
      "0.3481735289096832\n",
      "0.444492906332016\n",
      "0.3427414894104004\n",
      "0.44413816928863525\n",
      "0.4404982030391693\n",
      "0.5565033555030823\n",
      "0.4639120399951935\n",
      "0.46445751190185547\n",
      "0.3297322392463684\n",
      "0.3194965422153473\n",
      "0.4400043785572052\n",
      "0.49463334679603577\n",
      "0.4025115966796875\n",
      "0.4524780511856079\n",
      "0.28640204668045044\n",
      "0.4030722677707672\n",
      "0.32072874903678894\n",
      "0.31010058522224426\n",
      "0.3397778570652008\n",
      "0.38028183579444885\n",
      "0.49465131759643555\n",
      "0.31158843636512756\n",
      "0.4033712148666382\n",
      "0.43840956687927246\n",
      "0.35848525166511536\n",
      "0.4871120750904083\n",
      "0.3669314384460449\n",
      "0.2699280083179474\n",
      "0.4068000316619873\n",
      "0.22290165722370148\n",
      "0.4224683344364166\n",
      "0.5064413547515869\n",
      "0.4068075716495514\n",
      "0.26916322112083435\n",
      "0.42485976219177246\n",
      "0.4473693370819092\n",
      "0.4499877393245697\n",
      "0.3926990032196045\n",
      "0.288484662771225\n",
      "0.390648752450943\n",
      "0.3394462764263153\n",
      "0.4519409239292145\n",
      "0.3997102975845337\n",
      "0.43668198585510254\n",
      "0.3762764036655426\n",
      "0.35659193992614746\n",
      "0.3758877217769623\n",
      "0.44789281487464905\n",
      "0.2584588825702667\n",
      "0.3195945918560028\n",
      "0.2792951166629791\n",
      "0.4601726531982422\n",
      "0.7058248519897461\n"
     ]
    }
   ],
   "source": [
    "batchsize = 32\n",
    "s = time.time()\n",
    "\n",
    "for i in range(100):\n",
    "    # make batch\n",
    "    x = xp.random.random((batchsize, 5)).astype(np.float32)\n",
    "    t = xp.matmul(x, W.T) + b\n",
    "    \n",
    "    # forward\n",
    "    y = model(x)\n",
    "\n",
    "    # loss\n",
    "    loss = F.mean_squared_error(y, t)\n",
    "\n",
    "    # backward\n",
    "    model.cleargrads()\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    opt.update()\n",
    "\n",
    "    print(loss.data)\n",
    "\n",
    "print(time.time() - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9415384027439404"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.3876018524169922 / 0.19963645935058594"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7228536962537975"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.584319829940796 / 0.5818600654602051"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chainer の 2.7 倍の計算時間がかかっている……\n",
    "\n",
    "推論に限定しても 1.9 倍。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394 ns ± 0.249 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "cuda.get_array_module(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = xp.arange(15, dtype=np.float32).reshape(3, 5)\n",
    "b = xp.arange(3, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(xp.random.random((batchsize, 5)).astype(np.float32))\n",
    "t = Variable(xp.matmul(x.data, W.T) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.37 ms ± 2.01 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "x = Variable(xp.random.random((batchsize, 5)).astype(np.float32))\n",
    "t = Variable(xp.matmul(x.data, W.T) + b)\n",
    "h0 = l0(x)\n",
    "h1 = l1(h0)\n",
    "h2 = l2(h1)\n",
    "h3 = l3(h2)\n",
    "h4 = l4(h3)\n",
    "h5 = l5(h4)\n",
    "y  = l6(h5)\n",
    "y.data.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = xp.random.random((batchsize, 5)).astype(np.float32)\n",
    "t = xp.matmul(x, W.T) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.05 ms ± 16.2 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "x = xp.random.random((batchsize, 5)).astype(np.float32)\n",
    "t = xp.matmul(x, W.T) + b\n",
    "\n",
    "y = model(x)\n",
    "y.data.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chainer よりほんのちょっと早くなった（type check などやっていないせいかな。）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.cuda.cudnn.CUDNN_ACTIVATION_TANH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cupy.cuda.cudnn' from '/home/ubuntu/anaconda3/lib/python3.6/site-packages/cupy/cuda/cudnn.cpython-36m-x86_64-linux-gnu.so'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.cuda.cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
