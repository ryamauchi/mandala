{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from mandala.nodecore import Node\n",
    "from mandala.nodecore import Variable\n",
    "from mandala.autodiff import autodiff\n",
    "from mandala.autodiff.linear import Linear\n",
    "from mandala.autodiff.relu import relu\n",
    "from mandala.autodiff import initializers\n",
    "from mandala import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mandala.autodiff.under_development import basic_math_ho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_math_ho.install_node_arithmetics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp = cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_forward(x):\n",
    "    xp = cuda.get_array_module(x)\n",
    "    return xp.sum(x)\n",
    "\n",
    "\n",
    "def sum_backward(x, gy):\n",
    "    xp = cuda.get_array_module(x)\n",
    "    return xp.ones_like(x) * gy\n",
    "\n",
    "\n",
    "class SumFunction(autodiff.AutoDiff):\n",
    "    def forward(self, xs):\n",
    "        x = xs[0]\n",
    "        y = Node(sum_forward, [x])\n",
    "        return y\n",
    "\n",
    "    def backward(self, xs, gy):\n",
    "        x = xs[0]\n",
    "        gx = Node(sum_backward, [x, gy])\n",
    "        return gx,\n",
    "\n",
    "\n",
    "def _sum(x):\n",
    "    return SumFunction()([x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "l0 = Linear(   5, 1000)\n",
    "l1 = Linear(1000, 1000)\n",
    "l2 = Linear(1000, 1000)\n",
    "l3 = Linear(1000, 1000)\n",
    "l4 = Linear(1000, 1000)\n",
    "l5 = Linear(1000, 1000)\n",
    "l6 = Linear(1000,    3)\n",
    "\n",
    "layer_list = [l0, l1, l2, l3, l4, l5, l6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in layer_list:\n",
    "    l.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 真の係数\n",
    "W = xp.arange(15, dtype=np.float32).reshape(3, 5)\n",
    "b = xp.arange(3, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 32\n",
    "x = Variable(xp.random.random((batchsize, 5)).astype(np.float32))\n",
    "t = Variable(xp.matmul(x.data, W.T) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = relu(l0(x))\n",
    "h1 = relu(l1(h0))\n",
    "h2 = relu(l2(h1))\n",
    "h3 = relu(l3(h2))\n",
    "h4 = relu(l4(h3))\n",
    "h5 = relu(l5(h4))\n",
    "y  = relu(l6(h5))\n",
    "loss = (y - t) ** 2 / batchsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5._reference_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "None\n",
      "2\n",
      "[[ 0.          0.57037848  0.97586858 ...,  0.          0.          0.        ]\n",
      " [ 0.          0.39933702  1.69326723 ...,  0.          0.          0.57848614]\n",
      " [ 0.          0.07765651  0.74141574 ...,  0.          0.          0.00233528]\n",
      " ..., \n",
      " [ 0.          0.13806045  0.52868599 ...,  0.          0.          0.        ]\n",
      " [ 0.          0.52704078  1.40175164 ...,  0.          0.          0.28490806]\n",
      " [ 0.          0.88213855  1.08820438 ...,  0.          0.          0.        ]]\n",
      "2\n",
      "[[ 0.          0.57037848  0.97586858 ...,  0.          0.          0.        ]\n",
      " [ 0.          0.39933702  1.69326723 ...,  0.          0.          0.57848614]\n",
      " [ 0.          0.07765651  0.74141574 ...,  0.          0.          0.00233528]\n",
      " ..., \n",
      " [ 0.          0.13806045  0.52868599 ...,  0.          0.          0.        ]\n",
      " [ 0.          0.52704078  1.40175164 ...,  0.          0.          0.28490806]\n",
      " [ 0.          0.88213855  1.08820438 ...,  0.          0.          0.        ]]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(h0._reference_count)\n",
    "print(h0._data)\n",
    "l0.b.grad.data\n",
    "\n",
    "print(h0._reference_count)\n",
    "print(h0._data)\n",
    "l1.W.grad.data\n",
    "\n",
    "print(h0._reference_count)\n",
    "print(h0._data)\n",
    "l2.W.grad.data\n",
    "\n",
    "print(h0._reference_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "894.57568359375\n",
      "842.2807006835938\n",
      "776.6619262695312\n",
      "647.2041625976562\n",
      "663.3584594726562\n",
      "587.43310546875\n",
      "431.1292724609375\n",
      "445.94268798828125\n",
      "321.49884033203125\n",
      "258.0339050292969\n",
      "182.3206329345703\n",
      "182.62779235839844\n",
      "111.57316589355469\n",
      "105.64765167236328\n",
      "80.47604370117188\n",
      "58.344139099121094\n",
      "39.61833953857422\n",
      "31.013195037841797\n",
      "25.392305374145508\n",
      "15.32214069366455\n",
      "12.973474502563477\n",
      "12.737436294555664\n",
      "7.291163921356201\n",
      "6.148909568786621\n",
      "4.056299686431885\n",
      "3.795440435409546\n",
      "4.631786823272705\n",
      "3.210674285888672\n",
      "3.762791156768799\n",
      "4.308149337768555\n",
      "3.6449215412139893\n",
      "3.200988531112671\n",
      "2.987309455871582\n",
      "2.0498623847961426\n",
      "3.510840892791748\n",
      "2.583799362182617\n",
      "2.7985048294067383\n",
      "3.279245138168335\n",
      "2.3766136169433594\n",
      "3.6609625816345215\n",
      "2.426819324493408\n",
      "3.5281293392181396\n",
      "2.870962142944336\n",
      "2.987401008605957\n",
      "2.8914365768432617\n",
      "2.449875593185425\n",
      "3.9658966064453125\n",
      "2.757169485092163\n",
      "2.931574821472168\n",
      "3.5221142768859863\n",
      "2.5374226570129395\n",
      "2.3056631088256836\n",
      "3.3382019996643066\n",
      "3.0123562812805176\n",
      "1.987640142440796\n",
      "2.7503726482391357\n",
      "2.5592527389526367\n",
      "1.958939790725708\n",
      "1.5080435276031494\n",
      "3.2813637256622314\n",
      "2.110562562942505\n",
      "1.7427611351013184\n",
      "2.6625988483428955\n",
      "2.86613130569458\n",
      "2.0760889053344727\n",
      "2.2032113075256348\n",
      "2.333791732788086\n",
      "2.030102491378784\n",
      "2.6938090324401855\n",
      "2.1177096366882324\n",
      "1.569380521774292\n",
      "1.9570934772491455\n",
      "1.4867775440216064\n",
      "2.0018997192382812\n",
      "1.6410531997680664\n",
      "2.424110174179077\n",
      "1.6807472705841064\n",
      "1.8591127395629883\n",
      "1.621943473815918\n",
      "1.451070785522461\n",
      "2.1431519985198975\n",
      "1.883234977722168\n",
      "1.7767086029052734\n",
      "1.3953392505645752\n",
      "1.7286603450775146\n",
      "1.7027864456176758\n",
      "2.5236775875091553\n",
      "1.2824389934539795\n",
      "2.1073741912841797\n",
      "1.8146142959594727\n",
      "1.2570812702178955\n",
      "2.1059553623199463\n",
      "1.9131615161895752\n",
      "1.830669641494751\n",
      "1.3879659175872803\n",
      "1.5581496953964233\n",
      "1.7408074140548706\n",
      "2.716362953186035\n",
      "1.9863618612289429\n",
      "1.7333699464797974\n",
      "time: 0.6259562969207764\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "lr = 1e-5\n",
    "\n",
    "for i in range(100):\n",
    "    # make batch\n",
    "    x = Variable(xp.random.random((batchsize, 5)).astype(np.float32))\n",
    "    t = Variable(xp.matmul(x.data, W.T) + b)\n",
    "    \n",
    "    # forward\n",
    "    h0 = relu(l0(x))\n",
    "    h1 = relu(l1(h0))\n",
    "    h2 = relu(l2(h1))\n",
    "    h3 = relu(l3(h2))\n",
    "    h4 = relu(l4(h3))\n",
    "    h5 = relu(l5(h4))\n",
    "    y  = l6(h5)\n",
    "    loss = (y - t) ** 2 / batchsize\n",
    "\n",
    "    # loss\n",
    "    loss = _sum((y - t) ** 2) / batchsize\n",
    "    \n",
    "    for l in layer_list:\n",
    "        l.W.grad = 0\n",
    "        if l.b is not None:\n",
    "            l.b.grad = 0.\n",
    "\n",
    "    # backward\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    for l in layer_list[::-1]:\n",
    "        l.W.data -= lr * l.W.grad.data\n",
    "        if l.b is not None:\n",
    "            l.b.data -= lr * l.b.grad.data\n",
    "\n",
    "    print(loss.data)\n",
    "\n",
    "print('time:', time.time() - s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chainer との速度比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer import optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(chainer.Chain):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        with self.init_scope():\n",
    "            self.l0 = L.Linear(   5, 1000)\n",
    "            self.l1 = L.Linear(1000, 1000)\n",
    "            self.l2 = L.Linear(1000, 1000)\n",
    "            self.l3 = L.Linear(1000, 1000)\n",
    "            self.l4 = L.Linear(1000, 1000)\n",
    "            self.l5 = L.Linear(1000, 1000)\n",
    "            self.l6 = L.Linear(1000,    3)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h  = F.relu(self.l0(x))\n",
    "        h  = F.relu(self.l1(h))\n",
    "        h  = F.relu(self.l2(h))\n",
    "        h  = F.relu(self.l3(h))\n",
    "        h  = F.relu(self.l4(h))\n",
    "        h  = F.relu(self.l5(h))\n",
    "        y  = self.l6(h)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Model at 0x7fd8dc4fb668>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model()\n",
    "model.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<chainer.optimizers.sgd.SGD at 0x7fd8dc4ab9e8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = chainer.optimizers.SGD(lr=1e-4)\n",
    "opt.setup(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484.5459899902344\n",
      "440.8442077636719\n",
      "503.1265563964844\n",
      "550.2545776367188\n",
      "441.613037109375\n",
      "501.4929504394531\n",
      "413.2272644042969\n",
      "569.9443969726562\n",
      "502.867431640625\n",
      "501.7845764160156\n",
      "498.6287536621094\n",
      "449.3643798828125\n",
      "451.263427734375\n",
      "489.0592956542969\n",
      "510.0538635253906\n",
      "488.62548828125\n",
      "499.8179626464844\n",
      "368.2991027832031\n",
      "382.900634765625\n",
      "465.1600036621094\n",
      "454.8226013183594\n",
      "476.9388122558594\n",
      "479.9302062988281\n",
      "421.3287048339844\n",
      "409.83203125\n",
      "459.923828125\n",
      "486.7774963378906\n",
      "407.2345275878906\n",
      "395.7827453613281\n",
      "425.9024353027344\n",
      "422.9732666015625\n",
      "407.4546203613281\n",
      "347.1906433105469\n",
      "332.0914001464844\n",
      "310.6220703125\n",
      "314.3719787597656\n",
      "269.88616943359375\n",
      "218.4090576171875\n",
      "242.2445526123047\n",
      "167.9180908203125\n",
      "155.75143432617188\n",
      "125.58639526367188\n",
      "93.26728057861328\n",
      "48.98112869262695\n",
      "29.781511306762695\n",
      "21.675058364868164\n",
      "8.618934631347656\n",
      "4.790206432342529\n",
      "2.231900930404663\n",
      "1.9461106061935425\n",
      "1.2503701448440552\n",
      "1.1134284734725952\n",
      "1.2792353630065918\n",
      "1.2976678609848022\n",
      "0.8787908554077148\n",
      "1.2940067052841187\n",
      "0.7504477500915527\n",
      "0.49691399931907654\n",
      "0.8603453040122986\n",
      "0.7533342838287354\n",
      "0.9378524422645569\n",
      "1.2916961908340454\n",
      "0.7571421265602112\n",
      "1.6752389669418335\n",
      "0.9578273892402649\n",
      "0.6935623288154602\n",
      "1.251387596130371\n",
      "0.8385708928108215\n",
      "0.8284637331962585\n",
      "0.711418628692627\n",
      "0.7845357060432434\n",
      "0.6651176810264587\n",
      "0.576606273651123\n",
      "0.6179295182228088\n",
      "0.7296013832092285\n",
      "1.040717363357544\n",
      "0.6597121357917786\n",
      "0.9322161674499512\n",
      "0.6623918414115906\n",
      "0.9082770347595215\n",
      "0.7292354702949524\n",
      "0.754626452922821\n",
      "0.6979538798332214\n",
      "0.7732632756233215\n",
      "0.6387266516685486\n",
      "0.7001628875732422\n",
      "0.6072925925254822\n",
      "0.684575080871582\n",
      "0.5723047852516174\n",
      "0.6578535437583923\n",
      "0.7523937225341797\n",
      "0.9290081858634949\n",
      "0.651057779788971\n",
      "0.7669371962547302\n",
      "1.2631564140319824\n",
      "0.507174015045166\n",
      "0.8182669281959534\n",
      "0.4459582269191742\n",
      "0.8231456875801086\n",
      "0.8846847414970398\n",
      "0.702876091003418\n"
     ]
    }
   ],
   "source": [
    "batchsize = 32\n",
    "s = time.time()\n",
    "\n",
    "for i in range(100):\n",
    "    # make batch\n",
    "    x = xp.random.random((batchsize, 5)).astype(np.float32)\n",
    "    t = xp.matmul(x, W.T) + b\n",
    "    \n",
    "    # forward\n",
    "    y = model(x)\n",
    "\n",
    "    # loss\n",
    "    loss = F.mean_squared_error(y, t)\n",
    "\n",
    "    # backward\n",
    "    model.cleargrads()\n",
    "    loss.backward()\n",
    "    \n",
    "    # update\n",
    "    opt.update()\n",
    "\n",
    "    print(loss.data)\n",
    "\n",
    "print(time.time() - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9415384027439404"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.3876018524169922 / 0.19963645935058594"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7228536962537975"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.584319829940796 / 0.5818600654602051"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chainer の 2.7 倍の計算時間がかかっている……\n",
    "\n",
    "推論に限定しても 1.9 倍。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "389 ns ± 0.379 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "cuda.get_array_module(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = xp.arange(15, dtype=np.float32).reshape(3, 5)\n",
    "b = xp.arange(3, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(xp.random.random((batchsize, 5)).astype(np.float32))\n",
    "t = Variable(xp.matmul(x.data, W.T) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.35 ms ± 1.72 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "x = Variable(xp.random.random((batchsize, 5)).astype(np.float32))\n",
    "t = Variable(xp.matmul(x.data, W.T) + b)\n",
    "h0 = l0(x)\n",
    "h1 = l1(h0)\n",
    "h2 = l2(h1)\n",
    "h3 = l3(h2)\n",
    "h4 = l4(h3)\n",
    "h5 = l5(h4)\n",
    "y  = l6(h5)\n",
    "y.data.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = xp.random.random((batchsize, 5)).astype(np.float32)\n",
    "t = xp.matmul(x, W.T) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.02 ms ± 10.4 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "x = xp.random.random((batchsize, 5)).astype(np.float32)\n",
    "t = xp.matmul(x, W.T) + b\n",
    "\n",
    "y = model(x)\n",
    "y.data.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chainer よりほんのちょっと早くなった（type check などやっていないせいかな。）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.cuda.cudnn.CUDNN_ACTIVATION_TANH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cupy.cuda.cudnn' from '/home/ubuntu/anaconda3/lib/python3.6/site-packages/cupy/cuda/cudnn.cpython-36m-x86_64-linux-gnu.so'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.cuda.cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
