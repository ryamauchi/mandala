{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "try:\n",
    "    import cupy as cp\n",
    "    xp = cp\n",
    "except:\n",
    "    xp = np\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "import mandala\n",
    "from mandala import Node\n",
    "from mandala import Variable\n",
    "\n",
    "import mandala.autodiff as ad\n",
    "import mandala.autodiff.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = xp.arange(15, dtype=np.float32).reshape(3, 5)\n",
    "b = xp.arange(3, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mandala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(ad.Graph):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.l0 = F.Linear(   5, 1000)\n",
    "        self.l1 = F.Linear(1000, 1000)\n",
    "        self.l2 = F.Linear(1000, 1000)\n",
    "        self.l3 = F.Linear(1000, 1000)\n",
    "        self.l4 = F.Linear(1000, 1000)\n",
    "        self.l5 = F.Linear(1000, 1000)\n",
    "        self.l6 = F.Linear(1000,    3)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h = F.relu(self.l0(x))\n",
    "        h = F.relu(self.l1(h))\n",
    "        h = F.relu(self.l2(h))\n",
    "        h = F.relu(self.l3(h))\n",
    "        h = F.relu(self.l4(h))\n",
    "        h = F.relu(self.l5(h))\n",
    "        y = F.relu(self.l6(h))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "if not xp == np:\n",
    "    model.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l0': <mandala.autodiff.functions.linear.Linear at 0x7f4672bff898>,\n",
       " 'l1': <mandala.autodiff.functions.linear.Linear at 0x7f4672bff940>,\n",
       " 'l2': <mandala.autodiff.functions.linear.Linear at 0x7f4672bff9e8>,\n",
       " 'l3': <mandala.autodiff.functions.linear.Linear at 0x7f4672bffb00>,\n",
       " 'l4': <mandala.autodiff.functions.linear.Linear at 0x7f4672bffc18>,\n",
       " 'l5': <mandala.autodiff.functions.linear.Linear at 0x7f4672bffd30>,\n",
       " 'l6': <mandala.autodiff.functions.linear.Linear at 0x7f4672bffe48>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0.7418503761291504\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "lr = 1e-4\n",
    "\n",
    "for i in range(100):\n",
    "    # make batch\n",
    "    x = Variable(xp.random.random((batch_size, 5)).astype(np.float32))\n",
    "    t = Variable(xp.matmul(x.data, W.T) + b)\n",
    "    \n",
    "    # forward\n",
    "    y = model(x)\n",
    "    loss = (y - t) ** 2 / batch_size\n",
    "\n",
    "    # loss\n",
    "    loss = F.sum((y - t) ** 2) / batch_size\n",
    "    # backward\n",
    "    model.cleargrads()\n",
    "    #loss.backward()\n",
    "\n",
    "    loss.data\n",
    "\n",
    "    #for p in model.params.values():\n",
    "    #    p.data -= lr * p.grad.data\n",
    "\n",
    "print('time:', time.time() - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y._data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y._reference_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Aug  5 15:18:58 2018       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 396.26                 Driver Version: 396.26                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   47C    P0   103W / 149W |    166MiB / 11441MiB |     96%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      3229      C   /home/ubuntu/anaconda3/bin/python            155MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer import optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(chainer.Chain):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        with self.init_scope():\n",
    "            self.l0 = L.Linear(   5, 1000)\n",
    "            self.l1 = L.Linear(1000, 1000)\n",
    "            self.l2 = L.Linear(1000, 1000)\n",
    "            self.l3 = L.Linear(1000, 1000)\n",
    "            self.l4 = L.Linear(1000, 1000)\n",
    "            self.l5 = L.Linear(1000, 1000)\n",
    "            self.l6 = L.Linear(1000,    3)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h  = F.relu(self.l0(x))\n",
    "        h  = F.relu(self.l1(h))\n",
    "        h  = F.relu(self.l2(h))\n",
    "        h  = F.relu(self.l3(h))\n",
    "        h  = F.relu(self.l4(h))\n",
    "        h  = F.relu(self.l5(h))\n",
    "        y  = self.l6(h)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "if not xp == np:\n",
    "    model.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<chainer.optimizers.sgd.SGD at 0x7f3da67d8e80>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = chainer.optimizers.SGD(lr=1e-4)\n",
    "opt.setup(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8809006214141846\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "\n",
    "for i in range(100):\n",
    "    # make batch\n",
    "    x = xp.random.random((batch_size, 5)).astype(np.float32)\n",
    "    t = xp.matmul(x, W.T) + b\n",
    "    \n",
    "    # forward\n",
    "    y = model(x)\n",
    "\n",
    "    # loss\n",
    "    loss = F.mean_squared_error(y, t)\n",
    "\n",
    "    # backward\n",
    "    model.cleargrads()\n",
    "    loss.backward(retain_grad=False)\n",
    "    \n",
    "    # update\n",
    "    opt.update()\n",
    "\n",
    "    # print(loss.data)\n",
    "\n",
    "print(time.time() - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Aug  5 15:17:58 2018       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 396.26                 Driver Version: 396.26                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   48C    P0   123W / 149W |    146MiB / 11441MiB |     54%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      3181      C   /home/ubuntu/anaconda3/bin/python            135MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.99s „Åß 139MiB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
