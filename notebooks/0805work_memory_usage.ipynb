{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "try:\n",
    "    import cupy as cp\n",
    "    xp = cp\n",
    "except:\n",
    "    xp = np\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "import mandala\n",
    "from mandala import Node\n",
    "from mandala import Variable\n",
    "\n",
    "import mandala.autodiff as ad\n",
    "import mandala.autodiff.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(ad.Graph):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.l0 = F.Linear(   5, 1000)\n",
    "        self.l1 = F.Linear(1000, 1000)\n",
    "        self.l2 = F.Linear(1000, 1000)\n",
    "        self.l3 = F.Linear(1000, 1000)\n",
    "        self.l4 = F.Linear(1000, 1000)\n",
    "        self.l5 = F.Linear(1000, 1000)\n",
    "        self.l6 = F.Linear(1000,    3)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h = F.relu(self.l0(x))\n",
    "        h = F.relu(self.l1(h))\n",
    "        h = F.relu(self.l2(h))\n",
    "        h = F.relu(self.l3(h))\n",
    "        h = F.relu(self.l4(h))\n",
    "        h = F.relu(self.l5(h))\n",
    "        y = F.relu(self.l6(h))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "if not xp == np:\n",
    "    model.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = xp.arange(15, dtype=np.float32).reshape(3, 5)\n",
    "b = xp.arange(3, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l0': <mandala.autodiff.functions.linear.Linear at 0x1948536cd30>,\n",
       " 'l1': <mandala.autodiff.functions.linear.Linear at 0x1948536ce80>,\n",
       " 'l2': <mandala.autodiff.functions.linear.Linear at 0x1948536c908>,\n",
       " 'l3': <mandala.autodiff.functions.linear.Linear at 0x19485362048>,\n",
       " 'l4': <mandala.autodiff.functions.linear.Linear at 0x19485362160>,\n",
       " 'l5': <mandala.autodiff.functions.linear.Linear at 0x19485362278>,\n",
       " 'l6': <mandala.autodiff.functions.linear.Linear at 0x19485362390>}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mandala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.399904251098633\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "lr = 1e-4\n",
    "\n",
    "for i in range(100):\n",
    "    # make batch\n",
    "    x = Variable(xp.random.random((batch_size, 5)).astype(np.float32))\n",
    "    t = Variable(xp.matmul(x.data, W.T) + b)\n",
    "    \n",
    "    # forward\n",
    "    y  = model(x)\n",
    "    loss = (y - t) ** 2 / batch_size\n",
    "\n",
    "    # loss\n",
    "    loss = F.sum((y - t) ** 2) / batch_size\n",
    "\n",
    "    # backward\n",
    "    model.cleargrads()\n",
    "    loss.backward()\n",
    "    \n",
    "    del loss\n",
    "    del y\n",
    "\n",
    "    # update\n",
    "#    for p in model.params.values():\n",
    "#        p.grad.reserve()\n",
    "\n",
    "    for p in model.params.values():\n",
    "        p.data -= lr * p.grad.data\n",
    "\n",
    "    #print(loss.data)\n",
    "\n",
    "print('time:', time.time() - s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer import optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(chainer.Chain):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        with self.init_scope():\n",
    "            self.l0 = L.Linear(   5, 1000)\n",
    "            self.l1 = L.Linear(1000, 1000)\n",
    "            self.l2 = L.Linear(1000, 1000)\n",
    "            self.l3 = L.Linear(1000, 1000)\n",
    "            self.l4 = L.Linear(1000, 1000)\n",
    "            self.l5 = L.Linear(1000, 1000)\n",
    "            self.l6 = L.Linear(1000,    3)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h  = F.relu(self.l0(x))\n",
    "        h  = F.relu(self.l1(h))\n",
    "        h  = F.relu(self.l2(h))\n",
    "        h  = F.relu(self.l3(h))\n",
    "        h  = F.relu(self.l4(h))\n",
    "        h  = F.relu(self.l5(h))\n",
    "        y  = self.l6(h)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "if not xp == np:\n",
    "    model.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = chainer.optimizers.SGD(lr=1e-4)\n",
    "opt.setup(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.075519323348999\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "\n",
    "for i in range(100):\n",
    "    # make batch\n",
    "    x = xp.random.random((batch_size, 5)).astype(np.float32)\n",
    "    t = xp.matmul(x, W.T) + b\n",
    "    \n",
    "    # forward\n",
    "    y = model(x)\n",
    "\n",
    "    # loss\n",
    "    loss = F.mean_squared_error(y, t)\n",
    "\n",
    "    # backward\n",
    "    model.cleargrads()\n",
    "    loss.backward(retain_grad=True)\n",
    "    \n",
    "    # update\n",
    "    opt.update()\n",
    "\n",
    "    # print(loss.data)\n",
    "\n",
    "print(time.time() - s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
