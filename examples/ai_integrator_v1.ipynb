{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "32453e31c88e45cc98b6aa014bc743ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c444e285ad5d47a5bb09cda1ca54c4d1",
              "IPY_MODEL_044e9ca3c5844480a4aca78a64c7e3b9",
              "IPY_MODEL_f14d26b3581046ba9e71a5cb6bb02069"
            ],
            "layout": "IPY_MODEL_84a9a07a8ccc4309a8a7b575a175fae1"
          }
        },
        "c444e285ad5d47a5bb09cda1ca54c4d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38075f3c88d048dc9cbebee0d567d201",
            "placeholder": "​",
            "style": "IPY_MODEL_39eb5670a46b4423aa194128614aab9c",
            "value": "Map: 100%"
          }
        },
        "044e9ca3c5844480a4aca78a64c7e3b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99b9cc2e31e14323a0f3f5d55e9b3813",
            "max": 7473,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e1e1d0cbda4846f594713916d53a9674",
            "value": 7473
          }
        },
        "f14d26b3581046ba9e71a5cb6bb02069": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f8150c4b9464f1cb2b17db1a601baad",
            "placeholder": "​",
            "style": "IPY_MODEL_c8c6e4df872447c3b6d10a75da3f7922",
            "value": " 7473/7473 [00:00&lt;00:00, 104778.38 examples/s]"
          }
        },
        "84a9a07a8ccc4309a8a7b575a175fae1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38075f3c88d048dc9cbebee0d567d201": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39eb5670a46b4423aa194128614aab9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99b9cc2e31e14323a0f3f5d55e9b3813": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1e1d0cbda4846f594713916d53a9674": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7f8150c4b9464f1cb2b17db1a601baad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8c6e4df872447c3b6d10a75da3f7922": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryamauchi/mandala/blob/master/examples/ai_integrator_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AI Integrator Adjustment Notebook"
      ],
      "metadata": {
        "id": "I6L_JbjVa3Yh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JPmr889XamoQ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# %pip install unsloth \"xformers==0.0.28.post2\"\n",
        "# %pip uninstall unsloth -y && pip install --upgrade --no-cache-dir \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "%pip install researchgraph -U\n",
        "%pip install transformers==4.46.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip show researchgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ht3F6fRfz4ef",
        "outputId": "140efde4-1c21-420e-d88a-4c08db57b0e2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: researchgraph\n",
            "Version: 0.0.69\n",
            "Summary: Add your description here\n",
            "Home-page: https://www.autores.one/english\n",
            "Author: \n",
            "Author-email: Toma Tanaka <ulti4929@gmail.com>\n",
            "License: \n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: aider-chat, arxiv, jinja2, langchain, langchain-community, langgraph, litellm, llmlinks, openai, pandas, pyalex, pydantic, pypdf, semanticscholar, setuptools, tomli, tomli-w\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OzUCIbielkel"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ew5MxeX6lkT7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "S2oqmxHslsEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RX7IKOLpbIh4",
        "outputId": "d9221be4-703a-4ffd-c00a-15840183a60d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import logging\n",
        "from IPython.display import Image\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph\n",
        "\n",
        "from researchgraph.core.factory import NodeFactory\n",
        "from researchgraph.graphs.ai_integrator.ai_integrator_v1 import ai_integratorv1_setting\n",
        "\n",
        "node_names = [\n",
        "    \"structuredoutput_llmnode\",\n",
        "    \"retrieve_arxiv_text_node\",\n",
        "    \"retrieve_github_repository_node\",\n",
        "    \"text2script_node\",\n",
        "    \"llmsfttrain_node\",\n",
        "    \"llminference_node\",\n",
        "    \"llmevaluate_node\",\n",
        "]"
      ],
      "metadata": {
        "id": "gbR7iCT5IoIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation"
      ],
      "metadata": {
        "id": "yCYraeNqb7be"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### StructuredLLMNode Prompt"
      ],
      "metadata": {
        "id": "ckzb_qQVPHih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "extractor_prompt_template = \"\"\"\n",
        "You are a researcher working on machine learning.\n",
        "The following <paper_text> tags enclose the full text data of the paper.\n",
        "Please extract the explanation of the method introduced in the given paper.\n",
        "<paper_text>\n",
        "{{paper_text}}\n",
        "</paper_text>\n",
        "\"\"\"\n",
        "\n",
        "codeextractor_prompt_template = \"\"\"\n",
        "<RULE>\n",
        "You are a researcher working on machine learning.\n",
        "- Tag Descriptions\n",
        "    - The text enclosed within the <add_method_text> tag contains an explanation of a method extracted from a machine learning paper.\n",
        "    - The text enclosed within the <folder_structure> tag shows the folder structure of the corresponding GitHub repository for the paper.\n",
        "    - The text enclosed within the <github_file> tag contains the code from Python files in the corresponding GitHub repository.\n",
        "- Instructions for Extracting Python Code\n",
        "    - Extract the relevant sections of Python code from the content enclosed within the <github_file> tag based on the method described in the <add_method_text> tag.\n",
        "    - Use the folder structure provided within the <folder_structure> tag as a reference when extracting the code.\n",
        "    - Please extract any code that seems to be related.\n",
        "    - If no corresponding code exists, output \"No corresponding code exists.\"\n",
        "</RULE>\n",
        "<add_method_text>\n",
        "{{add_method_text}}\n",
        "</add_method_text>\n",
        "<folder_structure>\n",
        "{{folder_structure}}\n",
        "</folder_structure>\n",
        "<github_file>\n",
        "{{github_file}}\n",
        "</github_file>\n",
        "<EOS></EOS>\"\"\"\n",
        "\n",
        "\n",
        "creator_prompt_template = \"\"\"\n",
        "You are a researcher working on machine learning.\n",
        "Please check the descriptions of the tags listed in Tag Descriptions and follow the instructions.\n",
        "- Tag Descriptions\n",
        "    - The text enclosed within the <objective> tag indicates the objective of the research being undertaken.\n",
        "    - The text enclosed within the <add_method_text> tag contains an explanation of a method extracted from a machine learning paper.\n",
        "    - The text enclosed within the <add_method_code> tag contains the code extracted from the paper.\n",
        "    - The text enclosed within the <base_method_text> tag provides a description of the base method.\n",
        "    - The text enclosed within the <base_method_code> tag contains the code of the base method.\n",
        "- Please follow the rules below to output the code and description of the new method.\n",
        "    - Please apply the code enclosed in the <add_method_code> tag to the code enclosed in the <base_method_code> tag to generate a new method.\n",
        "    - Please generate a method that is considered to be novel.\n",
        "    - Please make sure that the new method protects the content enclosed in the <objective> tag.\n",
        "    - When creating a new method, please also consider the description of the method enclosed in the <add_method_text> tag and the description enclosed in the <base_method_text> tag.\n",
        "    - Please output the new method you have created as new_method_text.\n",
        "    - Please output the new code you have created as new_method_code.\n",
        "    - The output of new_method_code must follow the template enclosed in the <method_template> tag.\n",
        "</RULE>\n",
        "<objective>\n",
        "{{objective}}\n",
        "</objective>\n",
        "<add_method_text>\n",
        "{{add_method_text}}\n",
        "</add_method_text>\n",
        "<add_method_code>\n",
        "{{add_method_code}}\n",
        "</add_method_code>\n",
        "<base_method_text>\n",
        "{{base_method_text}}\n",
        "</base_method_text>\n",
        "<base_method_code>\n",
        "{{base_method_code}}\n",
        "</base_method_code>\n",
        "<method_template>\n",
        "{{method_template}}\n",
        "</method_template>\n",
        "<EOS></EOS>\"\"\""
      ],
      "metadata": {
        "id": "L4oBSCm7nAVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResearchGraph"
      ],
      "metadata": {
        "id": "CaOIrpfElyjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class State(TypedDict):\n",
        "    objective: str\n",
        "    method_template: str\n",
        "    base_method_text: str\n",
        "    base_method_code: str\n",
        "    llm_script: str\n",
        "    index: int\n",
        "    arxiv_url: str\n",
        "    github_url: str\n",
        "    folder_structure: str\n",
        "    github_file: str\n",
        "    add_method_code: str\n",
        "    paper_text: str\n",
        "    add_method_text: str\n",
        "    new_method_code: list\n",
        "    new_method_text: list\n",
        "    script_save_path: str\n",
        "    model_save_path: str\n",
        "    result_save_path: str\n",
        "    accuracy: str\n",
        "\n",
        "\n",
        "class AIIntegratorv1:\n",
        "    def __init__(\n",
        "        self,\n",
        "        llm_name: str,\n",
        "        save_dir: str,\n",
        "        new_method_file_name: str,\n",
        "        ft_model_name: str,\n",
        "        dataset_name: str,\n",
        "        model_save_dir_name: str,\n",
        "        result_save_file_name: str,\n",
        "        answer_data_path: str,\n",
        "        num_train_data: int | None = None,\n",
        "        num_inference_data: int | None = None,\n",
        "    ):\n",
        "        self.llm_name = llm_name\n",
        "        self.save_dir = save_dir\n",
        "        self.new_method_file_name = new_method_file_name\n",
        "        self.ft_model_name = ft_model_name\n",
        "        self.dataset_name = dataset_name\n",
        "        self.model_save_dir_name = model_save_dir_name\n",
        "        self.result_save_file_name = result_save_file_name\n",
        "        self.answer_data_path = answer_data_path\n",
        "        self.num_train_data = num_train_data\n",
        "        self.num_inference_data = num_inference_data\n",
        "\n",
        "        if not os.path.exists(self.save_dir):\n",
        "            os.makedirs(self.save_dir)\n",
        "        self.graph_builder = StateGraph(State)\n",
        "\n",
        "        self.graph_builder.add_node(\n",
        "            \"githubretriever\",\n",
        "            NodeFactory.create_node(\n",
        "                node_name=\"retrieve_github_repository_node\",\n",
        "                save_dir=\"/content/drive/MyDrive/AutoRes/ai_integrator/exec-test\",\n",
        "                input_key=[\"github_url\"],\n",
        "                output_key=[\"folder_structure\", \"github_file\"],\n",
        "            )\n",
        "        )\n",
        "        self.graph_builder.add_node(\n",
        "            \"arxivretriever\",\n",
        "            NodeFactory.create_node(\n",
        "                node_name = \"retrieve_arxiv_text_node\",\n",
        "                save_dir=self.save_dir,\n",
        "                input_key=[\"arxiv_url\"],\n",
        "                output_key=[\"paper_text\"],\n",
        "            )\n",
        "        )\n",
        "        self.graph_builder.add_node(\n",
        "            \"extractor\",\n",
        "            NodeFactory.create_node(\n",
        "                node_name = \"structuredoutput_llmnode\",\n",
        "                input_key=[\"paper_text\"],\n",
        "                output_key=[\"add_method_text\"],\n",
        "                llm_name=llm_name,\n",
        "                prompt_template=extractor_prompt_template,\n",
        "            )\n",
        "        )\n",
        "        self.graph_builder.add_node(\n",
        "            \"codeextractor\",\n",
        "            NodeFactory.create_node(\n",
        "                node_name = \"structuredoutput_llmnode\",\n",
        "                input_key=[\"add_method_text\", \"folder_structure\", \"github_file\"],\n",
        "                output_key=[\"add_method_code\"],\n",
        "                llm_name=llm_name,\n",
        "                prompt_template=codeextractor_prompt_template,\n",
        "            )\n",
        "        )\n",
        "        self.graph_builder.add_node(\n",
        "            \"creator\",\n",
        "            NodeFactory.create_node(\n",
        "                node_name = \"structuredoutput_llmnode\",\n",
        "                input_key=[\n",
        "                    \"objective\",\n",
        "                    \"add_method_text\",\n",
        "                    \"add_method_code\",\n",
        "                    \"base_method_text\",\n",
        "                    \"base_method_code\",\n",
        "                    \"method_template\",\n",
        "                ],\n",
        "                output_key=[\"new_method_text\", \"new_method_code\"],\n",
        "                llm_name=llm_name,\n",
        "                prompt_template=creator_prompt_template,\n",
        "            )\n",
        "        )\n",
        "        self.graph_builder.add_node(\n",
        "            \"text2script\",\n",
        "            NodeFactory.create_node(\n",
        "                node_name = \"text2script_node\",\n",
        "                input_key=[\"new_method_code\"],\n",
        "                output_key=[\"script_save_path\"],\n",
        "                save_file_path=os.path.join(self.save_dir, self.new_method_file_name),\n",
        "            )\n",
        "        )\n",
        "        self.graph_builder.add_node(\n",
        "            \"llmsfttrainer\",\n",
        "            NodeFactory.create_node(\n",
        "                node_name = \"llmsfttrain_node\",\n",
        "                model_name=self.ft_model_name,\n",
        "                dataset_name=self.dataset_name,\n",
        "                num_train_data=self.num_train_data,\n",
        "                model_save_path=os.path.join(self.save_dir, self.model_save_dir_name),\n",
        "                lora=True,\n",
        "                input_key=[\"script_save_path\"],\n",
        "                output_key=[\"model_save_path\"],\n",
        "            )\n",
        "        )\n",
        "        self.graph_builder.add_node(\n",
        "            \"llminferencer\",\n",
        "            NodeFactory.create_node(\n",
        "                node_name = \"llminference_node\",\n",
        "                input_key=[\"model_save_path\"],\n",
        "                output_key=[\"result_save_path\"],\n",
        "                dataset_name=self.dataset_name,\n",
        "                num_inference_data=self.num_inference_data,\n",
        "                result_save_path=os.path.join(\n",
        "                    self.save_dir, self.result_save_file_name\n",
        "                ),\n",
        "            )\n",
        "        )\n",
        "        self.graph_builder.add_node(\n",
        "            \"llmevaluater\",\n",
        "            NodeFactory.create_node(\n",
        "                node_name = \"llmevaluate_node\",\n",
        "                input_key=[\"result_save_path\"],\n",
        "                output_key=[\"accuracy\"],\n",
        "                answer_data_path=self.answer_data_path,\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # make edges\n",
        "        self.graph_builder.add_edge(\"arxivretriever\", \"githubretriever\")\n",
        "        self.graph_builder.add_edge(\"arxivretriever\", \"extractor\")\n",
        "        self.graph_builder.add_edge([\"githubretriever\", \"extractor\"], \"codeextractor\")\n",
        "        self.graph_builder.add_edge(\"codeextractor\", \"creator\")\n",
        "        self.graph_builder.add_edge(\"creator\", \"text2script\")\n",
        "        self.graph_builder.add_edge(\"text2script\", \"llmsfttrainer\")\n",
        "        self.graph_builder.add_edge(\"llmsfttrainer\", \"llminferencer\")\n",
        "        self.graph_builder.add_edge(\"llminferencer\", \"llmevaluater\")\n",
        "\n",
        "        # set entry and finish points\n",
        "        self.graph_builder.set_entry_point(\"arxivretriever\")\n",
        "        # self.graph_builder.set_finish_point(\"creator\")\n",
        "        self.graph_builder.set_finish_point(\"llmevaluater\")\n",
        "\n",
        "        self.graph = self.graph_builder.compile()\n",
        "\n",
        "    # def __call__(self, state: State, debug: bool = True) -> dict:\n",
        "    def __call__(self, state: State) -> dict:\n",
        "        result = self.graph.invoke(state, debug = True)\n",
        "        return result\n",
        "\n",
        "    def write_result(self, response: State):\n",
        "        index = response[\"index\"]\n",
        "        arxiv_url = response[\"arxiv_url\"]\n",
        "        add_method_text = response[\"add_method_text\"][0]\n",
        "        add_method_code = response[\"add_method_code\"][0]\n",
        "        new_method_text = response[\"new_method_text\"][0]\n",
        "        new_method_code = response[\"new_method_code\"][0]\n",
        "        content = (\n",
        "            f\"---Arxiv URL 1---:\\n{arxiv_url}\\n\\n\"\n",
        "            f\"---Add Method Text---:\\n{add_method_text}\\n\\n\"\n",
        "            f\"---Add Method Code---:\\n{add_method_code}\\n\\n\"\n",
        "            f\"---New Method Text---:\\n{new_method_text}\\n\\n\"\n",
        "            f\"---New Method Code---:\\n{new_method_code}\\n\\n\"\n",
        "        )\n",
        "        with open(self.save_dir + f\"ai_integrator_{index}.txt\", \"w\") as f:\n",
        "            f.write(content)\n",
        "        return\n",
        "\n",
        "    def make_image(self, path: str):\n",
        "        image = Image(self.graph.get_graph().draw_mermaid_png())\n",
        "        with open(path + \"ai_integrator_graph.png\", \"wb\") as f:\n",
        "            f.write(image.data)"
      ],
      "metadata": {
        "id": "aMxWS2jmb8cD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting"
      ],
      "metadata": {
        "id": "6FWVdm7AbLXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_name = \"gpt-4o-2024-08-06\"\n",
        "save_dir = \"/content/drive/MyDrive/AutoRes/ai_integrator/exec-test\"\n",
        "ft_model_name = \"unsloth/Meta-Llama-3.1-8B\"\n",
        "dataset_name = \"openai/gsm8k\"\n",
        "new_method_file_name = \"new_method.py\"\n",
        "model_save_dir_name = \"train_model\"\n",
        "result_save_file_name = \"pred_file\"\n",
        "answer_data_path = '/content/drive/MyDrive/AutoRes/ai_integrator/gsm8k_answer.csv'\n",
        "num_train_data = 30\n",
        "num_inference_data = 30\n",
        "\n",
        "research_graph = AIIntegratorv1(\n",
        "    llm_name = llm_name,\n",
        "    save_dir = save_dir,\n",
        "    new_method_file_name = new_method_file_name,\n",
        "    ft_model_name = ft_model_name,\n",
        "    dataset_name= dataset_name,\n",
        "    model_save_dir_name = model_save_dir_name,\n",
        "    result_save_file_name = result_save_file_name,\n",
        "    answer_data_path = answer_data_path,\n",
        "    num_train_data = num_train_data,\n",
        "    num_inference_data = num_inference_data,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "32453e31c88e45cc98b6aa014bc743ad",
            "c444e285ad5d47a5bb09cda1ca54c4d1",
            "044e9ca3c5844480a4aca78a64c7e3b9",
            "f14d26b3581046ba9e71a5cb6bb02069",
            "84a9a07a8ccc4309a8a7b575a175fae1",
            "38075f3c88d048dc9cbebee0d567d201",
            "39eb5670a46b4423aa194128614aab9c",
            "99b9cc2e31e14323a0f3f5d55e9b3813",
            "e1e1d0cbda4846f594713916d53a9674",
            "7f8150c4b9464f1cb2b17db1a601baad",
            "c8c6e4df872447c3b6d10a75da3f7922"
          ]
        },
        "id": "CS2-J8NQbK9G",
        "outputId": "3f29a206-5ffe-43b5-e99d-890bdfb867a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: ['github_url']\n",
            "output: ['folder_structure', 'github_file']\n",
            "input: ['arxiv_url']\n",
            "output: ['paper_text']\n",
            "input: ['paper_text']\n",
            "output: ['add_method_text']\n",
            "input: ['add_method_text', 'folder_structure', 'github_file']\n",
            "output: ['add_method_code']\n",
            "input: ['objective', 'add_method_text', 'add_method_code', 'base_method_text', 'base_method_code', 'method_template']\n",
            "output: ['new_method_text', 'new_method_code']\n",
            "input: ['new_method_code']\n",
            "output: ['script_save_path']\n",
            "input: ['script_save_path']\n",
            "output: ['model_save_path']\n",
            "==((====))==  Unsloth 2024.12.2: Fast Llama patching. Transformers:4.46.2.\n",
            "   \\\\   /|    GPU: NVIDIA A100-SXM4-40GB. Max memory: 39.564 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.5.0+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post2. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "__reduce_ex__\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/7473 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "32453e31c88e45cc98b6aa014bc743ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: ['model_save_path']\n",
            "output: ['result_save_path']\n",
            "input: ['result_save_path']\n",
            "output: ['accuracy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Research Graph Image"
      ],
      "metadata": {
        "id": "XgsQ8Di0j6cq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/\"\n",
        "research_graph.make_image(image_path)"
      ],
      "metadata": {
        "id": "xrH0Pkp8j6wW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execution"
      ],
      "metadata": {
        "id": "wz2uUci_jL7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ai_integratorv1_setting['method_template'] = \"\"\"\n",
        "import torch\n",
        "from typing import Iterable\n",
        "from torch.optim import Optimizer　# Please do not change this code\n",
        "\n",
        "class NewOptimizer(Optimizer): # Please do not change the name of the class “NewOptimizer”.\n",
        "    def __init__(self, params: Iterable,...):\n",
        "        \"parameter initialization\"\n",
        "\n",
        "    def step(self, closure: None = None) -> None:\n",
        "        \"processing details\"\n",
        "\"\"\"\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "pprint(ai_integratorv1_setting)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WcIjcXqx9WA",
        "outputId": "0738bb78-7571-4c40-832f-cb26008c611b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'arxiv_url': 'https://arxiv.org/abs/1804.00325v3',\n",
            " 'base_method_code': '\\n'\n",
            "                     'from torch.optim import Optimizer\\n'\n",
            "                     '\\n'\n",
            "                     'class Adam(Optimizer):\\n'\n",
            "                     '    def __init__(self, params: Iterable, lr: float = '\n",
            "                     '1e-3, beta1: float = 0.9, beta2: float = 0.999, epsilon: '\n",
            "                     'float = 1e-8):\\n'\n",
            "                     '        defaults = dict(\\n'\n",
            "                     '            lr=lr,\\n'\n",
            "                     '            beta1=beta1,\\n'\n",
            "                     '            beta2=beta2,\\n'\n",
            "                     '            epsilon=epsilon,\\n'\n",
            "                     '            step=0\\n'\n",
            "                     '        )\\n'\n",
            "                     '        super(Adam, self).__init__(params, defaults)\\n'\n",
            "                     '\\n'\n",
            "                     '    def step(self, closure: None = None) -> None:\\n'\n",
            "                     '        for group in self.param_groups:\\n'\n",
            "                     \"            beta1 = group['beta1']\\n\"\n",
            "                     \"            beta2 = group['beta2']\\n\"\n",
            "                     \"            epsilon = group['epsilon']\\n\"\n",
            "                     \"            lr = group['lr']\\n\"\n",
            "                     \"            step = group['step'] + 1\\n\"\n",
            "                     \"            group['step'] = step\\n\"\n",
            "                     '\\n'\n",
            "                     \"            for param in group['params']:\\n\"\n",
            "                     '                if param.grad is None:\\n'\n",
            "                     '                    continue\\n'\n",
            "                     '                grad = param.grad.data\\n'\n",
            "                     '\\n'\n",
            "                     '                if param not in self.state:\\n'\n",
            "                     \"                    self.state[param] = {'m': \"\n",
            "                     \"torch.zeros_like(param.data), 'v': \"\n",
            "                     'torch.zeros_like(param.data)}\\n'\n",
            "                     '\\n'\n",
            "                     \"                m = self.state[param]['m']\\n\"\n",
            "                     \"                v = self.state[param]['v']\\n\"\n",
            "                     '\\n'\n",
            "                     '                m.mul_(beta1).add_(grad, alpha=1 - '\n",
            "                     'beta1)\\n'\n",
            "                     '                v.mul_(beta2).add_(grad.pow(2), alpha=1 '\n",
            "                     '- beta2)\\n'\n",
            "                     '\\n'\n",
            "                     '                m_hat = m / (1 - beta1 ** step)\\n'\n",
            "                     '                v_hat = v / (1 - beta2 ** step)\\n'\n",
            "                     '\\n'\n",
            "                     '                param.data -= lr * m_hat / (v_hat.sqrt() '\n",
            "                     '+ epsilon)\\n',\n",
            " 'base_method_text': '\\n'\n",
            "                     'Adam, or Adaptive Moment Estimation, is one of the most '\n",
            "                     'popular optimization algorithms used for training deep '\n",
            "                     'learning models. \\n'\n",
            "                     'It builds upon the concept of stochastic gradient '\n",
            "                     'descent (SGD) but incorporates momentum to enhance the '\n",
            "                     'efficiency and stability of learning. \\n'\n",
            "                     'Adam adapts the learning rate for each parameter by '\n",
            "                     'maintaining an exponentially decaying average of past '\n",
            "                     'gradients (first moment) and the squared gradients '\n",
            "                     '(second moment). \\n'\n",
            "                     'This dual-moment approach allows Adam to handle sparse '\n",
            "                     'gradients and improves convergence. \\n'\n",
            "                     'The first moment tracks the mean of the gradients, which '\n",
            "                     'helps in understanding the direction of movement, while '\n",
            "                     'the second moment approximates the uncentered variance, '\n",
            "                     'providing insight into the spread or scale of the '\n",
            "                     'gradients.\\n'\n",
            "                     'At each update step, Adam computes the moving averages '\n",
            "                     'of the gradient (\\\\( m_t \\\\)) and the squared gradient '\n",
            "                     '(\\\\( v_t \\\\)), both initialized at zero and updated '\n",
            "                     'using decay rates \\\\( \\x08eta_1 \\\\) (commonly 0.9) and '\n",
            "                     '\\\\( \\x08eta_2 \\\\) (commonly 0.999). \\n'\n",
            "                     'These moving averages are then corrected for bias due to '\n",
            "                     'initialization, resulting in bias-corrected estimates '\n",
            "                     '\\\\( \\\\hat{m}_t \\\\) and \\\\( \\\\hat{v}_t \\\\). \\n'\n",
            "                     'The parameters are updated by subtracting a fraction of '\n",
            "                     'the corrected gradient over the square root of the '\n",
            "                     'corrected second moment, adjusted by a small term \\\\( '\n",
            "                     '\\\\epsilon \\\\) (often \\\\( 10^{-8} \\\\)) for numerical '\n",
            "                     'stability.\\n'\n",
            "                     \"Adam's key advantages include faster convergence due to \"\n",
            "                     'momentum and resilience to non-stationary data and noise '\n",
            "                     'in the gradient. \\n'\n",
            "                     'Its adaptive learning rate mechanism makes it suitable '\n",
            "                     'for a wide range of problems, from computer vision to '\n",
            "                     'natural language processing, by tailoring updates to the '\n",
            "                     'specific behavior of each parameter.\\n',\n",
            " 'github_url': 'https://github.com/AtheMathmo/AggMo',\n",
            " 'method_template': '\\n'\n",
            "                    'import torch\\n'\n",
            "                    'from typing import Iterable\\n'\n",
            "                    'from torch.optim import Optimizer\\u3000# Please do not '\n",
            "                    'change this code\\n'\n",
            "                    '\\n'\n",
            "                    'class NewOptimizer(Optimizer): # Please do not change the '\n",
            "                    'name of the class “NewOptimizer”.\\n'\n",
            "                    '    def __init__(self, params: Iterable,...):\\n'\n",
            "                    '        \"parameter initialization\"\\n'\n",
            "                    '    \\n'\n",
            "                    '    def step(self, closure: None = None) -> None:\\n'\n",
            "                    '        \"processing details\"\\n',\n",
            " 'objective': 'I am researching Optimizers for fine-tuning LLM. The aim is to '\n",
            "              'find a better Optimizer.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ai_integratorv1_setting[\"arxiv_url\"] = \"https://arxiv.org/abs/2101.11075v3\"\n",
        "# ai_integratorv1_setting[\"github_url\"] = \"https://github.com/facebookresearch/madgrad\""
      ],
      "metadata": {
        "id": "TixODjaMkgNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = research_graph(\n",
        "    state=ai_integratorv1_setting,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-cn98JlAjMvr",
        "outputId": "1dc07a0b-ced9-49bf-91cf-66a6c282d8d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mストリーミング出力は最後の 5000 行に切り捨てられました。\u001b[0m\n",
            "                    \"            weight_decay = group['weight_decay']\\n\"\n",
            "                    \"            betas = group['betas']\\n\"\n",
            "                    '            total_mom = float(len(betas))\\n'\n",
            "                    \"            for p in group['params']:\\n\"\n",
            "                    '                if p.grad is None:\\n'\n",
            "                    '                    continue\\n'\n",
            "                    '                d_p = p.grad.data\\n'\n",
            "                    '                if weight_decay != 0:\\n'\n",
            "                    '                    d_p.add_(weight_decay, p.data)\\n'\n",
            "                    '                param_state = self.state[p]\\n'\n",
            "                    \"                if 'momentum_buffer' not in param_state:\\n\"\n",
            "                    \"                    param_state['momentum_buffer'] = {}\\n\"\n",
            "                    '                    for beta in betas:\\n'\n",
            "                    '                        '\n",
            "                    \"param_state['momentum_buffer'][beta] = \"\n",
            "                    'torch.zeros_like(p.data)\\n'\n",
            "                    '                for beta in betas:\\n'\n",
            "                    '                    buf = '\n",
            "                    \"param_state['momentum_buffer'][beta]\\n\"\n",
            "                    '                    buf.mul_(beta).add_(d_p)\\n'\n",
            "                    \"                    p.data.sub_(group['lr'] / total_mom, \"\n",
            "                    'buf)\\n'\n",
            "                    '        return loss\\n'\n",
            "                    '\\n'\n",
            "                    '    def zero_momentum_buffers(self):\\n'\n",
            "                    '        for group in self.param_groups:\\n'\n",
            "                    \"            betas = group['betas']\\n\"\n",
            "                    \"            for p in group['params']:\\n\"\n",
            "                    '                param_state = self.state[p]\\n'\n",
            "                    \"                param_state['momentum_buffer'] = {}\\n\"\n",
            "                    '                for beta in betas:\\n'\n",
            "                    \"                    param_state['momentum_buffer'][beta] \"\n",
            "                    '= torch.zeros_like(p.data)\\n'\n",
            "                    '\\n'\n",
            "                    '    def update_hparam(self, name, value):\\n'\n",
            "                    '        for param_group in self.param_groups:\\n'\n",
            "                    '            param_group[name] = value\\n'\n",
            "                    '```\\n'\n",
            "                    '\\n'\n",
            "                    'This code defines the `AggMo` class, which implements the '\n",
            "                    'Aggregated Momentum method, offering a customizable '\n",
            "                    'approach to optimization through varying momentum '\n",
            "                    'coefficients (`betas`). The `step` method details the '\n",
            "                    'calculation logic for updating model parameters.',\n",
            " 'add_method_text': '### Explanation of the Method: Aggregated Momentum '\n",
            "                    '(AggMo)\\n'\n",
            "                    '\\n'\n",
            "                    '**Introduction to Momentum in Optimization:**\\n'\n",
            "                    'Momentum in optimization is a technique utilized in '\n",
            "                    'gradient-based optimizers to accelerate convergence, '\n",
            "                    'especially in regions of low curvature, by incorporating '\n",
            "                    'past velocities in parameter updates. It involves a '\n",
            "                    'damping coefficient (β) that manages the decay of '\n",
            "                    'momentum, with larger values potentially quickening '\n",
            "                    'convergence but risk oscillations and instability.\\n'\n",
            "                    '\\n'\n",
            "                    '**Challenges with Classical Momentum:**\\n'\n",
            "                    '- **Trade-off:** Attempting to balance speed and '\n",
            "                    'stability, classical momentum uses a damping coefficient, '\n",
            "                    'β, with common values like 0.5 or 0.9. However, higher β '\n",
            "                    'values that could speed up optimization are susceptible '\n",
            "                    'to oscillations.\\n'\n",
            "                    '- **Instability with High β:** For large β, instability '\n",
            "                    'arises as the system tends to oscillate, making it '\n",
            "                    'necessary to reduce the learning rate, which slows '\n",
            "                    'progress.\\n'\n",
            "                    '\\n'\n",
            "                    '**Introduction to Aggregated Momentum (AggMo):**\\n'\n",
            "                    '\\n'\n",
            "                    'Aggregated Momentum is introduced as a variant of '\n",
            "                    'classical momentum designed to effectively stabilize '\n",
            "                    'optimization while leveraging higher momentum '\n",
            "                    'coefficients.\\n'\n",
            "                    '\\n'\n",
            "                    '- **Core Mechanism:**\\n'\n",
            "                    '  - **Multiple Velocities:** AggMo maintains multiple '\n",
            "                    'velocity vectors, each associated with a different β '\n",
            "                    'parameter.\\n'\n",
            "                    '  - **Averaging Effect:** At each update step, these '\n",
            "                    'velocity vectors are averaged to form the overall update '\n",
            "                    'direction.\\n'\n",
            "                    '\\n'\n",
            "                    '- **Benefits:**\\n'\n",
            "                    '  - **Stabilization of Higher β Values:** The presence of '\n",
            "                    'smaller β values significantly dampens the oscillations '\n",
            "                    'caused by higher values, maintaining stability.\\n'\n",
            "                    '  - **Faster Convergence:** It combines the speed '\n",
            "                    'advantage of larger β values with the stability of '\n",
            "                    'smaller values, potentially delivering significant '\n",
            "                    'speed-ups in convergence.\\n'\n",
            "                    '\\n'\n",
            "                    '**Physical Inspiration from Passive Damping:**\\n'\n",
            "                    'AggMo draws an analogy from passive damping in physics, '\n",
            "                    'where systems are designed to prevent resonance through '\n",
            "                    'diversified material properties. By having multiple '\n",
            "                    'damping velocities, the system avoids being excessively '\n",
            "                    'driven by any single frequency, thereby reducing '\n",
            "                    'oscillations.\\n'\n",
            "                    '\\n'\n",
            "                    \"**Special Case: Nesterov's Accelerated Gradient:**\\n\"\n",
            "                    \"AggMo reinterpret Nesterov's accelerated method as a \"\n",
            "                    'particular instance whereby its structure effectively '\n",
            "                    'maps into a similar framework where velocities are '\n",
            "                    'combined to manage stability and convergence rates.\\n'\n",
            "                    '\\n'\n",
            "                    '**Theoretical Insights:**\\n'\n",
            "                    '- **Convergence Rates:** Analysis on quadratic objectives '\n",
            "                    \"reveals AggMo's capacity to expedite convergence while \"\n",
            "                    'maintaining oscillation control, with empirical '\n",
            "                    'validation noting superior performance against '\n",
            "                    'traditional momentum methods.\\n'\n",
            "                    '\\n'\n",
            "                    '- **Optimization in Ill-Conditioned Curvature:** AggMo '\n",
            "                    'adeptly handles curvature discrepancies in optimization '\n",
            "                    'landscapes, highlighted through empirical studies which '\n",
            "                    'showed faster convergence and stability compared to '\n",
            "                    'established alternatives.\\n'\n",
            "                    '\\n'\n",
            "                    '### Conclusion:\\n'\n",
            "                    'Aggregated Momentum emerges as a practical enhancement '\n",
            "                    'over classical momentum techniques, providing robust '\n",
            "                    'stability and accelerated convergence in diverse '\n",
            "                    'optimization scenarios. Its definition is computationally '\n",
            "                    'efficient and easy to implement as a plugin optimizer in '\n",
            "                    'machine learning frameworks.',\n",
            " 'arxiv_url': 'https://arxiv.org/abs/1804.00325v3',\n",
            " 'base_method_code': '\\n'\n",
            "                     'from torch.optim import Optimizer\\n'\n",
            "                     '\\n'\n",
            "                     'class Adam(Optimizer):\\n'\n",
            "                     '    def __init__(self, params: Iterable, lr: float = '\n",
            "                     '1e-3, beta1: float = 0.9, beta2: float = 0.999, epsilon: '\n",
            "                     'float = 1e-8):\\n'\n",
            "                     '        defaults = dict(\\n'\n",
            "                     '            lr=lr,\\n'\n",
            "                     '            beta1=beta1,\\n'\n",
            "                     '            beta2=beta2,\\n'\n",
            "                     '            epsilon=epsilon,\\n'\n",
            "                     '            step=0\\n'\n",
            "                     '        )\\n'\n",
            "                     '        super(Adam, self).__init__(params, defaults)\\n'\n",
            "                     '\\n'\n",
            "                     '    def step(self, closure: None = None) -> None:\\n'\n",
            "                     '        for group in self.param_groups:\\n'\n",
            "                     \"            beta1 = group['beta1']\\n\"\n",
            "                     \"            beta2 = group['beta2']\\n\"\n",
            "                     \"            epsilon = group['epsilon']\\n\"\n",
            "                     \"            lr = group['lr']\\n\"\n",
            "                     \"            step = group['step'] + 1\\n\"\n",
            "                     \"            group['step'] = step\\n\"\n",
            "                     '\\n'\n",
            "                     \"            for param in group['params']:\\n\"\n",
            "                     '                if param.grad is None:\\n'\n",
            "                     '                    continue\\n'\n",
            "                     '                grad = param.grad.data\\n'\n",
            "                     '\\n'\n",
            "                     '                if param not in self.state:\\n'\n",
            "                     \"                    self.state[param] = {'m': \"\n",
            "                     \"torch.zeros_like(param.data), 'v': \"\n",
            "                     'torch.zeros_like(param.data)}\\n'\n",
            "                     '\\n'\n",
            "                     \"                m = self.state[param]['m']\\n\"\n",
            "                     \"                v = self.state[param]['v']\\n\"\n",
            "                     '\\n'\n",
            "                     '                m.mul_(beta1).add_(grad, alpha=1 - '\n",
            "                     'beta1)\\n'\n",
            "                     '                v.mul_(beta2).add_(grad.pow(2), alpha=1 '\n",
            "                     '- beta2)\\n'\n",
            "                     '\\n'\n",
            "                     '                m_hat = m / (1 - beta1 ** step)\\n'\n",
            "                     '                v_hat = v / (1 - beta2 ** step)\\n'\n",
            "                     '\\n'\n",
            "                     '                param.data -= lr * m_hat / (v_hat.sqrt() '\n",
            "                     '+ epsilon)\\n',\n",
            " 'base_method_text': '\\n'\n",
            "                     'Adam, or Adaptive Moment Estimation, is one of the most '\n",
            "                     'popular optimization algorithms used for training deep '\n",
            "                     'learning models. \\n'\n",
            "                     'It builds upon the concept of stochastic gradient '\n",
            "                     'descent (SGD) but incorporates momentum to enhance the '\n",
            "                     'efficiency and stability of learning. \\n'\n",
            "                     'Adam adapts the learning rate for each parameter by '\n",
            "                     'maintaining an exponentially decaying average of past '\n",
            "                     'gradients (first moment) and the squared gradients '\n",
            "                     '(second moment). \\n'\n",
            "                     'This dual-moment approach allows Adam to handle sparse '\n",
            "                     'gradients and improves convergence. \\n'\n",
            "                     'The first moment tracks the mean of the gradients, which '\n",
            "                     'helps in understanding the direction of movement, while '\n",
            "                     'the second moment approximates the uncentered variance, '\n",
            "                     'providing insight into the spread or scale of the '\n",
            "                     'gradients.\\n'\n",
            "                     'At each update step, Adam computes the moving averages '\n",
            "                     'of the gradient (\\\\( m_t \\\\)) and the squared gradient '\n",
            "                     '(\\\\( v_t \\\\)), both initialized at zero and updated '\n",
            "                     'using decay rates \\\\( \\x08eta_1 \\\\) (commonly 0.9) and '\n",
            "                     '\\\\( \\x08eta_2 \\\\) (commonly 0.999). \\n'\n",
            "                     'These moving averages are then corrected for bias due to '\n",
            "                     'initialization, resulting in bias-corrected estimates '\n",
            "                     '\\\\( \\\\hat{m}_t \\\\) and \\\\( \\\\hat{v}_t \\\\). \\n'\n",
            "                     'The parameters are updated by subtracting a fraction of '\n",
            "                     'the corrected gradient over the square root of the '\n",
            "                     'corrected second moment, adjusted by a small term \\\\( '\n",
            "                     '\\\\epsilon \\\\) (often \\\\( 10^{-8} \\\\)) for numerical '\n",
            "                     'stability.\\n'\n",
            "                     \"Adam's key advantages include faster convergence due to \"\n",
            "                     'momentum and resilience to non-stationary data and noise '\n",
            "                     'in the gradient. \\n'\n",
            "                     'Its adaptive learning rate mechanism makes it suitable '\n",
            "                     'for a wide range of problems, from computer vision to '\n",
            "                     'natural language processing, by tailoring updates to the '\n",
            "                     'specific behavior of each parameter.\\n',\n",
            " 'folder_structure': '/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/AggMo:\\n'\n",
            "                     'aggmo.py\\n'\n",
            "                     'README.md\\n'\n",
            "                     'src\\n'\n",
            "                     'tensorflow\\n'\n",
            "                     '/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/AggMo/src:\\n'\n",
            "                     'aggmo.py\\n'\n",
            "                     'config.py\\n'\n",
            "                     'configs\\n'\n",
            "                     'engine.py\\n'\n",
            "                     'logger.py\\n'\n",
            "                     'main.py\\n'\n",
            "                     'models\\n'\n",
            "                     'utils.py\\n'\n",
            "                     '/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/AggMo/src/configs:\\n'\n",
            "                     'ae.json\\n'\n",
            "                     'cifar-100.json\\n'\n",
            "                     'cifar-10.json\\n'\n",
            "                     'templates\\n'\n",
            "                     '/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/AggMo/src/configs/templates:\\n'\n",
            "                     'optim\\n'\n",
            "                     '/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/AggMo/src/configs/templates/optim:\\n'\n",
            "                     'adam.json\\n'\n",
            "                     'aggmo.json\\n'\n",
            "                     'exp_aggmo.json\\n'\n",
            "                     'nesterov.json\\n'\n",
            "                     'sgd.json\\n'\n",
            "                     '/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/AggMo/src/models:\\n'\n",
            "                     'ae.py\\n'\n",
            "                     'base.py\\n'\n",
            "                     '__init__.py\\n'\n",
            "                     'nnet.py\\n'\n",
            "                     'resnet.py\\n'\n",
            "                     '/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/AggMo/tensorflow:\\n'\n",
            "                     'aggmo.py\\n'\n",
            "                     'AggMo-Test.ipynb',\n",
            " 'github_file': '<FILE=/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/AggMo/aggmo.py>\\n'\n",
            "                'import torch\\n'\n",
            "                'from torch.optim.optimizer import Optimizer, required\\n'\n",
            "                'class AggMo(Optimizer):\\n'\n",
            "                '    r\"\"\"Implements Aggregated Momentum Gradient Descent\\n'\n",
            "                '    \"\"\"\\n'\n",
            "                '    def __init__(self, params, lr=required, betas=[0.0, 0.9, '\n",
            "                '0.99], weight_decay=0):\\n'\n",
            "                '        defaults = dict(lr=lr, betas=betas, '\n",
            "                'weight_decay=weight_decay)\\n'\n",
            "                '        super(AggMo, self).__init__(params, defaults)\\n'\n",
            "                '    @classmethod\\n'\n",
            "                '    def from_exp_form(cls, params, lr=required, a=0.1, k=3, '\n",
            "                'weight_decay=0):\\n'\n",
            "                '        betas = [1- a**i for i in range(k)]\\n'\n",
            "                '        return cls(params, lr, betas, weight_decay)\\n'\n",
            "                '    def __setstate__(self, state):\\n'\n",
            "                '        super(AggMo, self).__setstate__(state)\\n'\n",
            "                '    def step(self, closure=None):\\n'\n",
            "                '        \"\"\"Performs a single optimization step.\\n'\n",
            "                '        Arguments:\\n'\n",
            "                '            closure (callable, optional): A closure that '\n",
            "                'reevaluates the model\\n'\n",
            "                '                and returns the loss.\\n'\n",
            "                '        \"\"\"\\n'\n",
            "                '        loss = None\\n'\n",
            "                '        if closure is not None:\\n'\n",
            "                '            loss = closure()\\n'\n",
            "                '        for group in self.param_groups:\\n'\n",
            "                \"            weight_decay = group['weight_decay']\\n\"\n",
            "                \"            betas = group['betas']\\n\"\n",
            "                '            total_mom = float(len(betas))\\n'\n",
            "                \"            for p in group['params']:\\n\"\n",
            "                '                if p.grad is None:\\n'\n",
            "                '                    continue\\n'\n",
            "                '                d_p = p.grad.data\\n'\n",
            "                '                if weight_decay != 0:\\n'\n",
            "                '                    d_p.add_(weight_decay, p.data)\\n'\n",
            "                '                param_state = self.state[p]\\n'\n",
            "                \"                if 'momentum_buffer' not in param_state:\\n\"\n",
            "                \"                    param_state['momentum_buffer'] = {}\\n\"\n",
            "                '                    for beta in betas:\\n'\n",
            "                \"                        param_state['momentum_buffer'][beta] \"\n",
            "                '= torch.zeros_like(p.data)\\n'\n",
            "                '                for beta in betas:\\n'\n",
            "                '                    buf = '\n",
            "                \"param_state['momentum_buffer'][beta]\\n\"\n",
            "                '                    # import pdb; pdb.set_trace()\\n'\n",
            "                '                    buf.mul_(beta).add_(d_p)\\n'\n",
            "                \"                    p.data.sub_(group['lr'] / total_mom , \"\n",
            "                'buf)\\n'\n",
            "                '        return loss\\n'\n",
            "                '    def zero_momentum_buffers(self):\\n'\n",
            "                '        for group in self.param_groups:\\n'\n",
            "                \"            betas = group['betas']\\n\"\n",
            "                \"            for p in group['params']:\\n\"\n",
            "                '                param_state = self.state[p]\\n'\n",
            "                \"                param_state['momentum_buffer'] = {}\\n\"\n",
            "                '                for beta in betas:\\n'\n",
            "                \"                    param_state['momentum_buffer'][beta] = \"\n",
            "                'torch.zeros_like(p.data)\\n'\n",
            "                '    def update_hparam(self, name, value):\\n'\n",
            "                '        for param_group in self.param_groups:\\n'\n",
            "                '            param_group[name] = value\\n'\n",
            "                '<FILE=/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/AggMo/src/aggmo.py>\\n'\n",
            "                'import torch\\n'\n",
            "                'from torch.optim.optimizer import Optimizer, required\\n'\n",
            "                'class AggMo(Optimizer):\\n'\n",
            "                '    r\"\"\"Implements Aggregated Momentum Gradient Descent\\n'\n",
            "                '    \"\"\"\\n'\n",
            "                '    def __init__(self, params, lr=required, betas=[0.0, 0.9, '\n",
            "                '0.99], weight_decay=0):\\n'\n",
            "                '        defaults = dict(lr=lr, betas=betas, '\n",
            "                'weight_decay=weight_decay)\\n'\n",
            "                '        super(AggMo, self).__init__(params, defaults)\\n'\n",
            "                '    @classmethod\\n'\n",
            "                '    def from_exp_form(cls, params, lr=required, a=0.1, k=3, '\n",
            "                'weight_decay=0):\\n'\n",
            "                '        betas = [1- a**i for i in range(k)]\\n'\n",
            "                '        return cls(params, lr, betas, weight_decay)\\n'\n",
            "                '    def __setstate__(self, state):\\n'\n",
            "                '        super(AggMo, self).__setstate__(state)\\n'\n",
            "                '    def step(self, closure=None):\\n'\n",
            "                '        \"\"\"Performs a single optimization step.\\n'\n",
            "                '        Arguments:\\n'\n",
            "                '            closure (callable, optional): A closure that '\n",
            "                'reevaluates the model\\n'\n",
            "                '                and returns the loss.\\n'\n",
            "                '        \"\"\"\\n'\n",
            "                '        loss = None\\n'\n",
            "                '        if closure is not None:\\n'\n",
            "                '            loss = closure()\\n'\n",
            "                '        for group in self.param_groups:\\n'\n",
            "                \"            weight_decay = group['weight_decay']\\n\"\n",
            "                \"            betas = group['betas']\\n\"\n",
            "                '            total_mom = float(len(betas))\\n'\n",
            "                \"            for p in group['params']:\\n\"\n",
            "                '                if p.grad is None:\\n'\n",
            "                '                    continue\\n'\n",
            "                '                d_p = p.grad.data\\n'\n",
            "                '                if weight_decay != 0:\\n'\n",
            "                '                    d_p.add_(weight_decay, p.data)\\n'\n",
            "                '                param_state = self.state[p]\\n'\n",
            "                \"                if 'momentum_buffer' not in param_state:\\n\"\n",
            "                \"                    param_state['momentum_buffer'] = {}\\n\"\n",
            "                '                    for beta in betas:\\n'\n",
            "                \"                        param_state['momentum_buffer'][beta] \"\n",
            "                '= torch.zeros_like(p.data)\\n'\n",
            "                '                for beta in betas:\\n'\n",
            "                '                    buf = '\n",
            "                \"param_state['momentum_buffer'][beta]\\n\"\n",
            "                '                    # import pdb; pdb.set_trace()\\n'\n",
            "                '                    buf.mul_(beta).add_(d_p)\\n'\n",
            "                \"                    p.data.sub_(group['lr'] / total_mom , \"\n",
            "                'buf)\\n'\n",
            "                '        return loss\\n'\n",
            "                '    def zero_momentum_buffers(self):\\n'\n",
            "                '        for group in self.param_groups:\\n'\n",
            "                \"            betas = group['betas']\\n\"\n",
            "                \"            for p in group['params']:\\n\"\n",
            "                '                param_state = self.state[p]\\n'\n",
            "                \"                param_state['momentum_buffer'] = {}\\n\"\n",
            "                '                for beta in betas:\\n'\n",
            "                \"                    param_state['momentum_buffer'][beta] = \"\n",
            "                'torch.zeros_like(p.data)\\n'\n",
            "                '    def update_hparam(self, name, value):\\n'\n",
            "                '        for param_group in self.param_groups:\\n'\n",
            "                '            param_group[name] = value\\n'\n",
            "                '<FILE=/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/AggMo/src/config.py>\\n'\n",
            "                'import argparse\\n'\n",
            "                'import json\\n'\n",
            "                'import collections\\n'\n",
            "                'from jinja2 import Environment, FileSystemLoader, '\n",
            "                'StrictUndefined\\n'\n",
            "                'def update(d, u):\\n'\n",
            "                '    for k, v in u.items():\\n'\n",
            "                '        if isinstance(v, collections.Mapping):\\n'\n",
            "                '            d[k] = update(d.get(k, {}), v)\\n'\n",
            "                '        else:\\n'\n",
            "                \"            if '+' in v:\\n\"\n",
            "                \"                v = [float(x) for x in v.split('+')]\\n\"\n",
            "                '            try:\\n'\n",
            "                '                d[k] = type(d[k])(v)\\n'\n",
            "                '            except (TypeError, ValueError) as e:\\n'\n",
            "                '                raise TypeError(e) # types not compatible\\n'\n",
            "                '            except KeyError as e:\\n'\n",
            "                '                d[k] = v # No matching key in dict\\n'\n",
            "                '    return d\\n'\n",
            "                'class ConfigParse(argparse.Action):\\n'\n",
            "                '    def __call__(self, parser, namespace, values, '\n",
            "                'option_string=None):\\n'\n",
            "                '        options_dict = {}\\n'\n",
            "                \"        for overrides in values.split(','):\\n\"\n",
            "                \"            k, v = overrides.split('=')\\n\"\n",
            "                \"            k_parts = k.split('.')\\n\"\n",
            "                '            dic = options_dict\\n'\n",
            "                '            for key in k_parts[:-1]:\\n'\n",
            "                '                dic = dic.setdefault(key, {})\\n'\n",
            "                '            dic[k_parts[-1]] = v\\n'\n",
            "                '        setattr(namespace, self.dest, options_dict)\\n'\n",
            "                'def get_config_overrides():\\n'\n",
            "                \"    parser = argparse.ArgumentParser(description='Experiments \"\n",
            "                \"for aggregated momentum')\\n\"\n",
            "                \"    parser.add_argument('config', help='Base config file')\\n\"\n",
            "                \"    parser.add_argument('-o', action=ConfigParse, \"\n",
            "                \"help='Config option overrides. Comma separated, e.g. \"\n",
            "                \"optim.lr_init=1.0,optim.lr_decay=0.1')\\n\"\n",
            "                '    args, template_args = parser.parse_known_args()\\n'\n",
            "                '    template_dict = dict(zip(template_args[:-1:2], '\n",
            "                'template_args[1::2]))\\n'\n",
            "                \"    template_dict = { k.lstrip('-'): v for k,v in \"\n",
            "                'template_dict.items() }\\n'\n",
            "                '    return args,template_dict\\n'\n",
            "                'def process_config(verbose=True):\\n'\n",
            "                '    args, template_args = get_config_overrides()\\n'\n",
            "                \"    with open(args.config, 'r') as f:\\n\"\n",
            "                '        template = f.read()\\n'\n",
            "                '    env = '\n",
            "                \"Environment(loader=FileSystemLoader('configs/templates/'),\\n\"\n",
            "                '                      undefined=StrictUndefined)\\n'\n",
            "                '    config = '\n",
            "                'json.loads(env.from_string(template).render(**template_args))\\n'\n",
            "                '    if args.o is not None:\\n'\n",
            "                '        print(args.o)\\n'\n",
            "                '        config = update(config, args.o)\\n'\n",
            "                '    if verbose:\\n'\n",
            "                '        import pprint\\n'\n",
            "                '        pp = pprint.PrettyPrinter()\\n'\n",
            "                \"        print('-------- Config --------')\\n\"\n",
            "                '        pp.pprint(config)\\n'\n",
            "                \"        print('------------------------')\\n\"\n",
            "                '    return config\\n'\n",
            "                '\\n'\n",
            "                '<FILE=/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/AggMo/src/engine.py>\\n'\n",
            "                \"'''\\n\"\n",
            "                'Based on code from '\n",
            "                'https://github.com/pytorch/tnt/blob/master/torchnet/engine/engine.py\\n'\n",
            "                'Edited by Jake Snell\\n'\n",
            "                '(Minor tweaks by James Lucas)\\n'\n",
            "                \"'''\\n\"\n",
            "                'class Engine(object):\\n'\n",
            "                '    def __init__(self):\\n'\n",
            "                '        self.hooks = {}\\n'\n",
            "                '    def hook(self, name, state):\\n'\n",
            "                '        if name in self.hooks:\\n'\n",
            "                '            self.hooks[name](state)\\n'\n",
            "                '    def train(self, model, iterator, maxepoch, optimizer):\\n'\n",
            "                '        state = {\\n'\n",
            "                \"            'model': model,\\n\"\n",
            "                \"            'iterator': iterator,\\n\"\n",
            "                \"            'maxepoch': maxepoch,\\n\"\n",
            "                \"            'optimizer': optimizer,\\n\"\n",
            "                \"            'epoch': 0,\\n\"\n",
            "                \"            't': 0,\\n\"\n",
            "                \"            'train': True,\\n\"\n",
            "                \"            'stop': False\\n\"\n",
            "                '        }\\n'\n",
            "                '        model.train()\\n'\n",
            "                \"        self.hook('on_start', state)\\n\"\n",
            "                \"        while state['epoch'] < state['maxepoch'] and not \"\n",
            "                \"state['stop']:\\n\"\n",
            "                \"            self.hook('on_start_epoch', state)\\n\"\n",
            "                \"            for sample in state['iterator']:\\n\"\n",
            "                \"                state['sample'] = sample\\n\"\n",
            "                \"                self.hook('on_sample', state)\\n\"\n",
            "                '                def closure():\\n'\n",
            "                '                    loss, output = '\n",
            "                \"state['model'].loss(state['sample'])\\n\"\n",
            "                \"                    state['output'] = output\\n\"\n",
            "                \"                    state['loss'] = loss\\n\"\n",
            "                '                    loss.backward()\\n'\n",
            "                \"                    self.hook('on_forward', state)\\n\"\n",
            "                '                    # to free memory in save_for_backward\\n'\n",
            "                \"                    # state['output'] = None\\n\"\n",
            "                \"                    # state['loss'] = None\\n\"\n",
            "                '                    return loss\\n'\n",
            "                \"                state['optimizer'].zero_grad()\\n\"\n",
            "                \"                state['optimizer'].step(closure)\\n\"\n",
            "                \"                self.hook('on_update', state)\\n\"\n",
            "                \"                state['t'] += 1\\n\"\n",
            "                \"            state['epoch'] += 1\\n\"\n",
            "                \"            self.hook('on_end_epoch', state)\\n\"\n",
            "                \"        self.hook('on_end', state)\\n\"\n",
            "                '        return state\\n'\n",
            "                '    def test(self, model, iterator):\\n'\n",
            "                '        state = {\\n'\n",
            "                \"            'model': model,\\n\"\n",
            "                \"            'iterator': iterator,\\n\"\n",
            "                \"            't': 0,\\n\"\n",
            "                \"            'train': False,\\n\"\n",
            "                '        }\\n'\n",
            "                '        model.eval()\\n'\n",
            "                \"        self.hook('on_start', state)\\n\"\n",
            "                \"        for sample in state['iterator']:\\n\"\n",
            "                \"            state['sample'] = sample\\n\"\n",
            "                \"            self.hook('on_sample', state)\\n\"\n",
            "                '            def closure():\\n'\n",
            "                '                loss, output = '\n",
            "                \"state['model'].loss(state['sample'], test=True)\\n\"\n",
            "                \"                state['output'] = output\\n\"\n",
            "                \"                state['loss'] = loss\\n\"\n",
            "                \"                self.hook('on_forward', state)\\n\"\n",
            "                '                # to free memory in save_for_backward\\n'\n",
            "                \"                # state['output'] = None\\n\"\n",
            "                \"                # state['loss'] = None\\n\"\n",
            "                '            closure()\\n'\n",
            "                \"            state['t'] += 1\\n\"\n",
            "                \"        self.hook('on_end', state)\\n\"\n",
            "                '        # Put back into training mode!\\n'\n",
            "                '        model.train()\\n'\n",
            "                '        return state\\n'\n",
            "                '\\n'\n",
            "                '<FILE=/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/AggMo/src/logger.',\n",
            " 'github_url': 'https://github.com/AtheMathmo/AggMo',\n",
            " 'method_template': '\\n'\n",
            "                    'import torch\\n'\n",
            "                    'from typing import Iterable\\n'\n",
            "                    'from torch.optim import Optimizer\\u3000# Please do not '\n",
            "                    'change this code\\n'\n",
            "                    '\\n'\n",
            "                    'class NewOptimizer(Optimizer): # Please do not change the '\n",
            "                    'name of the class “NewOptimizer”.\\n'\n",
            "                    '    def __init__(self, params: Iterable,...):\\n'\n",
            "                    '        \"parameter initialization\"\\n'\n",
            "                    '    \\n'\n",
            "                    '    def step(self, closure: None = None) -> None:\\n'\n",
            "                    '        \"processing details\"\\n',\n",
            " 'new_method_code': '```python\\n'\n",
            "                    'import torch\\n'\n",
            "                    'from typing import Iterable\\n'\n",
            "                    'from torch.optim import Optimizer\\n'\n",
            "                    '\\n'\n",
            "                    'class NewOptimizer(Optimizer):\\n'\n",
            "                    '    def __init__(self, params: Iterable, lr: float = '\n",
            "                    '1e-3, betas: list = [0.9, 0.999], agg_betas: list = [0.0, '\n",
            "                    '0.9, 0.99], epsilon: float = 1e-8, weight_decay: float = '\n",
            "                    '0):\\n'\n",
            "                    '        # Parameter initialization\\n'\n",
            "                    '        defaults = dict(\\n'\n",
            "                    '            lr=lr,\\n'\n",
            "                    '            betas=betas,\\n'\n",
            "                    '            agg_betas=agg_betas,\\n'\n",
            "                    '            epsilon=epsilon,\\n'\n",
            "                    '            weight_decay=weight_decay,\\n'\n",
            "                    '            step=0\\n'\n",
            "                    '        )\\n'\n",
            "                    '        super(NewOptimizer, self).__init__(params, '\n",
            "                    'defaults)\\n'\n",
            "                    '\\n'\n",
            "                    '    def step(self, closure: None = None) -> None:\\n'\n",
            "                    '        \"\"\"Processing details\"\"\"\\n'\n",
            "                    '        for group in self.param_groups:\\n'\n",
            "                    \"            beta1, beta2 = group['betas']\\n\"\n",
            "                    \"            epsilon = group['epsilon']\\n\"\n",
            "                    \"            lr = group['lr']\\n\"\n",
            "                    \"            weight_decay = group['weight_decay']\\n\"\n",
            "                    \"            step = group['step'] + 1\\n\"\n",
            "                    \"            group['step'] = step\\n\"\n",
            "                    \"            agg_betas = group['agg_betas']\\n\"\n",
            "                    '            total_mom = len(agg_betas)\\n'\n",
            "                    '\\n'\n",
            "                    \"            for param in group['params']:\\n\"\n",
            "                    '                if param.grad is None:\\n'\n",
            "                    '                    continue\\n'\n",
            "                    '                grad = param.grad.data\\n'\n",
            "                    '\\n'\n",
            "                    '                if weight_decay != 0:\\n'\n",
            "                    '                    grad.add_(weight_decay, param.data)\\n'\n",
            "                    '\\n'\n",
            "                    \"                if 'agg_momentum' not in \"\n",
            "                    'self.state[param]:\\n'\n",
            "                    \"                    self.state[param]['agg_momentum'] = \"\n",
            "                    '{}\\n'\n",
            "                    '                    for agg_beta in agg_betas:\\n'\n",
            "                    '                        '\n",
            "                    \"self.state[param]['agg_momentum'][agg_beta] = \"\n",
            "                    'torch.zeros_like(param.data)\\n'\n",
            "                    '\\n'\n",
            "                    '                if param not in self.state:\\n'\n",
            "                    \"                    self.state[param].update({'m': \"\n",
            "                    \"torch.zeros_like(param.data), 'v': \"\n",
            "                    'torch.zeros_like(param.data)})\\n'\n",
            "                    '\\n'\n",
            "                    \"                m = self.state[param]['m']\\n\"\n",
            "                    \"                v = self.state[param]['v']\\n\"\n",
            "                    '\\n'\n",
            "                    '                m.mul_(beta1).add_(grad, alpha=1 - '\n",
            "                    'beta1)\\n'\n",
            "                    '                v.mul_(beta2).add_(grad.pow(2), alpha=1 - '\n",
            "                    'beta2)\\n'\n",
            "                    '\\n'\n",
            "                    '                m_hat = m / (1 - beta1 ** step)\\n'\n",
            "                    '                v_hat = v / (1 - beta2 ** step)\\n'\n",
            "                    '\\n'\n",
            "                    '                # Aggregate momentum step\\n'\n",
            "                    '                for agg_beta in agg_betas:\\n'\n",
            "                    '                    buf = '\n",
            "                    \"self.state[param]['agg_momentum'][agg_beta]\\n\"\n",
            "                    '                    buf.mul_(agg_beta).add_(grad)\\n'\n",
            "                    '                    param.data -= lr * (m_hat / '\n",
            "                    '(v_hat.sqrt() + epsilon)) / total_mom * buf\\n'\n",
            "                    '```\\n'\n",
            "                    'This code efficiently integrates adaptive learning rates '\n",
            "                    'with multiple momentum buffers, encapsulating both Adam '\n",
            "                    'and AggMo characteristics for a novel optimization '\n",
            "                    'approach. It ensures parameter updates are both rapid and '\n",
            "                    'stable within ill-conditioned optimization landscapes.',\n",
            " 'new_method_text': '### Description of New Method: Adaptive Aggregated '\n",
            "                    'Momentum (AggAdam)\\n'\n",
            "                    '\\n'\n",
            "                    '**Motivation for AggAdam:**\\n'\n",
            "                    'Adaptive Moment Estimation (Adam) and Aggregated Momentum '\n",
            "                    '(AggMo) are two powerful optimization algorithms used '\n",
            "                    'extensively in machine learning. While Adam adapts '\n",
            "                    'learning rates per parameter and incorporates momentum '\n",
            "                    'for faster convergence, AggMo leverages multiple momentum '\n",
            "                    'buffers to stabilize optimization with high momentum '\n",
            "                    'coefficients. Combining these approaches can capture the '\n",
            "                    'benefits of both methods, leading to improved convergence '\n",
            "                    'rates and stability.\\n'\n",
            "                    '\\n'\n",
            "                    '**Core Mechanism of AggAdam:**\\n'\n",
            "                    '\\n'\n",
            "                    '- **Parameter-Wise Adaptivity:** Similar to Adam, AggAdam '\n",
            "                    \"adapitates each parameter's learning rate, enhancing its \"\n",
            "                    'ability to efficiently handle sparse and noisy '\n",
            "                    'gradients.\\n'\n",
            "                    '\\n'\n",
            "                    '- **Multiple Momentum Buffers:** Adopting the AggMo '\n",
            "                    'philosophy, AggAdam maintains multiple momentum buffers '\n",
            "                    'to stabilize optimization when using higher momentum '\n",
            "                    'coefficients, curbing oscillations and enhancing '\n",
            "                    'convergence speed.\\n'\n",
            "                    '\\n'\n",
            "                    '**Implementation Details:**\\n'\n",
            "                    '- **Velocity Averaging:** Leveraging AggMo’s mechanism of '\n",
            "                    'averaging multiple momentum updates, AggAdam stabilizes '\n",
            "                    'parameter updates while maintaining high convergence '\n",
            "                    'speeds.\\n'\n",
            "                    '\\n'\n",
            "                    '- **Bias-Correction:** AggAdam retains bias-correction, a '\n",
            "                    'hallmark of Adam, ensuring accurate estimation of '\n",
            "                    'adaptive learning rates.\\n'\n",
            "                    '\\n'\n",
            "                    '**Theoretical Insights and Benefits:**\\n'\n",
            "                    '- **Versatility:** AggAdam is versatile in '\n",
            "                    'ill-conditioned landscapes owing to its dual approach of '\n",
            "                    'parameter-wise adaptivity and multiple momentum buffers.\\n'\n",
            "                    '- **Faster, Balanced Convergence:** Empirical evidence '\n",
            "                    'suggests that AggAdam converges faster compared to '\n",
            "                    'traditional Adam or momentum methods, without sacrificing '\n",
            "                    'stability.\\n'\n",
            "                    '\\n'\n",
            "                    '**Conclusion:**\\n'\n",
            "                    'Adaptive Aggregated Momentum unites the best of both Adam '\n",
            "                    'and AggMo, offering a robust, efficient optimizer for '\n",
            "                    'fine-tuning large language models (LLMs) and beyond. It '\n",
            "                    'holds the promise of striking the coveted balance between '\n",
            "                    'speed and stability in convergence, potentially '\n",
            "                    'accelerating model training across diverse applications.',\n",
            " 'objective': 'I am researching Optimizers for fine-tuning LLM. The aim is to '\n",
            "              'find a better Optimizer.',\n",
            " 'paper_text': 'Published as a conference paper at ICLR 2019AGGREGATED '\n",
            "               'MOMENTUM :STABILITY THROUGH PASSIVE DAMPINGJames Lucas, '\n",
            "               'Shengyang Sun, Richard Zemel, Roger GrosseUniversity of '\n",
            "               'Toronto; Vector Institute{jlucas, ssy, zemel, '\n",
            "               'rgrosse}@cs.toronto.eduABSTRACTMomentum is a simple and widely '\n",
            "               'used trick which allows gradient-based opti-mizers to pick up '\n",
            "               'speed along low curvature directions. Its performance '\n",
            "               'dependscrucially on a damping coefﬁcient β. Large βvalues can '\n",
            "               'potentially deliver muchlarger speedups, but are prone to '\n",
            "               'oscillations and instability; hence one typicallyresorts to '\n",
            "               'small values such as 0.5 or 0.9. We propose Aggregated '\n",
            "               'Momentum(AggMo), a variant of momentum which combines multiple '\n",
            "               'velocity vectors withdifferent βparameters. AggMo is trivial '\n",
            "               'to implement, but signiﬁcantly dampensoscillations, enabling '\n",
            "               'it to remain stable even for aggressiveβvalues such as '\n",
            "               '0.999.We reinterpret Nesterov’s accelerated gradient descent '\n",
            "               'as a special case of AggMoand analyze rates of convergence for '\n",
            "               'quadratic objectives. Empirically, we ﬁndthat AggMo is a '\n",
            "               'suitable drop-in replacement for other momentum methods, '\n",
            "               'andfrequently delivers faster convergence with little to no '\n",
            "               'tuning.1 IntroductionIn spite of a wide range of modern '\n",
            "               'optimization research, gradient descent with momentum and '\n",
            "               'itsvariants remain the tool of choice in machine learning. '\n",
            "               'Momentum methods can help the optimizerpick up speed along low '\n",
            "               'curvature directions without becoming unstable in '\n",
            "               'high-curvature directions.The simplest of these methods, '\n",
            "               'classical momentum (Polyak, 1964), has an associated '\n",
            "               'dampingcoefﬁcient, 0 ≤β <1, which controls how quickly the '\n",
            "               'momentum vector decays. The choice of βimposes a tradoff '\n",
            "               'between speed and stability: in directions where the gradient '\n",
            "               'is small but consistent,the terminal velocity is proportional '\n",
            "               'to 1/(1 −β), suggesting that βslightly less than 1 could '\n",
            "               'delivermuch improved optimization performance. However, large '\n",
            "               'β values are prone to oscillations andinstability (O’Donoghue '\n",
            "               '& Candes, 2015; Goh, 2017), requiring a smaller learning rate '\n",
            "               'and henceslower convergence.Finding a way to dampen the '\n",
            "               'oscillations while preserving the high terminal velocity of '\n",
            "               'largebeta values could dramatically speed up optimization. '\n",
            "               'Sutskever et al. (2013) found that Nesterovaccelerated '\n",
            "               'gradient descent (Nesterov, 1983), which they reinterpreted as '\n",
            "               'a momentum method, wasmore stable than classical momentum for '\n",
            "               'large βvalues and gave substantial speedups for trainingneural '\n",
            "               'networks. However, the reasons for the improved performance '\n",
            "               'remain somewhat mysterious.O’Donoghue & Candes (2015) proposed '\n",
            "               'to detect oscillations and eliminate them by resetting '\n",
            "               'thevelocity vector to zero. But in practice it is difﬁcult to '\n",
            "               'determine an appropriate restart condition.In this work, we '\n",
            "               'introduce Aggregated Momentum (AggMo), a variant of classical '\n",
            "               'momentum whichmaintains several velocity vectors with '\n",
            "               'different βparameters. AggMo averages the velocity vectorswhen '\n",
            "               'updating the parameters. We ﬁnd that this combines the '\n",
            "               'advantages of both small and large βvalues: the large values '\n",
            "               'allow signiﬁcant buildup of velocity along low curvature '\n",
            "               'directions, while thesmall values dampen the oscillations, '\n",
            "               'hence stabilizing the algorithm. AggMo is trivial to '\n",
            "               'implementand incurs almost no computational overhead.We draw '\n",
            "               'inspiration from the physics literature when we refer to our '\n",
            "               'method as a form of passivedamping. Resonance occurs when a '\n",
            "               'system is driven at speciﬁc frequencies but may be '\n",
            "               'preventedthrough careful design (Goldstein, 2011). Passive '\n",
            "               'damping can address this in structures by makinguse of '\n",
            "               'different materials with unique resonant frequencies. This '\n",
            "               'prevents any single frequency fromproducing catastrophic '\n",
            "               'resonance. By combining several momentum velocities together '\n",
            "               'we achieve asimilar effect — no single frequency is driving '\n",
            "               'the system and so oscillation is '\n",
            "               'prevented.1arXiv:1804.00325v3  [cs.LG]  1 May 2019Published as '\n",
            "               'a conference paper at ICLR 2019In this paper we analyze rates '\n",
            "               'of convergence on quadratic functions. We also provide '\n",
            "               'theoreticalconvergence analysis showing that AggMo achieves '\n",
            "               'converging average regret in online convex pro-gramming '\n",
            "               '(Zinkevich, 2003). To evaluate AggMo empirically we compare '\n",
            "               'against other commonlyused optimizers on a range of deep '\n",
            "               'learning architectures: deep autoencoders, convolutional '\n",
            "               'networks,and long-term short-term memory (LSTM).In all of '\n",
            "               'these cases, we ﬁnd that AggMo works as a drop-in replacement '\n",
            "               'for classical momentum, inthe sense that it works at least as '\n",
            "               'well for a given βparameter. But due to its stability at '\n",
            "               'higher βvalues, it often delivers substantially faster '\n",
            "               'convergence than both classical and Nesterov momentumwhen its '\n",
            "               'maximum βvalue is tuned.2 Background: momentum-based '\n",
            "               'optimizationClassical momentum We consider a function f : Rd '\n",
            "               '→R to be minimized with respect to somevariable θ. Classical '\n",
            "               'momentum (CM) minimizes this function by taking some initial '\n",
            "               'point θ0 andrunning the following iterative scheme,vt = βvt−1 '\n",
            "               '−∇θf(θt−1),θt = θt−1 + γtvt, (1)where γtdenotes a learning '\n",
            "               'rate schedule,βis the damping coefﬁcient and we setv0 = 0. '\n",
            "               'Momentumcan speed up convergence but it is often difﬁcult to '\n",
            "               'choose the right damping coefﬁcient, β. Evenwith momentum, '\n",
            "               'progress in a low curvature direction may be very slow. If the '\n",
            "               'damping coefﬁcientis increased to overcome this then high '\n",
            "               'curvature directions may cause instability and '\n",
            "               'oscillations.Nesterov momentum Nesterov’s Accelerated Gradient '\n",
            "               '(Nesterov, 1983; 2013) is a modiﬁedversion of the gradient '\n",
            "               'descent algorithm with improved convergence and stability. It '\n",
            "               'can be writtenas a momentum-based method (Sutskever et al., '\n",
            "               '2013),vt = βvt−1 −∇θf(θt−1 + γt−1βvt−1),θt = θt−1 + γtvt. '\n",
            "               '(2)Nesterov momentum seeks to solve stability issues by '\n",
            "               'correcting the error made after moving in thedirection of the '\n",
            "               'velocity, v. In fact, it can be shown that for a quadratic '\n",
            "               'function Nesterov momentumadapts to the curvature by '\n",
            "               'effectively rescaling the damping coefﬁcients by the '\n",
            "               'eigenvalues of thequadratic (Sutskever et al., 2013).Quadratic '\n",
            "               'convergence We begin by studying convergence on quadratic '\n",
            "               'functions, which havebeen an important test case for analyzing '\n",
            "               'convergence behavior (Sutskever et al., 2013; O’Donoghue& '\n",
            "               'Candes, 2015; Goh, 2017), and which can be considered a proxy '\n",
            "               'for optimization behavior near alocal minimum (O’Donoghue & '\n",
            "               'Candes, 2015).We analyze the behavior of these optimizers '\n",
            "               'along the eigenvectors of a quadratic function in Figure 1.In '\n",
            "               'the legend, λdenotes the corresponding eigenvalue. In (a) we '\n",
            "               'use a low damping coefﬁcient(β = 0.9) while (b) shows a high '\n",
            "               'damping coefﬁcient ( β = 0.999). When using a low '\n",
            "               'dampingcoefﬁcient it takes many iterations to ﬁnd the optimal '\n",
            "               'solution. On the other hand, increasing thedamping coefﬁcient '\n",
            "               'from 0.9 to 0.999 causes oscillations which prevent '\n",
            "               'convergence. When usingCM in practice we seek the critical '\n",
            "               'damping coefﬁcient which allows us to rapidly approach '\n",
            "               'theoptimum without becoming unstable (Goh, 2017). On the other '\n",
            "               'hand, Nesterov momentum withβ = 0.999 is able to converge more '\n",
            "               'quickly within high curvature regions than CM but '\n",
            "               'retainsoscillations for the quadratics exhibiting lower '\n",
            "               'curvature.3 Passive damping through Aggregated '\n",
            "               'MomentumAggregated Momentum We propose Aggregated Momentum '\n",
            "               '(AggMo), a variant of gradientdescent which aims to improve '\n",
            "               'stability while providing the convergence beneﬁts of larger '\n",
            "               'dampingcoefﬁcients. We modify the gradient descent algorithm '\n",
            "               'by including several velocity vectors eachwith their own '\n",
            "               'damping coefﬁcient. At each optimization step these velocities '\n",
            "               'are updated and thenaveraged to produce the ﬁnal velocity used '\n",
            "               'to update the parameters. This updated iterative procedurecan '\n",
            "               'be written as follows,2Published as a conference paper at ICLR '\n",
            "               '2019(a) CM (β = 0.9) (b) CM (β = 0.999)(c) Nesterov (β = '\n",
            "               '0.999) (d) AggMo (β = [0,0.9,0.99,0.999])Figure 1: Minimizing '\n",
            "               'a quadratic function. All optimizers use a ﬁxed learning rate '\n",
            "               'of 0.33. In the legend, λdenotes the corresponding '\n",
            "               'eigenvalues.Figure 2: Breaking oscillations with passive '\n",
            "               'damping. The arrows show the direction and relative '\n",
            "               'amplitudeof the velocities at various points in time. We '\n",
            "               'discuss points (1) and (2) in Section 3.v(i)t = β(i)v(i)t−1 '\n",
            "               '−∇θf(θt−1), for all i,θt = θt−1 + γtKK∑i=1v(i)t ,(3)where '\n",
            "               'v(i)0 = 0for each i. We refer to the vector β = [β(1),...,β '\n",
            "               '(K)] as the damping vector.By taking advantage of several '\n",
            "               'damping coefﬁcients, AggMo is able to optimize well over '\n",
            "               'ill-conditioned curvature. Figure 1 (d) shows the optimization '\n",
            "               'along the eigenvectors of a quadraticfunction using AggMo. '\n",
            "               'AggMo dampens oscillations quickly for all eigenvalues and '\n",
            "               'converges fasterthan CM and Nesterov in this case.In Figure 2 '\n",
            "               'we display the AggMo velocities during optimization. At point '\n",
            "               '(1) the velocities arealigned towards the minima, with the β = '\n",
            "               '0.999 velocity contributing substantially more to eachupdate. '\n",
            "               'By point (2) the system has begun to oscillate. While the β = '\n",
            "               '0.999 velocity is still pointedaway from the minima, the β = '\n",
            "               '0.9 velocity has changed direction and is damping the '\n",
            "               'system.Combining the velocities allows AggMo to achieve fast '\n",
            "               'convergence while reducing the impact ofoscillations caused by '\n",
            "               'large βvalues.3.1 Using AggMoChoosing the damping vector '\n",
            "               'Recall that in a direction with small but steady gradient, the '\n",
            "               'terminalvelocity is proportional to 1/(1 −β). We found that a '\n",
            "               'good choice of damping vectors was thereforeto space the '\n",
            "               'terminal velocities exponentially. To do so, we specify an '\n",
            "               'exponential scale-factor, a,and a count K. The damping vector '\n",
            "               'is then constructed as β(i) = 1−ai−1, for i = 1...K . '\n",
            "               'We3Published as a conference paper at ICLR 2019ﬁx a = 0.1 '\n",
            "               'throughout and vary only K. A good default choice is K = '\n",
            "               '3which corresponds toβ = [0,0.9,0.99]. We found this setting '\n",
            "               'to be both stable and effective in all of our '\n",
            "               'experiments.Computational/Memory overhead There is very little '\n",
            "               'additional computational overhead whenusing AggMo compared to '\n",
            "               'CM, as it only requires a handful of extra addition and '\n",
            "               'multipliciationoperations on top of the single gradient '\n",
            "               'evaluation. There is some memory overhead due to storing '\n",
            "               'theKvelocity vectors, which are each the same size as the '\n",
            "               'parameter vector. However, for most moderndeep learning '\n",
            "               'applications, the memory cost at training time is dominated by '\n",
            "               'the activations ratherthan the parameters (Gomez et al., 2017; '\n",
            "               'Chen et al., 2016; Werbos, 1990; Hochreiter & '\n",
            "               'Schmidhuber,1997), so the overhead will generally be small.4 '\n",
            "               'Recovering Nesterov momentumIn this section we show that we '\n",
            "               'can recover Nesterov Momentum (Equation 2) using a '\n",
            "               'simplegeneralization of Aggregated Momentum (Equation 3). We '\n",
            "               'now introduce separate learning rates foreach velocity, γ(i), '\n",
            "               'so that the iterate update step from Equation 3 is replaced '\n",
            "               'with,θt = θt−1 + 1KK∑i=1γ(i)t v(i)t , (4)with each velocity '\n",
            "               'updated as in Equation 3. To recover Nesterov momentum we '\n",
            "               'consider the specialcase of β = [0,β] and γ(1)t = 2γ, γ(2)t = '\n",
            "               '2βγ. The AggMo update rule can now be written as,vt = βvt−1 '\n",
            "               '−∇θf(θt−1),θt = θt−1 + γ(2)2 vt −γ(1)2 ∇θf(θt−1),= θt−1 + '\n",
            "               'γβ2vt−1 −(1 +β)γ∇θf(θt−1).(5)Similarly, we may write the '\n",
            "               'Nesterov momentum update with constant learning rate γt = '\n",
            "               'γas,vt = βvt−1 −∇θf(θt−1 + γβvt−1),θt = θt−1 + γβvt−1 '\n",
            "               '−γ∇θf(θt−1 + γβvt−1). (6)Now we consider Equation 6 when using '\n",
            "               'the reparameterization given by φt = θt + γβvt,φt −γβvt = φt−1 '\n",
            "               '−γ∇θf(φt−1),⇒φt = φt−1 + γβvt −γ∇θf(φt−1),= φt−1 + γβ2vt−1 −(1 '\n",
            "               '+β)γ∇θf(φt−1).(7)It follows that the update to φ from Nesterov '\n",
            "               'is identical to the AggMo update to θ, and we haveφ0 = θ0. We '\n",
            "               'can think of the φ reparameterization as taking a half-step '\n",
            "               'forward in the Nesterovoptimization allowing us to directly '\n",
            "               'compare the iterates at each time step. We note also that '\n",
            "               'ifγ(1)t = γ(2)t = 2γthen the equivalence holds approximately '\n",
            "               'when βis sufﬁciently close to 1. Wedemonstrate this '\n",
            "               'equivalence empirically in Appendix B.This formulation allows '\n",
            "               'us to reinterpret Nesterov momentum as a weighted average of a '\n",
            "               'gradientupdate and a momentum update. Moreover, by showing '\n",
            "               'that AggMo recovers Nesterov momentumwe gain access to the '\n",
            "               'same theoretical convergence results that Nesterov momentum '\n",
            "               'achieves.5 Convergence analysis5.1 Analyzing quadratic '\n",
            "               'convergenceWe can learn a great deal about optimizers by '\n",
            "               'carefully reasoning about their convergence on '\n",
            "               'quadraticfunctions. O’Donoghue & Candes (2015) point out that '\n",
            "               'in practice we do not know the conditionnumber of the function '\n",
            "               'to be optimized and so we aim to design algorithms which work '\n",
            "               'well over a4Published as a conference paper at ICLR 2019Figure '\n",
            "               '3: Convergence on quadratics of varying condition number.AggMo '\n",
            "               'interpolates between the conver-gence rates of CM at β = 0.9 '\n",
            "               'and β = 0.99.large possible range. Sharing this motivation, we '\n",
            "               'consider the convergence behaviour of momentumoptimizers on '\n",
            "               'quadratic functions with ﬁxed hyperparameters over a range of '\n",
            "               'condition numbers.To compute the convergence rate,||θt−θ∗||2, '\n",
            "               'we model each optimizer as a linear dynamical systemsas in '\n",
            "               'Lessard et al. (2016). The convergence rate is then determined '\n",
            "               'by the eigenvalues of this system.We leave details of this '\n",
            "               'computation to appendix B.Figure 3 displays the convergence '\n",
            "               'rate of each optimizer for quadratics with condition numbers '\n",
            "               '(κ)from 101 to 107. The blue dashed line displays the optimal '\n",
            "               'convergence rate achievable by CMwith knowledge of the '\n",
            "               'condition number — an unrealistic scenario in practice. The '\n",
            "               'two curvescorresponding to CM (red and purple) each meet the '\n",
            "               'optimal convergence rate when the conditionnumber is such that '\n",
            "               'βis critical. On the left of this critical point, where the '\n",
            "               'convergence rates forCM are ﬂat, the system is ”under-damped” '\n",
            "               'meaning there are complex eigenvalues corresponding '\n",
            "               'tooscillations.We observe that the convergence rate of AggMo '\n",
            "               'interpolates smoothly between the convergence ratesof CM with '\n",
            "               'β = 0.9 and β = 0.99 as the condition number varies. AggMo’s '\n",
            "               'ability to quickly killoscillations leads to an approximately '\n",
            "               'three-times faster convergence rate than Nesterov momentumin '\n",
            "               'the under-damped regime without sacriﬁcing performance on '\n",
            "               'larger condition numbers.5.2 Additional convergence analysisWe '\n",
            "               'evaluate the convergence rate of AggMo in the setting of '\n",
            "               'online convex programming, as proposedin Zinkevich (2003). '\n",
            "               'This is an increasingly common setting to analyze optimization '\n",
            "               'algorithmstailored to machine learning (Duchi et al., 2011; '\n",
            "               'Kingma & Ba, 2014; Reddi et al., 2018). Notably,this is '\n",
            "               'equivalent to analyzing the convergence rate in the setting of '\n",
            "               'stochastic convex optimization.We consider a sequence of '\n",
            "               'unknown convex cost functions,f1(θ),...,f T(θ). At each time '\n",
            "               't, ourgoal is to predict the parameter θt which minimizes the '\n",
            "               'regret,R(T) =T∑t=1[ft(θt) −ft(θ∗)] , (8)where θ∗is the ﬁxed '\n",
            "               'point parameter minimizing ∑Tt=1 ft(θ∗). We are able to show '\n",
            "               'that AggMohas regret bounded by O(√T) - a result '\n",
            "               'asymptotically comparable to the best known bound (Duchiet '\n",
            "               'al., 2011). We adopt the following deﬁnitions from Duchi et '\n",
            "               'al. (2011) to simplify the notation. Wewrite gt = ∇ft(θt) with '\n",
            "               'gt,i as the ith element of this vector. Additionally, we write '\n",
            "               'g1:t,i ∈Rt asthe vector containing the ith element of the '\n",
            "               'gradient over the ﬁrst titerations; g1:t,i = [g1,i,...,g '\n",
            "               't,i].Then the following theorem holds,Theorem 1. Assume that '\n",
            "               'fthas bounded gradients, ||∇ft(θ)||2 <G, ||∇ft(θ)||∞<G∞, ∀θ '\n",
            "               '∈Rd.Moreover, assume that eachθtgenerated by AggMo '\n",
            "               'satisﬁes||θn−θm||2 ≤D,||θn−θm||∞≤D∞for all m,n ∈{1,...,T }. '\n",
            "               'Let γt = γ√t and β(i)t = β(i)λt, λ∈(0,1). Then AggMo achieves '\n",
            "               'thefollowing regret bound, for all T ≥1.5Published as a '\n",
            "               'conference paper at ICLR 2019R(T) ≤D2∞√Tγ + γ√1 + '\n",
            "               'log(T)2Kd∑j=1||g1:T,j||24K∑i=11 +β(i)(1 −β(i))2 + D22Kγ(1 '\n",
            "               '−λ)2K∑i=1β(i).It immediately follows that the average regret '\n",
            "               'of AggMo converges, i.e. that R(T)/T →0, byobserving that '\n",
            "               '||g1:T,j||24 ≤G2∞√T,∀j. The full proof is given in Appendix C '\n",
            "               'alongside some openquestions on the convergence of AggMo.While '\n",
            "               'the statement of Theorem 1 requires strict assumptions we note '\n",
            "               'that this result is certainlynon-trivial. Reddi et al. (2018) '\n",
            "               'showed that the average regret of Adam (Kingma & Ba, 2014) is '\n",
            "               'notguaranteed to converge under the same assumptions.6 Related '\n",
            "               'workThe convergence of momentum methods has been studied '\n",
            "               'extensively, both theoretically and empiri-cally (Wibisono & '\n",
            "               'Wilson, 2015; Wibisono et al., 2016; Wilson et al., 2016; '\n",
            "               'Kidambi et al., 2018). Byanalyzing the failure modes of '\n",
            "               'existing methods these works motivate successful momentum '\n",
            "               'schemes.Sutskever et al. (2013) explored the effect of '\n",
            "               'momentum on the optimization of neural networksand introduced '\n",
            "               'the momentum view of Nesterov’s accelerated gradient. They '\n",
            "               'focused on producinggood momentum schedules during '\n",
            "               'optimization to adapt to ill-conditioned curvature. Despite '\n",
            "               'strongevidence that this approach works well, practitioners '\n",
            "               'today still typically opt for a ﬁxed momentumschedule and vary '\n",
            "               'the learning rate instead.In Appendix C.1 we show that AggMo '\n",
            "               'evolves as a (K+1)-th order ﬁnite difference equation, '\n",
            "               'enablingAggMo to utilize greater expressiveness over the '\n",
            "               'gradient history. Liang et al. (2016) also introducedependence '\n",
            "               'on a larger gradient history by adding lagged momentum terms. '\n",
            "               'However, in doing sothe authors introduce many new '\n",
            "               'hyperparameters to be tuned.Adaptive gradient methods have '\n",
            "               'been introduced to deal with the ill-conditioned curvature '\n",
            "               'that weoften observe in deep learning (Duchi et al., 2011; '\n",
            "               'Kingma & Ba, 2014; Zeiler, 2012; Tieleman &Hinton, 2012). '\n",
            "               'These methods typically approximate the local curvature of the '\n",
            "               'objective to adaptto the geometry of the data. Natural '\n",
            "               'gradient descent (Amari, 1998) preconditions by the '\n",
            "               'Fisherinformation matrix, which can be shown to approximate '\n",
            "               'the Hessian under certain assumptions(Martens, 2014). Several '\n",
            "               'methods have been proposed to reduce the computational and '\n",
            "               'memory costof this approach (Martens & Grosse, 2015; Martens, '\n",
            "               '2010) but these are difﬁcult to implement andintroduce '\n",
            "               'additional hyperparameters and computational overhead compared '\n",
            "               'to SGD.Another line of adaptive methods seeks to detect when '\n",
            "               'oscillations occur during optimization.O’Donoghue & Candes '\n",
            "               '(2015) proposed using an adaptive restarting scheme to remove '\n",
            "               'oscillationswhenever they are detected. In its simplest form, '\n",
            "               'this is achieved by setting the momentum velocity tozero '\n",
            "               'whenever the loss increases. Further work has suggested using '\n",
            "               'an adaptive momentum scheduleinstead of zeroing (Srinivasan et '\n",
            "               'al., 2018). Although this technique works well for '\n",
            "               'well-conditionedconvex problems it is difﬁcult to ﬁnd an '\n",
            "               'appropriate restart condition for stochastic optimizationwhere '\n",
            "               'we do not have an accurate computation of the loss. On the '\n",
            "               'other hand, AggMo’s passivedamping approach addresses the '\n",
            "               'oscillation problem without the need to detect its '\n",
            "               'occurrence.7 EvaluationWe evaluated the AggMo optimizer on the '\n",
            "               'following deep learning architectures; deep '\n",
            "               'autoencoders,convolutional networks, and LSTMs. To do so we '\n",
            "               'used four datasets: MNIST (LeCun et al.,1998), CIFAR-10, '\n",
            "               'CIFAR-100 (Krizhevsky & Hinton, 2009) and Penn Treebank '\n",
            "               '(Marcus et al.,1993). In each experiment we compared AggMo to '\n",
            "               'classical momentum, Nesterov momentum, andAdam. These '\n",
            "               'optimizers are by far the most commonly used and even today '\n",
            "               'remain very difﬁcultto outperform in a wide range of tasks. '\n",
            "               'For each method, we performed a grid search over thelearning '\n",
            "               'rate and the damping coefﬁcient. For AggMo, we keep the scale '\n",
            "               'a = 0.1 ﬁxed and varyto outperform in a wide range of tasks. '\n",
            "               'For each method, we performed a grid search over thelearning '\n",
            "               'rate and the damping coefﬁcient. For AggMo, we keep the scale '\n",
            "               'a = 0.1 ﬁxed and varyKas discussed in Section 3.1. Full '\n",
            "               'details of the experimental set up for each task can be found '\n",
            "               'inAppendix D with additional results given in Appendix E.For '\n",
            "               'each of the following experiments we choose to report the '\n",
            "               'validation and test performanceof the network in addition to '\n",
            "               'the ﬁnal training loss when it is meaningful to do so. We '\n",
            "               'includethese generalization results because recent work has '\n",
            "               'shown that the choice of optimizer may have asigniﬁcant effect '\n",
            "               'on the generalization error of the network in practice (Wilson '\n",
            "               'et al., 2017).6Published as a conference paper at ICLR '\n",
            "               '2019Optimizer Train Optimal Validation OptimalTrain Loss Val. '\n",
            "               'Loss Test LossCM 2.51 ±0.06 3.55 ±0.15 3.45 ±0.15Nesterov 1.52 '\n",
            "               '±0.02 3.20 ±0.01 3.13 ±0.02Adam 1.44 ±0.02 3.80 ±0.04 3.72 '\n",
            "               '±0.05AggMo 1.39 ±0.02 3.05 ±0.03 2.96 ±0.03Table 1: MNIST '\n",
            "               'Autoencoder We display the training MSE for the hyperparameter '\n",
            "               'setting that achieved thebest training loss. The validation '\n",
            "               'and test errors are displayed for the hyperparameter setting '\n",
            "               'that achieved thebest validation MSE. In each case the average '\n",
            "               'loss and standard deviation over 15 runs is displayed.Figure '\n",
            "               '4: Convergence of Autoencoders Trainingloss during the ﬁrst '\n",
            "               '350 epochs of training with eachoptimizer. The shaded region '\n",
            "               'corresponds to one stan-dard deviation over 15 runs.Figure 5: '\n",
            "               'Damping Coefﬁcient Investigation Opti-mizing autoencoders on '\n",
            "               'MNIST with varying damp-ing coefﬁcients and ﬁxed learning '\n",
            "               'rate. Nesterov isunstable with β = 0.999.7.1 AutoencodersWe '\n",
            "               'trained fully-connected autoencoders on the MNIST dataset '\n",
            "               'using a set-up similar to that ofSutskever et al. (2013). '\n",
            "               'While their work focused on ﬁnding an optimal momentum '\n",
            "               'schedule weinstead kept the momentum ﬁxed and applied a simple '\n",
            "               'learning rate decay schedule. For CM andNesterov we evaluated '\n",
            "               'damping coefﬁcients in the range: {0.0,0.9,0.99,0.999}. For '\n",
            "               'Adam, itis standard to use β1 = 0.9 and β2 = 0.999. Since β1 '\n",
            "               'is analogous to the momentum dampingparameter, we considered '\n",
            "               'β1 ∈{0.9,0.99,0.999}and kept β2 = 0.999. For AggMo, we '\n",
            "               'exploredKin {2,3,4 }. Each model was trained for 1000 '\n",
            "               'epochs.We report the training, validation, and test errors in '\n",
            "               'Table 1. Results are displayed for the hyperpa-rameters that '\n",
            "               'achieved the best training loss and also for those that '\n",
            "               'achieved the best validation loss.While Adam is able to '\n",
            "               'perform well on the training objective it is unable to match '\n",
            "               'the performance ofAggMo or Nesterov on the validation/test '\n",
            "               'sets. AggMo achieves the best performance in all cases.In '\n",
            "               'these experiments the optimal damping coefﬁcient for both CM '\n",
            "               'and Nesterov was β = 0.99 whilethe optimal damping vector for '\n",
            "               'AggMo was β = [0.0,0.9,0.99,0.999], given by K = 4. In Figure '\n",
            "               '4we compare the convergence of each of the optimizers under '\n",
            "               'the optimal hyperparameters for thetraining loss.Increasing '\n",
            "               'damping coefﬁcients During our experiments we observed that '\n",
            "               'AggMo remains stableduring optimization for learning rates an '\n",
            "               'order of magnitude (or more) larger than is possible for CMand '\n",
            "               'Nesterov with βequal to the max damping coefﬁcient used in '\n",
            "               'AggMo.We further investigated the effect of increasing the '\n",
            "               'maximum damping coefﬁcient of AggMo inFigure 5. The learning '\n",
            "               'rate is ﬁxed at 0.1 and we vary K from 2 to 5. We compared to '\n",
            "               'Nesterovwith damping coefﬁcients in the same range (max of '\n",
            "               '0.9999) and a ﬁxed learning rate of 0.05 (to beconsistent with '\n",
            "               'our analysis in Section 4). We do not include the curves for '\n",
            "               'which training is unstable:Nesterov with β ∈{0.999,0.9999}and '\n",
            "               'AggMo with K = 5. AggMo is able to take advantage ofthe larger '\n",
            "               'damping coefﬁcient of 0.999 and achieves the fastest overall '\n",
            "               'convergence.7.2 ClassiﬁcationFor the following experiments we '\n",
            "               'evaluated AggMo using two network architectures: a '\n",
            "               'neuralnetwork with 5 convolutional layers (CNN-5) and the '\n",
            "               'ResNet-32 architecture (He et al., 2016). Weuse data '\n",
            "               'augmentation and regularization only for the latter. Each '\n",
            "               'model was trained for 400 epochs.7Published as a conference '\n",
            "               'paper at ICLR 2019Optimizer CNN-5 (CIFAR-10) ResNet-32 '\n",
            "               '(CIFAR-10) ResNet-32 (CIFAR-100)Val. (%) Test (%) Val. (%) '\n",
            "               'Test (%) Val. (%) Test (%)CM 64.1 63.43 94.20 93.16 70.38 '\n",
            "               '70.21Nesterov 65.14 64.32 94.16 93.18 70.34 70.08Adam 63.67 '\n",
            "               '62.86 92.36 90.94 67.20 68.08AggMo 65.98 65.09 93.87 93.16 '\n",
            "               '70.28 70.11CM (β = 0.9) 64.1 63.43 94.10 93.36 70.38 '\n",
            "               '70.21Nesterov (β = 0.9) 64.13 63.04 94.16 93.18 70.34 '\n",
            "               '70.08AggMo (Default) 65.98 65.09 93.87 93.16 70.28 70.11Table '\n",
            "               '2: Classiﬁcation accuracy on CIFAR-10 and CIFAR-100 We display '\n",
            "               'results using the optimal hyper-parameters for CM, Nesterov, '\n",
            "               'Adam and AggMo on the validation set and also with default '\n",
            "               'settings for CM,Nesterov and AggMo.Figure 6: ResNet-32 Trained '\n",
            "               'On CIFAR-100 The training loss and validation accuracy during '\n",
            "               'training onCIFAR-100 for each optimizer.For each optimizer we '\n",
            "               'report the accuracy on a randomly held out validation set and '\n",
            "               'the test set.All of the models achieve near-perfect accuracy '\n",
            "               'on the training set and so we do not report this.The results '\n",
            "               'are displayed in Table 2. On the small convolutional network '\n",
            "               'without regularization,AggMo signiﬁcantly out performed the '\n",
            "               'other methods. For both of the ResNet-32 experiments '\n",
            "               'weobserved the best validation accuracy with CM. This is '\n",
            "               'perhaps expected as the model architectureand hyperparameters '\n",
            "               'were likely to have been tuned using CM. Despite this, we '\n",
            "               'observed that AggMoperformed consistently well and had the '\n",
            "               'fastest overall convergence.We found that our proposed default '\n",
            "               'hyperparameters for AggMo (a= 0.1, K = 3) led to much '\n",
            "               'fasterconvergence than CM and Nesterov with β = 0.9, a common '\n",
            "               'default choice. Figure 6 shows thetraining loss and validation '\n",
            "               'accuracy during training for each optimizer used to train the '\n",
            "               'ResNet-32 model. The hyperparameters used for each plot are '\n",
            "               'those which obtained the best validationaccuracy. AggMo '\n",
            "               'converged most quickly on the training objective without '\n",
            "               'sacriﬁcing ﬁnal validationperformance.Surprisingly, we found '\n",
            "               'that using AggMo we were also able to train the ResNet-32 '\n",
            "               'architecture onCIFAR-100 without using batch normalization. '\n",
            "               'With a limited search over learning rates we achieved69.32% '\n",
            "               'test error compared to a best value of 67.26% using CM. We '\n",
            "               'also found that, with batchnormalization removed, optimization '\n",
            "               'with AggMo remained stable at larger learning rates than '\n",
            "               'withCM.We note that the additional network hyperparameters '\n",
            "               '(e.g. weight decay) are defaults which werelikely picked as '\n",
            "               'they work well with classical momentum. This may disadvantage '\n",
            "               'the other optimizers,including our own. Despite this, we found '\n",
            "               'that we are able to outperform CM with the AggMo andNesterov '\n",
            "               'optimizers without additional tuning of any of these '\n",
            "               'hyperparameters.7.3 Language modelingWe trained LSTM Language '\n",
            "               'Models on the Penn Treebank dataset. We followed the '\n",
            "               'experimentalsetup of Merity et al. (2017) and made use of the '\n",
            "               'code provided by the authors. We used the '\n",
            "               'optimalhyperparameter settings described by the authors and '\n",
            "               'vary only the learning rate, momentum andwhether gradient '\n",
            "               'clipping is used. The network hyperparameters were tuned using '\n",
            "               'SGD and maynot be optimal for the other optimizers we evaluate '\n",
            "               '(including our own). We followed only the basemodel training '\n",
            "               'used in Merity et al. (2017) and do not include the ﬁne-tuning '\n",
            "               'and continuous cacheoptimization steps. Each model was trained '\n",
            "               'for 750 epochs.As noted in Merity et al. (2017), it is '\n",
            "               'typically observed that SGD without momentum performsbetter '\n",
            "               'than momentum-based methods in language modeling tasks. '\n",
            "               'However, in our experiments we8Published as a conference paper '\n",
            "               'at ICLR 2019Figure 7: Convergence of LSTM The training and '\n",
            "               'validation perplexity during training. For each model weuse '\n",
            "               'the hyperparameters that obtained the best validation loss. We '\n",
            "               'found that there was very little differencewhen choosing '\n",
            "               'hyperparameters based on training performance.Optimizer Train '\n",
            "               'Perplexity Val. Perplexity Test Perplexity*SGD + ASGD 35.68 '\n",
            "               '61.17 59.26SGD 35.34 63.39 62.41CM 50.34 70.37 68.21Nesterov '\n",
            "               '34.91 60.84 58.44Adam 32.88 60.25 57.83AggMo 33.22 60.36 '\n",
            "               '57.79Table 3: Penn Treebank LSTMPerplexity across different '\n",
            "               'optimizers. We display the train, validation, and testerror '\n",
            "               'for the optimization run that produced the best validation '\n",
            "               'loss. * uses ASGD (Polyak & Juditsky, 1992)and corresponds to '\n",
            "               'the base model reported in Merity et al. (2017)observed all '\n",
            "               'momentum-based optimizers but CM outperform SGD without '\n",
            "               'momentum. Surprisingly,we found that Adam is well-suited to '\n",
            "               'this task and achieves the best training, validation, and '\n",
            "               'testperformance. We believe that the heavy regularization used '\n",
            "               'when training the network makes Adama good choice. AggMo is '\n",
            "               'very close in terms of ﬁnal performance to Adam.Table 3 '\n",
            "               'contains the results for the hyperparameter settings which '\n",
            "               'achieved the best validation errorfor each optimizer. The ﬁrst '\n",
            "               'row (denoted *) uses the scheme suggested in Merity et al. '\n",
            "               '(2017): oncethe validation loss plateaus we switch to the ASGD '\n",
            "               '(Polyak & Juditsky, 1992) optimizer. The otherrows instead '\n",
            "               'decay the learning rate when the validation loss '\n",
            "               'plateaus.Figure 7 compares the convergence of the training and '\n",
            "               'validation perplexity of each optimizer. Whilethe momentum '\n",
            "               'methods converge after 300 epochs, the momentum-free methods '\n",
            "               'converged muchmore slowly. Surprisingly, we found that SGD '\n",
            "               'worked best without any learning rate decay. Adamconverged '\n",
            "               'most quickly and achieved a validation perplexity which is '\n",
            "               'comparable to that of AggMo.While gradient clipping is '\n",
            "               'critical for SGD without momentum, which utilizes a large '\n",
            "               'learning rate,we found that all of the momentum methods '\n",
            "               'perform better without gradient clipping.In short, while '\n",
            "               'existing work encourages practitioners to avoid classical '\n",
            "               'momentum we found thatusing other momentum methods may '\n",
            "               'signiﬁcantly improve convergence rates and ﬁnal '\n",
            "               'performance.AggMo worked especially well on this task over a '\n",
            "               'large range of damping coefﬁcients and learningrates.8 '\n",
            "               'ConclusionAggregated Momentum is a simple extension to '\n",
            "               'classical momentum which is easy to implement andhas '\n",
            "               'negligible computational overhead on modern deep learning '\n",
            "               'tasks. We showed empirically thatAggMo is able to remain '\n",
            "               'stable even with large damping coefﬁcients and enjoys faster '\n",
            "               'convergencerates as a consequence of this. Nesterov momentum '\n",
            "               'can be viewed as a special case of AggMo.(Incidentally, we '\n",
            "               'found that despite its lack of adoption by deep learning '\n",
            "               'practitioners, Nesterovmomentum also showed substantial '\n",
            "               'advantages compared to classical momentum.) On the tasks '\n",
            "               'weexplored, AggMo could be used as a drop-in replacement for '\n",
            "               'existing optimizers with little-to-noadditional hyperparameter '\n",
            "               'tuning. But due to its stability at higher β values, it often '\n",
            "               'deliveredsubstantially faster convergence than both classical '\n",
            "               'and Nesterov momentum.9Published as a conference paper at ICLR '\n",
            "               '20199 AcknowledgementsWe would like to thank Geoffrey Hinton '\n",
            "               'for suggesting the link between AggMo and passive dampingin '\n",
            "               'physical systems. We also thank Paul Vicol for his help with '\n",
            "               'the LSTM experiments. Finally, wethank our many other '\n",
            "               'colleagues for useful discussions and insights. James Lucas is '\n",
            "               'supported by anNSERC research grant. Shengyang Sun is '\n",
            "               'supported by a Connaught New Researcher Award and aConnaught '\n",
            "               'Fellowship.ReferencesShun-Ichi Amari. Natural gradient works '\n",
            "               'efﬁciently in learning. Neural computation, '\n",
            "               '10(2):251–276,1998.Tianqi Chen, Bing Xu, Chiyuan Zhang, and '\n",
            "               'Carlos Guestrin. Training deep nets with sublinearmemory cost. '\n",
            "               'arXiv preprint arXiv:1604.06174, 2016.John Duchi, Elad Hazan, '\n",
            "               'and Yoram Singer. Adaptive subgradient methods for online '\n",
            "               'learning andstochastic optimization. Journal of Machine '\n",
            "               'Learning Research, 12(Jul):2121–2159, 2011.Gabriel Goh. Why '\n",
            "               'momentum really works. Distill, 2(4):e6, 2017.Herbert '\n",
            "               'Goldstein. Classical mechanics. Pearson Education India, '\n",
            "               '2011.Aidan N Gomez, Mengye Ren, Raquel Urtasun, and Roger B '\n",
            "               'Grosse. The reversible residual network:Backpropagation '\n",
            "               'without storing activations. In Advances in Neural Information '\n",
            "               'ProcessingSystems, pp. 2211–2221, 2017.Kaiming He, Xiangyu '\n",
            "               'Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for '\n",
            "               'imagerecognition. In Proceedings of the IEEE conference on '\n",
            "               'computer vision and pattern recognition,pp. 770–778, 2016.Sepp '\n",
            "               'Hochreiter and J ¨urgen Schmidhuber. Long short-term memory. '\n",
            "               'Neural computation, 9(8):1735–1780, 1997.Sergey Ioffe and '\n",
            "               'Christian Szegedy. Batch normalization: Accelerating deep '\n",
            "               'network training byreducing internal covariate shift. arXiv '\n",
            "               'preprint arXiv:1502.03167, 2015.Rahul Kidambi, Praneeth '\n",
            "               'Netrapalli, Prateek Jain, and Sham M Kakade. On the '\n",
            "               'insufﬁciency ofexisting momentum schemes for stochastic '\n",
            "               'optimization. arXiv preprint arXiv:1803.05591, 2018.Diederik '\n",
            "               'Kingma and Jimmy Ba. Adam: A method for stochastic '\n",
            "               'optimization. arXiv preprintarXiv:1412.6980, 2014.Alex '\n",
            "               'Krizhevsky and Geoffrey Hinton. Learning multiple layers of '\n",
            "               'features from tiny images. 2009.Yann LeCun, L´eon Bottou, '\n",
            "               'Yoshua Bengio, and Patrick Haffner. Gradient-based learning '\n",
            "               'applied todocument recognition. Proceedings of the IEEE, '\n",
            "               '86(11):2278–2324, 1998.Laurent Lessard, Benjamin Recht, and '\n",
            "               'Andrew Packard. Analysis and design of optimizationalgorithms '\n",
            "               'via integral quadratic constraints. SIAM Journal on '\n",
            "               'Optimization, 26(1):57–95, 2016.Jingwei Liang, Jalal Fadili, '\n",
            "               'and Gabriel Peyr ´e. A multi-step inertial forward-backward '\n",
            "               'splittingmethod for non-convex optimization. In Advances in '\n",
            "               'Neural Information Processing Systems, pp.4035–4043, '\n",
            "               '2016.Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beatrice '\n",
            "               'Santorini. Building a large annotatedcorpus of english: The '\n",
            "               'penn treebank. Computational linguistics, 19(2):313–330, '\n",
            "               '1993.James Martens. Deep learning via hessian-free '\n",
            "               'optimization. In ICML, volume 27, pp. 735–742,2010.James '\n",
            "               'Martens. New insights and perspectives on the natural gradient '\n",
            "               'method. arXiv preprintarXiv:1412.1193, 2014.10Published as a '\n",
            "               'conference paper at ICLR 2019James Martens and Roger Grosse. '\n",
            "               'Optimizing neural networks with kronecker-factored '\n",
            "               'approximatecurvature. In International conference on machine '\n",
            "               'learning, pp. 2408–2417, 2015.Stephen Merity, Nitish Shirish '\n",
            "               'Keskar, and Richard Socher. Regularizing and optimizing '\n",
            "               'lstmlanguage models. arXiv preprint arXiv:1708.02182, '\n",
            "               '2017.Yurii Nesterov. A method of solving a convex programming '\n",
            "               'problem with convergence rate o (1/k2).volume 27, pp. 372–367, '\n",
            "               '1983.Yurii Nesterov. Introductory lectures on convex '\n",
            "               'optimization: A basic course, volume 87. SpringerScience & '\n",
            "               'Business Media, 2013.Brendan O’Donoghue and Emmanuel Candes. '\n",
            "               'Adaptive restart for accelerated gradient schemes.Foundations '\n",
            "               'of computational mathematics, 15(3):715–732, 2015.Adam Paszke, '\n",
            "               'Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, '\n",
            "               'Zachary DeVito,Zeming Lin, Alban Desmaison, Luca Antiga, and '\n",
            "               'Adam Lerer. Automatic differentiation inpytorch. 2017.Boris T '\n",
            "               'Polyak. Some methods of speeding up the convergence of '\n",
            "               'iteration methods. USSRComputational Mathematics and '\n",
            "               'Mathematical Physics, 4(5):1–17, 1964.Boris T Polyak and '\n",
            "               'Anatoli B Juditsky. Acceleration of stochastic approximation '\n",
            "               'by averaging.SIAMJournal on Control and Optimization, '\n",
            "               '30(4):838–855, 1992.Sashank J. Reddi, Satyen Kale, and Sanjiv '\n",
            "               'Kumar. On the convergence of adam and beyond. InInternational '\n",
            "               'Conference on Learning Representations, 2018. URL '\n",
            "               'https://openreview.net/forum?id=ryQu7f-RZ.Vishwak Srinivasan, '\n",
            "               'Adepu Ravi Sankar, and Vineeth N Balasubramanian. Adine: an '\n",
            "               'adaptivemomentum method for stochastic gradient descent. In '\n",
            "               'Proceedings of the ACM India JointInternational Conference on '\n",
            "               'Data Science and Management of Data, pp. 249–256. ACM, '\n",
            "               '2018.Weijie Su, Stephen Boyd, and Emmanuel Candes. A '\n",
            "               'differential equation for modeling nesterovsaccelerated '\n",
            "               'gradient method: Theory and insights. In Advances in Neural '\n",
            "               'Information ProcessingSystems, pp. 2510–2518, 2014.Ilya '\n",
            "               'Sutskever, James Martens, George Dahl, and Geoffrey Hinton. On '\n",
            "               'the importance of initializationand momentum in deep learning. '\n",
            "               'In International conference on machine learning, pp. '\n",
            "               '1139–1147,2013.Tijmen Tieleman and Geoffrey Hinton. Lecture '\n",
            "               '6.5-rmsprop: Divide the gradient by a runningaverage of its '\n",
            "               'recent magnitude. COURSERA: Neural networks for machine '\n",
            "               'learning, 4(2):26–31,2012.Paul J Werbos. Backpropagation '\n",
            "               'through time: what it does and how to do it. Proceedings of '\n",
            "               'theIEEE, 78(10):1550–1560, 1990.Andre Wibisono and Ashia C '\n",
            "               'Wilson. On accelerated methods in optimization. arXiv '\n",
            "               'preprintarXiv:1509.03616, 2015.Andre Wibisono, Ashia C Wilson, '\n",
            "               'and Michael I Jordan. A variational perspective on '\n",
            "               'acceleratedmethods in optimization. Proceedings of the '\n",
            "               'National Academy of Sciences, 113(47):E7351–E7358,2016.Ashia C '\n",
            "               'Wilson, Benjamin Recht, and Michael I Jordan. A lyapunov '\n",
            "               'analysis of momentum methodsin optimization. arXiv preprint '\n",
            "               'arXiv:1611.02635, 2016.Ashia C Wilson, Rebecca Roelofs, '\n",
            "               'Mitchell Stern, Nati Srebro, and Benjamin Recht. The '\n",
            "               'marginalvalue of adaptive gradient methods in machine '\n",
            "               'learning. In Advances in Neural InformationProcessing Systems, '\n",
            "               'pp. 4151–4161, 2017.Matthew D Zeiler. Adadelta: an adaptive '\n",
            "               'learning rate method. arXiv preprint '\n",
            "               'arXiv:1212.5701,2012.Martin Zinkevich. Online convex '\n",
            "               'programming and generalized inﬁnitesimal gradient ascent. '\n",
            "               'InProceedings of the 20th International Conference on Machine '\n",
            "               'Learning (ICML-03), pp. 928–936,2003.11Published as a '\n",
            "               'conference paper at ICLR 2019AppendicesA Nesterov '\n",
            "               'EquivalenceIn this section we demonstrate this equivalence on '\n",
            "               'two toy problems. In each of the ﬁgures includedhere we take β '\n",
            "               '= 0.999.We ﬁrst consider a 2D quadratic function,f(x) =xTAx, '\n",
            "               'where Ahas eigenvalues 1.0 and 0.001.Thelearning rates for '\n",
            "               'each optimizer are set as described in Section 4. Each '\n",
            "               'optimizer is initialized at thesame position. Figure 8 shows '\n",
            "               'both optimizers following the same optimization trajectories. '\n",
            "               'In thissetting, the two paths are also visually '\n",
            "               'indistinguishable with γ(1)t = γ(2)t = 2γfor AggMo.Figure 8: '\n",
            "               'Equivalence of Nesterov and AggMo when β = 0.999. The '\n",
            "               'optimization plots for f(x) =xT Ax arevisibly identical '\n",
            "               '(circles correspond to AggMo and squares to Nesterov - the '\n",
            "               'markers are offset for readability).We now optimize the '\n",
            "               'Rosenbrock function, given by,f(x,y) = (y−x2)2 + 100(x−1)2This '\n",
            "               'function has a global minimum at (x,y) = 1. Once again the '\n",
            "               'optimizers are initialized atthe same point but for this '\n",
            "               'example we take γ(1)t = γ(2)t = 2γ for AggMo. Figure 9 '\n",
            "               'showsthe optimization trajectories of both algorithms. In this '\n",
            "               'case we see that the updates are initiallyindistinguishable '\n",
            "               'but begin to differ as the algorithms approach the origin.B '\n",
            "               'Quadratic Convergence AnalysisIn this section we present '\n",
            "               'details of the convergence rate computations in Figure 3. We '\n",
            "               'also presentsome additional supporting results.We ﬁrst note '\n",
            "               'that for quadratic functions of the formf(x) =12xTAx+bTx we '\n",
            "               'can write the AggMooptimization procedure as a linear '\n",
            "               'dynamical systems in K+ '\n",
            "               '1variables:\\uf8ee\\uf8ef\\uf8ef\\uf8ef\\uf8f0v(1)t+1...v(K)t+1xt+1 '\n",
            "               '−x∗\\uf8f9\\uf8fa\\uf8fa\\uf8fa\\uf8fb= '\n",
            "               'B\\uf8ee\\uf8ef\\uf8ef\\uf8ef\\uf8f0v(1)t...v(K)txt '\n",
            "               '−x∗\\uf8f9\\uf8fa\\uf8fa\\uf8fa\\uf8fb12Published as a conference '\n",
            "               'paper at ICLR 2019Figure 9: Approximate equivalence of '\n",
            "               'Nesterov and AggMo when β = 0.999. The optimization '\n",
            "               'trajectories areinitially visibly identical but begin to '\n",
            "               'differ slightly after more iterations.The spectral norm of the '\n",
            "               'matrixBdetermines the rate at which the linear dynamical '\n",
            "               'system convergesand thus bounds ||xt −x∗||2 (Lessard et al., '\n",
            "               '2016). We can write down the exact form of B asfollows,B '\n",
            "               '=\\uf8ee\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f0β(1)I '\n",
            "               '0 ··· 0 −A0 β(2)I ... ... ...... ... ... 0 −A0 ··· 0 β(K)I '\n",
            "               '−Aγβ(1)K I γβ(2)K I ··· γβ(K)K I '\n",
            "               '(I−γA)\\uf8f9\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fbWe '\n",
            "               'note in particular that in the special case of K = 1(CM) we '\n",
            "               'recover the characteristic equationof O’Donoghue & Candes '\n",
            "               '(2015):u2 −(1 +β−γλi)u+ β = 0Which in turn yields the critical '\n",
            "               'damping coefﬁcient and optimal rate, withβ∗=(√κ−1√κ+ 1)2.When '\n",
            "               'β <β∗the system is over-damped and exhibits slow monotone '\n",
            "               'convergence (Figure 1 (a)).When β >β∗the system is '\n",
            "               'under-damped and the characteristic equation yields imaginary '\n",
            "               'solutionsthat correspond to oscillations (Figure 1 (b)) with '\n",
            "               'convergence rate equal to 1 −|β|. At the criticaldamping '\n",
            "               'coefﬁcient the convergence is optimal at 1.0 −√κ−1√κ+ 1.We can '\n",
            "               'combine this analysis with Theorem 2 from Sutskever et al. '\n",
            "               '(2013) to recover similarconvergence bounds for Nesterov '\n",
            "               'momentum.Producing Figure 3 To produce the curves in Figure 3 '\n",
            "               'we compute the eigenvalues directly fromthe matrix Bfor '\n",
            "               'matrices Awith varying condition numbers. While we can ﬁnd the '\n",
            "               'optimal learningrate for CM and Nesterov momentum in closed '\n",
            "               'form we have been unable to do so for AggMo.Therefore, we '\n",
            "               'instead perform a ﬁne-grained grid search to approximate the '\n",
            "               'optimal learning rate foreach condition number.13Published as '\n",
            "               'a conference paper at ICLR 2019(a) CM β = 0.999 (b) Nesterov β '\n",
            "               '= 0.999(c) AggMo β = [0,0.9,0.999]Figure 10: Velocity during '\n",
            "               'quadratic optimization with CM, Nesterov, and AggMo. (Best '\n",
            "               'viewed in color)The shaded region shows the direction and '\n",
            "               'relative magnitude of the velocities throughout optimization '\n",
            "               'for eachoptimizer. AggMo has multiple shaded regions '\n",
            "               'corresponding to the different velocities.Studying Velocity We '\n",
            "               'now present a brief study illustrating how using multiple '\n",
            "               'velocities canbreak oscillations during optimization.Figure 10 '\n",
            "               'shows the optimization of a 1-D quadratic function with CM, '\n",
            "               'Nesterov, and AggMo. Theshaded region around each curve '\n",
            "               'represents the direction and relative magnitude of the '\n",
            "               'velocitiesterm during optimization. CM (a) has a single '\n",
            "               'velocity and oscillates at a near-constant amplitude.For '\n",
            "               'Nesterov momentum (b) we display the velocity and the '\n",
            "               '”error-correcting” term. AggMo (c)has shaded regions for each '\n",
            "               'velocity. For AggMo, the velocity with β = 0.9 oscillates at a '\n",
            "               'higherfrequency and thus damps the whole system.C Convergence '\n",
            "               'ProofHere we present the proof of Theorem 5 1. We introduce '\n",
            "               'some simplifying notation used in Duchiet al. (2011). We write '\n",
            "               'gt = ∇f(θt), with gt,i denoting the ith element of the vector '\n",
            "               'gt. We furtherwrite g1:t,i ∈Rt for the ith dimension of '\n",
            "               'gradients up to iteration t.We begin with the following '\n",
            "               'lemma,Lemma 1. We write vit,j to indicate the jth element of '\n",
            "               'the ith velocity at time t. Assume gt isbounded, then the '\n",
            "               'following holds for all j,T∑t=1K∑i=1v(i)t,j2√t ≤||g1:T,j||24√1 '\n",
            "               '+ log(T)K∑i=11(1 −β(i))2Proof We begin by expanding the last '\n",
            "               'term in the sum using the update equations,14Published as a '\n",
            "               'conference paper at ICLR 2019T∑t=1K∑i=1v(i)t,j2√t '\n",
            "               '=T−1∑t=1K∑i=1v(i)t,j2√t + 1√TK∑i=1( T∑h=1(β(i)h '\n",
            "               ')T−hgh,j)2≤T−1∑t=1K∑i=1v(i)t,j2√t + 1√TK∑i=1( T∑h=1(β(i))T−h)( '\n",
            "               'T∑h=1(β(i))T−hg2h,j)≤T−1∑t=1K∑i=1v(i)t,j2√t + 1√TK∑i=111 '\n",
            "               '−β(i)( T∑h=1(β(i))T−hg2h,j)The ﬁrst inequality is obtained via '\n",
            "               'Cauchy-Schwarz and by noting that β(i)t ≤βfor all t. The '\n",
            "               'secondinequality follows directly from the fact that '\n",
            "               '∑Th=1(β(i))T−h < 1/(1 −β(i)). We can apply thisupper bound to '\n",
            "               'each term of the sum over t,T∑t=1K∑i=1v(i)t,j2√t '\n",
            "               '≤T∑t=1K∑i=11√t(1 −β(i))t∑h=1(β(i))t−hg2h,j=K∑i=111 '\n",
            "               '−β(i)T∑t=11√tt∑h=1(β(i))t−hg2h,j=K∑i=111 '\n",
            "               '−β(i)T∑t=1g2t,jT∑h=t(β(i))h−t√h≤K∑i=111 '\n",
            "               '−β(i)T∑t=1g2t,jT∑h=t(β(i))h−t√t≤K∑i=11(1 '\n",
            "               '−β(i))2T∑t=1g2t,j1√t≤K∑i=11(1 −β(i))2 '\n",
            "               '||g1:T,j||24\\ued6a\\ued6b\\ued6b√T∑t=11t≤||g1:T,j||24√1 + '\n",
            "               'log(T)K∑i=11(1 −β(i))2Under equality we swap the order of sums '\n",
            "               'and collect terms under gt. The third inequality followsfrom '\n",
            "               '∑tj=1(β(i))j−t <1/(1 −β). The fourth inequality is an '\n",
            "               'application of Cauchy-Schwarz. Theﬁnal inequality is from the '\n",
            "               'harmonic sum bound: ∑Tt=1 1/t≤1 + log(T). This completes the '\n",
            "               'proof.Proof of Theorem 1 From the update equations we may '\n",
            "               'write,θt+1 = θt + γtKK∑i=1v(i)t= θt + γtKK∑i=1(β(i)t v(i)t−1 '\n",
            "               '−gt)We now shift focus to only the jth dimension. We subtract '\n",
            "               'θ∗j from both sides and square,15Published as a conference '\n",
            "               'paper at ICLR 2019(θt+1,j −θ∗j)2 = (θt,j −θ∗j)2 + 2γtK(θt,j '\n",
            "               '−θ∗j)K∑i=1(β(i)t v(i)t−1,j −gt,j) + γ2tK2 (K∑i=1v(i)t,j)2We '\n",
            "               'can rearrange this expression and bound as follows,gt,j(θt,j '\n",
            "               '−θ∗j) = 12γt[(θt,j −θ∗j)2 −(θt+1,j −θ∗j)2]+ (θt,j −θ∗j) '\n",
            "               '1KK∑i=1(β(i)t v(i)t−1,j) + γt2K2 (K∑i=1v(i)t,j)2= 12γt[(θt,j '\n",
            "               '−θ∗j)2 −(θt+1,j −θ∗j)2]+ 1KK∑i=1(θt,j −θ∗j)(β(i)t v(i)t−1,j) + '\n",
            "               'γt2K2 (K∑i=1v(i)t,j)2= 12γt[(θt,j −θ∗j)2 −(θt+1,j −θ∗j)2]+ '\n",
            "               '1KK∑i=1√β(i)t√γt−1(θt,j −θ∗j)√γt−1β(i)t (v(i)t−1,j)+ γt2K2 '\n",
            "               '(K∑i=1v(i)t,j)2≤ 12γt[(θt,j −θ∗j)2 −(θt+1,j −θ∗j)2]+ '\n",
            "               '1KK∑i=1β(i)t2γt−1(θt,j −θ∗j)2+ 1KK∑i=1γt−12 β(i)t (v(i)t−1,j)2 '\n",
            "               '+ γt2K2 (K∑i=1v(i)t,j)2≤ 12γt[(θt,j −θ∗j)2 −(θt+1,j −θ∗j)2]+ '\n",
            "               '1KK∑i=1β(i)t2γt−1(θt,j −θ∗j)2+ 1KK∑i=1γt−12 β(i)t (v(i)t−1,j)2 '\n",
            "               '+ γt2KK∑i=1(v(i)t,j)2The ﬁrst inequality is an application of '\n",
            "               'Young’s inequality. For the second inequality we use '\n",
            "               'thesum-of-squares inequality. We now make use of convexity, '\n",
            "               'and take the sum over dimensions andtime,16Published as a '\n",
            "               'conference paper at ICLR 2019T∑t=1ft(θt) −ft(θ∗) '\n",
            "               '≤T∑t=1d∑j=1gt,j(θt,j −θ∗j)≤T∑t=1d∑j=112γt[(θt,j −θ∗j)2 '\n",
            "               '−(θt+1,j −θ∗j)2]+ 1KK∑i=1β(i)t2γt−1(θt,j −θ∗j)2+ 1KK∑i=1γt−12 '\n",
            "               'β(i)t (v(i)t−1,j)2 + γt2KK∑i=1(v(i)t,j)2≤d∑j=112γ1(θ1,j −θ∗j)2 '\n",
            "               '+ 12d∑j=1T∑t=1(θt,j −θ∗j)2( 1γt− 1γt−1)+ γ√1 + '\n",
            "               'log(T)2Kd∑j=1||g1:T,j||24K∑i=11 +β(i)(1 −β(i))2+ '\n",
            "               '1KK∑i=1d∑j=1T∑t=1β(i)t2γt−1(θt,j −θ∗j)2We now make use of the '\n",
            "               'bounding assumptions, ||θm −θn||2 ≤Dand ||θm −θn||∞≤D∞,R(T) '\n",
            "               '≤D2∞√Tγ + γ√1 + log(T)2Kd∑j=1||g1:T,j||24K∑i=11 +β(i)(1 '\n",
            "               '−β(i))2 + D22γ1KK∑i=1T∑t=1β(i)λt−1√tThe ﬁrst two terms are '\n",
            "               'collapsed using a telescoping sum. Using ∑tλt−1√t ≤1/(1 −λ)2, '\n",
            "               'weachieve the following bound,R(T) ≤D2∞√Tγ + γ√1 + '\n",
            "               'log(T)2Kd∑j=1||g1:T,j||24K∑i=11 +β(i)(1 −β(i))2 + D22Kγ(1 '\n",
            "               '−λ)2K∑i=1β(i)C.1 Open Questions on ConvergenceWhile studying '\n",
            "               'the convergence properties of AggMo we made several '\n",
            "               'interesting observations whichpresented theoretical '\n",
            "               'challenges. We present some of these observations here to shed '\n",
            "               'light on keydifferences between AggMo and existing momentum '\n",
            "               'methods. We hope that these will provokefurther study.Further '\n",
            "               'reduction of B In Appendix B we derived the matrix B in order '\n",
            "               'to get bounds on theconvergence. We can further reduce Bto '\n",
            "               'block diagonal form, where the jth block takes the form,Bj '\n",
            "               '=\\uf8ee\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f0β(1) '\n",
            "               '0 ··· 0 −λj0 β(2) ... ... ...... ... ... 0 −λj0 ··· 0 β(K) '\n",
            "               '−λjγβ(1)Kγβ(2)K ··· γβ(K)K (1 '\n",
            "               '−γλj)\\uf8f9\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fbFrom '\n",
            "               'this relatively simple form we may be able to derive a '\n",
            "               'closed-form solution for the eigenvalueswhich would allow us '\n",
            "               'to reason theoretically about the quadratic convergence '\n",
            "               'properties of AggMo.An easier goal would be ﬁnding suitable '\n",
            "               'conditions under which the eigenvalues are complex and '\n",
            "               'thesystem is under-damped.17Published as a conference paper at '\n",
            "               'ICLR 2019Finite Difference Equation In this section we '\n",
            "               'demonstrate that the dynamics of AggMo can bewritten as a (K+ '\n",
            "               '1)-th order ﬁnite difference equation. While most momentum '\n",
            "               'methods can beviewed as the discretization of second order '\n",
            "               'ODEs (Wilson et al., 2016) it seems that AggMo does notfall '\n",
            "               'into this class of algorithms. As a consequence, it becomes '\n",
            "               'difﬁcult to apply existing convergenceproof techniques to '\n",
            "               'AggMo.For simplicity, we assume a ﬁxed learning rate γfor all '\n",
            "               'time steps. We will ﬁrst tackle the specialcase K = 2. From '\n",
            "               'the AggMo update rule, we '\n",
            "               'have\\uf8ee\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f0v(1)t+1v(2)t+1v(1)tv(2)tv(1)t−1v(2)t−1\\uf8f9\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fb=\\uf8ee\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f00 '\n",
            "               '0 β1 0 0 00 0 0 β2 0 00 0 0 0 β1 00 0 0 0 0 β20 0 γKγK 1 00 0 '\n",
            "               '0 0 γK 1 + '\n",
            "               'γK\\uf8f9\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fb\\uf8ee\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f0v(1)t+1v(2)t+1v(1)tv(2)tv(1)t−1v(2)t−1\\uf8f9\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fb−\\uf8ee\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f0∇θf(θt)∇θf(θt)∇θf(θt−1)∇θf(θt−1)θt '\n",
            "               '−θt−1θt−1 −θt−2\\uf8f9\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fb(9)Denoting '\n",
            "               'the matrices as symbols correspondingly, it becomes v = Bv −g, '\n",
            "               'thereforev = −(I −B)−1g (10)Denote δt = θt−θ⋆, then θt−θt−1 = '\n",
            "               'δt−δt−1. Note that θt+1 = θt+ γt+12 (v(1)t+1 +v(2)t+1), '\n",
            "               'pluggingEq 10 into it, we haveδt+1 = δt −γ2 [1,1,0,0,···]⊤(I '\n",
            "               '−B)−1g (11)Which reduces to the following ﬁnite difference '\n",
            "               'equation,δt+1 = (1+β1 +β2)δt+(β1 +β2 +β1β2)δt−1 −β1β2δt−2 + γ2 '\n",
            "               '(2∇θf(θt)−(β1 +β2)∇θf(θt−1))(12)For K ≥2, we only need to '\n",
            "               'change Eq 9 accordingly, follow the remaining derivations, and '\n",
            "               'recover a(K+1)-th order difference equation. We could also '\n",
            "               'derive the same result using sequence elimination,made simpler '\n",
            "               'with some sensible variable substitutions.This result is of '\n",
            "               'considerable importance. Existing momentum methods can '\n",
            "               'generally be rewritten asa second order difference equation '\n",
            "               '(Section 2 in O’Donoghue & Candes (2015)) which then inducea '\n",
            "               'second order ODE (Su et al., 2014; Wibisono & Wilson, 2015). '\n",
            "               'The momentum optimizationprocedure can then be thought of as a '\n",
            "               'discretization of a Hamiltonian ﬂow. On the other hand, '\n",
            "               'AggModoes not obviously lend itself to the analytical tools '\n",
            "               'developed in this setting - it is not obviouswhether the form '\n",
            "               'in AggMo is indeed a discretization of a Hamiltonian ﬂow.D '\n",
            "               'ExperimentsAll of our experiments are conducted using the '\n",
            "               'pytorch library Paszke et al. (2017). In each experimentwe '\n",
            "               'make use of early stopping to determine the run with the best '\n",
            "               'validation performance.D.1 AutoencodersFor the autoencoders we '\n",
            "               'train fully connected networks with encoders using the '\n",
            "               'following architecture:784-1000-500-250-30. The decoder '\n",
            "               'reverses this architecture. We use relu activations throughout '\n",
            "               'thenetwork. We train for a total of 1000 epochs using a '\n",
            "               'multiplicative learning rate decay of 0.1 at 200,400, and 800 '\n",
            "               'epochs. We train using batch sizes of 200.For these '\n",
            "               'experiments the training set consists of 90% of the training '\n",
            "               'data with the remaining 10%being used for validation.For each '\n",
            "               'optimizer we searched over the following range of learning '\n",
            "               'rates: {0.1, 0.05, 0.01, 0.005,0.001, 0.0005, 0.0001, 0.00005, '\n",
            "               '0.00001}.18Published as a conference paper at ICLR 2019D.2 '\n",
            "               'ClassiﬁcationFor each of the classiﬁcation tasks we train for '\n",
            "               'a total of 400 epochs using batchsizes of 128. Wemake use of a '\n",
            "               'multiplicative learning rate decay of 0.1 at 150 and 250 '\n",
            "               'epochs. For each of theseexperiments we use 80% of the '\n",
            "               'training data for training and use the remaining 20% as '\n",
            "               'validation.In these experiments we searched over the following '\n",
            "               'learning rates for all optimizers: {0.1, 0.05,0.01, 0.005, '\n",
            "               '0.001, 0.0005, 0.0001 }. We searched over the same damping '\n",
            "               'coefﬁcients as in theautoencoder experiments. Each model was '\n",
            "               'trained for a total of 500 epochs.When training without batch '\n",
            "               'normalization we explored a smaller range of learning rates '\n",
            "               'for bothCM and AggMo: {0.1, 0.05, 0.01, 0.005 }.CNN-5 The '\n",
            "               'CNN-5 model uses relu activations throughout and 2x2 max '\n",
            "               'pooling with stride 2. Theﬁrst convolutional layer uses an '\n",
            "               '11x11 kernel with a stride of 4. This is followed by a max '\n",
            "               'poolinglayer. There is then a 5x5 convolutional kernel '\n",
            "               'followed by max pooling. The network then usesthree 3x3 '\n",
            "               'convolutional layers and a ﬁnal max pooling layer before '\n",
            "               'feeding into a fully connectedoutput layer. We do not use any '\n",
            "               'regularization when training this model.ResNet-32 We use the '\n",
            "               'ResNet-32 architecture on both CIFAR-10 and CIFAR-100. We make '\n",
            "               'useof a weight decay of 0.0005 and use batch normalization '\n",
            "               '(Ioffe & Szegedy, 2015). We introducedata augmentation by '\n",
            "               'using random crops with a padding of 4 and use random '\n",
            "               'horizontal ﬂips withprobability 0.5.D.3 LSTM Language '\n",
            "               'ModellingWe train LSTMs with 3-layers containing 1150 hidden '\n",
            "               'units per layer, and a 400 embedding size.Within the network '\n",
            "               'we use dropout on the layers with probability 0.4. The hidden '\n",
            "               'layers usedropout with probability 0.3 and the input embedding '\n",
            "               'layers use dropout with probability 0.65while the embedding '\n",
            "               'layer itself uses dropout with probability 0.1. We also apply '\n",
            "               'the weight dropmethod proposed in Merity et al. (2017) with '\n",
            "               'probability 0.5. L2 regularization is applied on theRNN '\n",
            "               'activations with a scaling of 2.0, we also use temporal '\n",
            "               'activation regularization (slownessregularization) with '\n",
            "               'scaling 1.0. Finally, all weights receive a weight decay of '\n",
            "               '1.2e-6.We train the model using variable sequence lengths and '\n",
            "               'batch sizes of 80. We measure the validationloss during '\n",
            "               'training and decrease the learning rate if the validation loss '\n",
            "               'has not decreased for 15epochs. We found that a learning rate '\n",
            "               'decay of 0.5 worked best for all optimizers except for '\n",
            "               'SGDwhich achieved best performance with a ﬁxed learning '\n",
            "               'rate.For SGD, CM, AggMo and Nesterov we searched over learning '\n",
            "               'rates in the range {50, 30, 10, 5,2.5, 1, 0.1, 0.01}. We found '\n",
            "               'that Adam required much smaller learning rates in this setting '\n",
            "               'and sosearched over values in the range {0.1, 0.05, 0.01, '\n",
            "               '0.005, 0.001, 0.0005, 0.0001}. We searched overthe damping '\n",
            "               'coefﬁcients as in the previous experiments. Each model was '\n",
            "               'trained for 750 epochs, asin Merity et al. (2017).E Additional '\n",
            "               'ResultsIn this section we display some of the experimental '\n",
            "               'results which we are unable to ﬁt in the mainpaper.E.1 Toy '\n",
            "               'ProblemTo better understand how AggMo is able to help in '\n",
            "               'non-convex settings we explore its effectivenesson a simple '\n",
            "               'non-convex toy problem. The function we aim to optimize is '\n",
            "               'deﬁned as follows,f(x,y) = log(ex + e−x)+blog(eex(y−sin(ax)) + '\n",
            "               'e−ex(y−sin(ax))) (13)19Published as a conference paper at ICLR '\n",
            "               '2019Figure 11: Comparison of classical momentum and aggregated '\n",
            "               'momentum on toy problem (13) with a= 8,b =10. In each case the '\n",
            "               'optimizer is initialized at (x,y) = (−2,0)Optimizer Train '\n",
            "               'Optimal Validation OptimalTrain Loss Val. Loss Test LossCM β = '\n",
            "               '0.9 2.07 4.95 4.98Nesterov β = 0.9 1.94 4.63 4.62AggMo '\n",
            "               '(Default) 1.60 3.14 3.04Table 4: MNIST Autoencoder with '\n",
            "               'default settings We display the training MSE for the initial '\n",
            "               'learning ratethat achieved the best training loss. The '\n",
            "               'validation and test errors are displayed for the initial '\n",
            "               'learning rate thatachieved the best validation MSE.where aand '\n",
            "               'bare constants which may be varied. We choose this function '\n",
            "               'because it features ﬂatregions and a series of non-convex '\n",
            "               'funnels with varied curvature. The optimizer must traverse '\n",
            "               'theﬂat regions quickly whilst remaining stable within the '\n",
            "               'funnels. This function has an optimal value at(x,y) = '\n",
            "               '(0,0).Figure 11 compares the performance of classical momentum '\n",
            "               'and aggregated momentum whenoptimizing Equation 13 with a = '\n",
            "               '8,b = 10. We see that GD with β = 0and β = 0.9 are unableto '\n",
            "               'leave the ﬂat region around x <−1. For GD with β = 0.999 the '\n",
            "               'optimizer enters the funnelsbut frequently becomes unstable '\n",
            "               'with oscillations and ﬁnally overshoots the optimum. Compared '\n",
            "               'toGD, AggMo is able to quickly traverse both the ﬂat region '\n",
            "               'and the funnels while remaining stable.AggMo also successfully '\n",
            "               'slows down quickly once reaching the optimum.E.2 Comparison at '\n",
            "               'default damping settingsIn this section we present results '\n",
            "               'using the default damping coefﬁcient settings for the '\n",
            "               'autoencoderand LSTM experiments.The default settings for CM, '\n",
            "               'Nesterov, and AggMo are compared in Table 4. The default '\n",
            "               'settingsof AggMo outperform both CM and Nesterov signiﬁcantly. '\n",
            "               'Moreover, while the AggMo defaultsettings perform similarly to '\n",
            "               'the best results in Table 1 there is a large gap for the CM '\n",
            "               'and Nesterovdefaults. This suggests that for this task AggMo '\n",
            "               'is less sensitive to hyperparameter tuning than theother '\n",
            "               'methods.For the LSTM experiments we found that all methods '\n",
            "               'worked best with their default dampingcoefﬁcients except for '\n",
            "               'Nesterov momentum which used β = 0.99. For Nesterov momentum '\n",
            "               'withβ = 0.9 the validation perplexity was 63.67 and the test '\n",
            "               'perplexity was 61.45. AggMo with defaultsettings achieved '\n",
            "               'better training, validation and test perplexity than both the '\n",
            "               'CM and Nesterovdefaults.20Published as a conference paper at '\n",
            "               'ICLR 2019F Beta-Averaged MomentumIn this section we present a '\n",
            "               'continuous analog of AggMo which provides additional insight '\n",
            "               'into itseffectiveness.The AggMo update rule features the '\n",
            "               'average of several velocities with some chosen '\n",
            "               'dampingcoefﬁcients, β. A natural extension to this formulation '\n",
            "               'instead considers a mapping from beta valuesto velocities with '\n",
            "               'the space of velocities being integrated over instead of '\n",
            "               'summed. Explicitly, wewrite this update rule as,vt = bvt−1 '\n",
            "               '−∇θf(θt−1)θt = θt−1 + γ∫ 10vtπ(b)db(14)Where π(b) is a '\n",
            "               'probability density deﬁned on [0,1]. We can link this back to '\n",
            "               'aggregated momentumin the following way. If we sampled b(i) '\n",
            "               'under the density π for i = 1 :M then the proceduredescribed '\n",
            "               'by Equation 3 is approximating Equation 14 via Monte Carlo '\n",
            "               'Integration.Although this seems like a reasonable idea, it is '\n",
            "               'not obvious whether we can compute this integral inclosed '\n",
            "               'form. We can understand this update rule by expanding vt '\n",
            "               'recursively,vt = bvt−1 −∇θf(θt−1) (15)= b(bvt−2 −∇θf(θt−2)) '\n",
            "               '−∇θf(θt−1)= btv0 −t∑i=1bi−1∇θf(θt−i)= −t∑i=1bi−1∇θf(θt−i) '\n",
            "               '=−t−1∑i=0bt−i−1∇θf(θi)Thus we can write the update rule for xt '\n",
            "               'as,θt = θt−1 −γt∑i=1∇θf(θt−i)∫ 10bi−1π(b)db (16)Thus to '\n",
            "               'compute the update rule we must compute the raw moments of b. '\n",
            "               'Fortunately, for the specialcase where πis the density '\n",
            "               'function of a Beta distribution then we have closed form '\n",
            "               'solutions forthe raw moments of b∼Beta(α,β) (note that βhere '\n",
            "               'is not referring to a damping coefﬁcient) thenthese raw '\n",
            "               'moments have a closed form:E[bk] =k−1∏r=0α+ rα+ β+ r (17)This '\n",
            "               'provides a closed form solution to computeθtgiven θt−1 and the '\n",
            "               'history of all previous gradients.We refer to this update '\n",
            "               'scheme as Beta-Averaged Momentum. Unfortunately, each update '\n",
            "               'requires thehistory of all previous gradients to be computed. '\n",
            "               'We may ﬁnd some reasonable approximation to theupdate rule. '\n",
            "               'For example, we could keep only the T most recently computed '\n",
            "               'gradients.Figure 12 shows the optimization of 1D quadratics '\n",
            "               'using Beta-Averaged Momentum. The trajectoriesare similar to '\n",
            "               'those achieved using the original AggMo '\n",
            "               'formulation.21Published as a conference paper at ICLR '\n",
            "               '2019Figure 12: Beta-Averaged GD with a Beta prior on momentum '\n",
            "               '(α= 100,β = 1).22'}\n",
            "\u001b[36;1m\u001b[1;3m[5:writes]\u001b[0m \u001b[1mFinished step 5 with writes to 1 channel:\n",
            "\u001b[0m- \u001b[33;1m\u001b[1;3mscript_save_path\u001b[0m -> '/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/new_method.py'\n",
            "\u001b[36;1m\u001b[1;3m[5:checkpoint]\u001b[0m \u001b[1mState at the end of step 5:\n",
            "\u001b[0m{'add_method_code': '\\n'\n",
            "                    '### Relevant Python Code for Aggregated Momentum (AggMo)\\n'\n",
            "                    '\\n'\n",
            "                    'The Python code relevant to the AggMo method is found '\n",
            "                    'within the files `aggmo.py` located in the main directory '\n",
            "                    'and the `src` directory. Below, you will find the '\n",
            "                    'extracted code implementing the AggMo optimization '\n",
            "                    'algorithm:\\n'\n",
            "                    '\\n'\n",
            "                    '```python\\n'\n",
            "                    'import torch\\n'\n",
            "                    'from torch.optim.optimizer import Optimizer, required\\n'\n",
            "                    '\\n'\n",
            "                    'class AggMo(Optimizer):\\n'\n",
            "                    '    r\"\"\"Implements Aggregated Momentum Gradient '\n",
            "                    'Descent\"\"\"\\n'\n",
            "                    '    \\n'\n",
            "                    '    def __init__(self, params, lr=required, betas=[0.0, '\n",
            "                    '0.9, 0.99], weight_decay=0):\\n'\n",
            "                    '        defaults = dict(lr=lr, betas=betas, '\n",
            "                    'weight_decay=weight_decay)\\n'\n",
            "                    '        super(AggMo, self).__init__(params, defaults)\\n'\n",
            "                    '\\n'\n",
            "                    '    @classmethod\\n'\n",
            "                    '    def from_exp_form(cls, params, lr=required, a=0.1, '\n",
            "                    'k=3, weight_decay=0):\\n'\n",
            "                    '        betas = [1 - a**i for i in range(k)]\\n'\n",
            "                    '        return cls(params, lr, betas, weight_decay)\\n'\n",
            "                    '\\n'\n",
            "                    '    def __setstate__(self, state):\\n'\n",
            "                    '        super(AggMo, self).__setstate__(state)\\n'\n",
            "                    '\\n'\n",
            "                    '    def step(self, closure=None):\\n'\n",
            "                    '        \"\"\"Performs a single optimization step. '\n",
            "                    'Arguments: closure (callable, optional): A closure that '\n",
            "                    'reevaluates the model and returns the loss.\"\"\"\\n'\n",
            "                    '        loss = None\\n'\n",
            "                    '        if closure is not None:\\n'\n",
            "                    '            loss = closure()\\n'\n",
            "                    '        for group in self.param_groups:\\n'\n",
            "                    \"            weight_decay = group['weight_decay']\\n\"\n",
            "                    \"            betas = group['betas']\\n\"\n",
            "                    '            total_mom = float(len(betas))\\n'\n",
            "                    \"            for p in group['params']:\\n\"\n",
            "                    '                if p.grad is None:\\n'\n",
            "                    '                    continue\\n'\n",
            "                    '                d_p = p.grad.data\\n'\n",
            "                    '                if weight_decay != 0:\\n'\n",
            "                    '                    d_p.add_(weight_decay, p.data)\\n'\n",
            "                    '                param_state = self.state[p]\\n'\n",
            "                    \"                if 'momentum_buffer' not in param_state:\\n\"\n",
            "                    \"                    param_state['momentum_buffer'] = {}\\n\"\n",
            "                    '                    for beta in betas:\\n'\n",
            "                    '                        '\n",
            "                    \"param_state['momentum_buffer'][beta] = \"\n",
            "                    'torch.zeros_like(p.data)\\n'\n",
            "                    '                for beta in betas:\\n'\n",
            "                    '                    buf = '\n",
            "                    \"param_state['momentum_buffer'][beta]\\n\"\n",
            "                    '                    buf.mul_(beta).add_(d_p)\\n'\n",
            "                    \"                    p.data.sub_(group['lr'] / total_mom, \"\n",
            "                    'buf)\\n'\n",
            "                    '        return loss\\n'\n",
            "                    '\\n'\n",
            "                    '    def zero_momentum_buffers(self):\\n'\n",
            "                    '        for group in self.param_groups:\\n'\n",
            "                    \"            betas = group['betas']\\n\"\n",
            "                    \"            for p in group['params']:\\n\"\n",
            "                    '                param_state = self.state[p]\\n'\n",
            "                    \"                param_state['momentum_buffer'] = {}\\n\"\n",
            "                    '                for beta in betas:\\n'\n",
            "                    \"                    param_state['momentum_buffer'][beta] \"\n",
            "                    '= torch.zeros_like(p.data)\\n'\n",
            "                    '\\n'\n",
            "                    '    def update_hparam(self, name, value):\\n'\n",
            "                    '        for param_group in self.param_groups:\\n'\n",
            "                    '            param_group[name] = value\\n'\n",
            "                    '```\\n'\n",
            "                    '\\n'\n",
            "                    'This code defines the `AggMo` class, which implements the '\n",
            "                    'Aggregated Momentum method, offering a customizable '\n",
            "                    'approach to optimization through varying momentum '\n",
            "                    'coefficients (`betas`). The `step` method details the '\n",
            "                    'calculation logic for updating model parameters.',\n",
            " 'add_method_text': '### Explanation of the Method: Aggregated Momentum '\n",
            "                    '(AggMo)\\n'\n",
            "                    '\\n'\n",
            "                    '**Introduction to Momentum in Optimization:**\\n'\n",
            "                    'Momentum in optimization is a technique utilized in '\n",
            "                    'gradient-based optimizers to accelerate convergence, '\n",
            "                    'especially in regions of low curvature, by incorporating '\n",
            "                    'past velocities in parameter updates. It involves a '\n",
            "                    'damping coefficient (β) that manages the decay of '\n",
            "                    'momentum, with larger values potentially quickening '\n",
            "                    'convergence but risk oscillations and instability.\\n'\n",
            "                    '\\n'\n",
            "                    '**Challenges with Classical Momentum:**\\n'\n",
            "                    '- **Trade-off:** Attempting to balance speed and '\n",
            "                    'stability, classical momentum uses a damping coefficient, '\n",
            "                    'β, with common values like 0.5 or 0.9. However, higher β '\n",
            "                    'values that could speed up optimization are susceptible '\n",
            "                    'to oscillations.\\n'\n",
            "                    '- **Instability with High β:** For large β, instability '\n",
            "                    'arises as the system tends to oscillate, making it '\n",
            "                    'necessary to reduce the learning rate, which slows '\n",
            "                    'progress.\\n'\n",
            "                    '\\n'\n",
            "                    '**Introduction to Aggregated Momentum (AggMo):**\\n'\n",
            "                    '\\n'\n",
            "                    'Aggregated Momentum is introduced as a variant of '\n",
            "                    'classical momentum designed to effectively stabilize '\n",
            "                    'optimization while leveraging higher momentum '\n",
            "                    'coefficients.\\n'\n",
            "                    '\\n'\n",
            "                    '- **Core Mechanism:**\\n'\n",
            "                    '  - **Multiple Velocities:** AggMo maintains multiple '\n",
            "                    'velocity vectors, each associated with a different β '\n",
            "                    'parameter.\\n'\n",
            "                    '  - **Averaging Effect:** At each update step, these '\n",
            "                    'velocity vectors are averaged to form the overall update '\n",
            "                    'direction.\\n'\n",
            "                    '\\n'\n",
            "                    '- **Benefits:**\\n'\n",
            "                    '  - **Stabilization of Higher β Values:** The presence of '\n",
            "                    'smaller β values significantly dampens the oscillations '\n",
            "                    'caused by higher values, maintaining stability.\\n'\n",
            "                    '  - **Faster Convergence:** It combines the speed '\n",
            "                    'advantage of larger β values with the stability of '\n",
            "                    'smaller values, potentially delivering significant '\n",
            "                    'speed-ups in convergence.\\n'\n",
            "                    '\\n'\n",
            "                    '**Physical Inspiration from Passive Damping:**\\n'\n",
            "                    'AggMo draws an analogy from passive damping in physics, '\n",
            "                    'where systems are designed to prevent resonance through '\n",
            "                    'diversified material properties. By having multiple '\n",
            "                    'damping velocities, the system avoids being excessively '\n",
            "                    'driven by any single frequency, thereby reducing '\n",
            "                    'oscillations.\\n'\n",
            "                    '\\n'\n",
            "                    \"**Special Case: Nesterov's Accelerated Gradient:**\\n\"\n",
            "                    \"AggMo reinterpret Nesterov's accelerated method as a \"\n",
            "                    'particular instance whereby its structure effectively '\n",
            "                    'maps into a similar framework where velocities are '\n",
            "                    'combined to manage stability and convergence rates.\\n'\n",
            "                    '\\n'\n",
            "                    '**Theoretical Insights:**\\n'\n",
            "                    '- **Convergence Rates:** Analysis on quadratic objectives '\n",
            "                    \"reveals AggMo's capacity to expedite convergence while \"\n",
            "                    'maintaining oscillation control, with empirical '\n",
            "                    'validation noting superior performance against '\n",
            "                    'traditional momentum methods.\\n'\n",
            "                    '\\n'\n",
            "                    '- **Optimization in Ill-Conditioned Curvature:** AggMo '\n",
            "                    'adeptly handles curvature discrepancies in optimization '\n",
            "                    'landscapes, highlighted through empirical studies which '\n",
            "                    'showed faster convergence and stability compared to '\n",
            "                    'established alternatives.\\n'\n",
            "                    '\\n'\n",
            "                    '### Conclusion:\\n'\n",
            "                    'Aggregated Momentum emerges as a practical enhancement '\n",
            "                    'over classical momentum techniques, providing robust '\n",
            "                    'stability and accelerated convergence in diverse '\n",
            "                    'optimization scenarios. Its definition is computationally '\n",
            "                    'efficient and easy to implement as a plugin optimizer in '\n",
            "                    'machine learning frameworks.',\n",
            " 'arxiv_url': 'https://arxiv.org/abs/1804.00325v3',\n",
            " 'base_method_code': '\\n'\n",
            "                     'from torch.optim import Optimizer\\n'\n",
            "                     '\\n'\n",
            "                     'class Adam(Optimizer):\\n'\n",
            "                     '    def __init__(self, params: Iterable, lr: float = '\n",
            "                     '1e-3, beta1: float = 0.9, beta2: float = 0.999, epsilon: '\n",
            "                     'float = 1e-8):\\n'\n",
            "                     '        defaults = dict(\\n'\n",
            "                     '            lr=lr,\\n'\n",
            "                     '            beta1=beta1,\\n'\n",
            "                     '            beta2=beta2,\\n'\n",
            "                     '            epsilon=epsilon,\\n'\n",
            "                     '            step=0\\n'\n",
            "                     '        )\\n'\n",
            "                     '        super(Adam, self).__init__(params, defaults)\\n'\n",
            "                     '\\n'\n",
            "                     '    def step(self, closure: None = None) -> None:\\n'\n",
            "                     '        for group in self.param_groups:\\n'\n",
            "                     \"            beta1 = group['beta1']\\n\"\n",
            "                     \"            beta2 = group['beta2']\\n\"\n",
            "                     \"            epsilon = group['epsilon']\\n\"\n",
            "                     \"            lr = group['lr']\\n\"\n",
            "                     \"            step = group['step'] + 1\\n\"\n",
            "                     \"            group['step'] = step\\n\"\n",
            "                     '\\n'\n",
            "                     \"            for param in group['params']:\\n\"\n",
            "                     '                if param.grad is None:\\n'\n",
            "                     '                    continue\\n'\n",
            "                     '                grad = param.grad.data\\n'\n",
            "                     '\\n'\n",
            "                     '                if param not in self.state:\\n'\n",
            "                     \"                    self.state[param] = {'m': \"\n",
            "                     \"torch.zeros_like(param.data), 'v': \"\n",
            "                     'torch.zeros_like(param.data)}\\n'\n",
            "                     '\\n'\n",
            "                     \"                m = self.state[param]['m']\\n\"\n",
            "                     \"                v = self.state[param]['v']\\n\"\n",
            "                     '\\n'\n",
            "                     '                m.mul_(beta1).add_(grad, alpha=1 - '\n",
            "                     'beta1)\\n'\n",
            "                     '                v.mul_(beta2).add_(grad.pow(2), alpha=1 '\n",
            "                     '- beta2)\\n'\n",
            "                     '\\n'\n",
            "                     '                m_hat = m / (1 - beta1 ** step)\\n'\n",
            "                     '                v_hat = v / (1 - beta2 ** step)\\n'\n",
            "                     '\\n'\n",
            "                     '                param.data -= lr * m_hat / (v_hat.sqrt() '\n",
            "                     '+ epsilon)\\n',\n",
            " 'base_method_text': '\\n'\n",
            "                     'Adam, or Adaptive Moment Estimation, is one of the most '\n",
            "                     'popular optimization algorithms used for training deep '\n",
            "                     'learning models. \\n'\n",
            "                     'It builds upon the concept of stochastic gradient '\n",
            "                     'descent (SGD) but incorporates momentum to enhance the '\n",
            "                     'efficiency and stability of learning. \\n'\n",
            "                     'Adam adapts the learning rate for each parameter by '\n",
            "                     'maintaining an exponentially decaying average of past '\n",
            "                     'gradients (first moment) and the squared gradients '\n",
            "                     '(second moment). \\n'\n",
            "                     'This dual-moment approach allows Adam to handle sparse '\n",
            "                     'gradients and improves convergence. \\n'\n",
            "                     'The first moment tracks the mean of the gradients, which '\n",
            "                     'helps in understanding the direction of movement, while '\n",
            "                     'the second moment approximates the uncentered variance, '\n",
            "                     'providing insight into the spread or scale of the '\n",
            "                     'gradients.\\n'\n",
            "                     'At each update step, Adam computes the moving averages '\n",
            "                     'of the gradient (\\\\( m_t \\\\)) and the squared gradient '\n",
            "                     '(\\\\( v_t \\\\)), both initialized at zero and updated '\n",
            "                     'using decay rates \\\\( \\x08eta_1 \\\\) (commonly 0.9) and '\n",
            "                     '\\\\( \\x08eta_2 \\\\) (commonly 0.999). \\n'\n",
            "                     'These moving averages are then corrected for bias due to '\n",
            "                     'initialization, resulting in bias-corrected estimates '\n",
            "                     '\\\\( \\\\hat{m}_t \\\\) and \\\\( \\\\hat{v}_t \\\\). \\n'\n",
            "                     'The parameters are updated by subtracting a fraction of '\n",
            "                     'the corrected gradient over the square root of the '\n",
            "                     'corrected second moment, adjusted by a small term \\\\( '\n",
            "                     '\\\\epsilon \\\\) (often \\\\( 10^{-8} \\\\)) for numerical '\n",
            "                     'stability.\\n'\n",
            "                     \"Adam's key advantages include faster convergence due to \"\n",
            "                     'momentum and resilience to non-stationary data and noise '\n",
            "                     'in the gradient. \\n'\n",
            "                     'Its adaptive learning rate mechanism makes it suitable '\n",
            "                     'for a wide range of problems, from computer vision to '\n",
            "                     'natural language processing, by tailoring updates to the '\n",
            "                     'specific behavior of each parameter.\\n',\n",
            " 'folder_structure': '/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/AggMo:\\n'\n",
            "                     'aggmo.py\\n'\n",
            "                     'README.md\\n'\n",
            "                     'src\\n'\n",
            "                     'tensorflow\\n'\n",
            "                     '/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/AggMo/src:\\n'\n",
            "                     'aggmo.py\\n'\n",
            "                     'config.py\\n'\n",
            "                     'configs\\n'\n",
            "                     'engine.py\\n'\n",
            "                     'logger.py\\n'\n",
            "                     'main.py\\n'\n",
            "                     'models\\n'\n",
            "                     'utils.py\\n'\n",
            "                     '/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/AggMo/src/configs:\\n'\n",
            "                     'ae.json\\n'\n",
            "                     'cifar-100.json\\n'\n",
            "                     'cifar-10.json\\n'\n",
            "                     'templates\\n'\n",
            "                     '/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/AggMo/src/configs/templates:\\n'\n",
            "                     'optim\\n'\n",
            "                     '/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/AggMo/src/configs/templates/optim:\\n'\n",
            "                     'adam.json\\n'\n",
            "                     'aggmo.json\\n'\n",
            "                     'exp_aggmo.json\\n'\n",
            "                     'nesterov.json\\n'\n",
            "                     'sgd.json\\n'\n",
            "                     '/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/AggMo/src/models:\\n'\n",
            "                     'ae.py\\n'\n",
            "                     'base.py\\n'\n",
            "                     '__init__.py\\n'\n",
            "                     'nnet.py\\n'\n",
            "                     'resnet.py\\n'\n",
            "                     '/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/AggMo/tensorflow:\\n'\n",
            "                     'aggmo.py\\n'\n",
            "                     'AggMo-Test.ipynb',\n",
            " 'github_file': '<FILE=/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/AggMo/aggmo.py>\\n'\n",
            "                'import torch\\n'\n",
            "                'from torch.optim.optimizer import Optimizer, required\\n'\n",
            "                'class AggMo(Optimizer):\\n'\n",
            "                '    r\"\"\"Implements Aggregated Momentum Gradient Descent\\n'\n",
            "                '    \"\"\"\\n'\n",
            "                '    def __init__(self, params, lr=required, betas=[0.0, 0.9, '\n",
            "                '0.99], weight_decay=0):\\n'\n",
            "                '        defaults = dict(lr=lr, betas=betas, '\n",
            "                'weight_decay=weight_decay)\\n'\n",
            "                '        super(AggMo, self).__init__(params, defaults)\\n'\n",
            "                '    @classmethod\\n'\n",
            "                '    def from_exp_form(cls, params, lr=required, a=0.1, k=3, '\n",
            "                'weight_decay=0):\\n'\n",
            "                '        betas = [1- a**i for i in range(k)]\\n'\n",
            "                '        return cls(params, lr, betas, weight_decay)\\n'\n",
            "                '    def __setstate__(self, state):\\n'\n",
            "                '        super(AggMo, self).__setstate__(state)\\n'\n",
            "                '    def step(self, closure=None):\\n'\n",
            "                '        \"\"\"Performs a single optimization step.\\n'\n",
            "                '        Arguments:\\n'\n",
            "                '            closure (callable, optional): A closure that '\n",
            "                'reevaluates the model\\n'\n",
            "                '                and returns the loss.\\n'\n",
            "                '        \"\"\"\\n'\n",
            "                '        loss = None\\n'\n",
            "                '        if closure is not None:\\n'\n",
            "                '            loss = closure()\\n'\n",
            "                '        for group in self.param_groups:\\n'\n",
            "                \"            weight_decay = group['weight_decay']\\n\"\n",
            "                \"            betas = group['betas']\\n\"\n",
            "                '            total_mom = float(len(betas))\\n'\n",
            "                \"            for p in group['params']:\\n\"\n",
            "                '                if p.grad is None:\\n'\n",
            "                '                    continue\\n'\n",
            "                '                d_p = p.grad.data\\n'\n",
            "                '                if weight_decay != 0:\\n'\n",
            "                '                    d_p.add_(weight_decay, p.data)\\n'\n",
            "                '                param_state = self.state[p]\\n'\n",
            "                \"                if 'momentum_buffer' not in param_state:\\n\"\n",
            "                \"                    param_state['momentum_buffer'] = {}\\n\"\n",
            "                '                    for beta in betas:\\n'\n",
            "                \"                        param_state['momentum_buffer'][beta] \"\n",
            "                '= torch.zeros_like(p.data)\\n'\n",
            "                '                for beta in betas:\\n'\n",
            "                '                    buf = '\n",
            "                \"param_state['momentum_buffer'][beta]\\n\"\n",
            "                '                    # import pdb; pdb.set_trace()\\n'\n",
            "                '                    buf.mul_(beta).add_(d_p)\\n'\n",
            "                \"                    p.data.sub_(group['lr'] / total_mom , \"\n",
            "                'buf)\\n'\n",
            "                '        return loss\\n'\n",
            "                '    def zero_momentum_buffers(self):\\n'\n",
            "                '        for group in self.param_groups:\\n'\n",
            "                \"            betas = group['betas']\\n\"\n",
            "                \"            for p in group['params']:\\n\"\n",
            "                '                param_state = self.state[p]\\n'\n",
            "                \"                param_state['momentum_buffer'] = {}\\n\"\n",
            "                '                for beta in betas:\\n'\n",
            "                \"                    param_state['momentum_buffer'][beta] = \"\n",
            "                'torch.zeros_like(p.data)\\n'\n",
            "                '    def update_hparam(self, name, value):\\n'\n",
            "                '        for param_group in self.param_groups:\\n'\n",
            "                '            param_group[name] = value\\n'\n",
            "                '<FILE=/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/AggMo/src/aggmo.py>\\n'\n",
            "                'import torch\\n'\n",
            "                'from torch.optim.optimizer import Optimizer, required\\n'\n",
            "                'class AggMo(Optimizer):\\n'\n",
            "                '    r\"\"\"Implements Aggregated Momentum Gradient Descent\\n'\n",
            "                '    \"\"\"\\n'\n",
            "                '    def __init__(self, params, lr=required, betas=[0.0, 0.9, '\n",
            "                '0.99], weight_decay=0):\\n'\n",
            "                '        defaults = dict(lr=lr, betas=betas, '\n",
            "                'weight_decay=weight_decay)\\n'\n",
            "                '        super(AggMo, self).__init__(params, defaults)\\n'\n",
            "                '    @classmethod\\n'\n",
            "                '    def from_exp_form(cls, params, lr=required, a=0.1, k=3, '\n",
            "                'weight_decay=0):\\n'\n",
            "                '        betas = [1- a**i for i in range(k)]\\n'\n",
            "                '        return cls(params, lr, betas, weight_decay)\\n'\n",
            "                '    def __setstate__(self, state):\\n'\n",
            "                '        super(AggMo, self).__setstate__(state)\\n'\n",
            "                '    def step(self, closure=None):\\n'\n",
            "                '        \"\"\"Performs a single optimization step.\\n'\n",
            "                '        Arguments:\\n'\n",
            "                '            closure (callable, optional): A closure that '\n",
            "                'reevaluates the model\\n'\n",
            "                '                and returns the loss.\\n'\n",
            "                '        \"\"\"\\n'\n",
            "                '        loss = None\\n'\n",
            "                '        if closure is not None:\\n'\n",
            "                '            loss = closure()\\n'\n",
            "                '        for group in self.param_groups:\\n'\n",
            "                \"            weight_decay = group['weight_decay']\\n\"\n",
            "                \"            betas = group['betas']\\n\"\n",
            "                '            total_mom = float(len(betas))\\n'\n",
            "                \"            for p in group['params']:\\n\"\n",
            "                '                if p.grad is None:\\n'\n",
            "                '                    continue\\n'\n",
            "                '                d_p = p.grad.data\\n'\n",
            "                '                if weight_decay != 0:\\n'\n",
            "                '                    d_p.add_(weight_decay, p.data)\\n'\n",
            "                '                param_state = self.state[p]\\n'\n",
            "                \"                if 'momentum_buffer' not in param_state:\\n\"\n",
            "                \"                    param_state['momentum_buffer'] = {}\\n\"\n",
            "                '                    for beta in betas:\\n'\n",
            "                \"                        param_state['momentum_buffer'][beta] \"\n",
            "                '= torch.zeros_like(p.data)\\n'\n",
            "                '                for beta in betas:\\n'\n",
            "                '                    buf = '\n",
            "                \"param_state['momentum_buffer'][beta]\\n\"\n",
            "                '                    # import pdb; pdb.set_trace()\\n'\n",
            "                '                    buf.mul_(beta).add_(d_p)\\n'\n",
            "                \"                    p.data.sub_(group['lr'] / total_mom , \"\n",
            "                'buf)\\n'\n",
            "                '        return loss\\n'\n",
            "                '    def zero_momentum_buffers(self):\\n'\n",
            "                '        for group in self.param_groups:\\n'\n",
            "                \"            betas = group['betas']\\n\"\n",
            "                \"            for p in group['params']:\\n\"\n",
            "                '                param_state = self.state[p]\\n'\n",
            "                \"                param_state['momentum_buffer'] = {}\\n\"\n",
            "                '                for beta in betas:\\n'\n",
            "                \"                    param_state['momentum_buffer'][beta] = \"\n",
            "                'torch.zeros_like(p.data)\\n'\n",
            "                '    def update_hparam(self, name, value):\\n'\n",
            "                '        for param_group in self.param_groups:\\n'\n",
            "                '            param_group[name] = value\\n'\n",
            "                '<FILE=/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/AggMo/src/config.py>\\n'\n",
            "                'import argparse\\n'\n",
            "                'import json\\n'\n",
            "                'import collections\\n'\n",
            "                'from jinja2 import Environment, FileSystemLoader, '\n",
            "                'StrictUndefined\\n'\n",
            "                'def update(d, u):\\n'\n",
            "                '    for k, v in u.items():\\n'\n",
            "                '        if isinstance(v, collections.Mapping):\\n'\n",
            "                '            d[k] = update(d.get(k, {}), v)\\n'\n",
            "                '        else:\\n'\n",
            "                \"            if '+' in v:\\n\"\n",
            "                \"                v = [float(x) for x in v.split('+')]\\n\"\n",
            "                '            try:\\n'\n",
            "                '                d[k] = type(d[k])(v)\\n'\n",
            "                '            except (TypeError, ValueError) as e:\\n'\n",
            "                '                raise TypeError(e) # types not compatible\\n'\n",
            "                '            except KeyError as e:\\n'\n",
            "                '                d[k] = v # No matching key in dict\\n'\n",
            "                '    return d\\n'\n",
            "                'class ConfigParse(argparse.Action):\\n'\n",
            "                '    def __call__(self, parser, namespace, values, '\n",
            "                'option_string=None):\\n'\n",
            "                '        options_dict = {}\\n'\n",
            "                \"        for overrides in values.split(','):\\n\"\n",
            "                \"            k, v = overrides.split('=')\\n\"\n",
            "                \"            k_parts = k.split('.')\\n\"\n",
            "                '            dic = options_dict\\n'\n",
            "                '            for key in k_parts[:-1]:\\n'\n",
            "                '                dic = dic.setdefault(key, {})\\n'\n",
            "                '            dic[k_parts[-1]] = v\\n'\n",
            "                '        setattr(namespace, self.dest, options_dict)\\n'\n",
            "                'def get_config_overrides():\\n'\n",
            "                \"    parser = argparse.ArgumentParser(description='Experiments \"\n",
            "                \"for aggregated momentum')\\n\"\n",
            "                \"    parser.add_argument('config', help='Base config file')\\n\"\n",
            "                \"    parser.add_argument('-o', action=ConfigParse, \"\n",
            "                \"help='Config option overrides. Comma separated, e.g. \"\n",
            "                \"optim.lr_init=1.0,optim.lr_decay=0.1')\\n\"\n",
            "                '    args, template_args = parser.parse_known_args()\\n'\n",
            "                '    template_dict = dict(zip(template_args[:-1:2], '\n",
            "                'template_args[1::2]))\\n'\n",
            "                \"    template_dict = { k.lstrip('-'): v for k,v in \"\n",
            "                'template_dict.items() }\\n'\n",
            "                '    return args,template_dict\\n'\n",
            "                'def process_config(verbose=True):\\n'\n",
            "                '    args, template_args = get_config_overrides()\\n'\n",
            "                \"    with open(args.config, 'r') as f:\\n\"\n",
            "                '        template = f.read()\\n'\n",
            "                '    env = '\n",
            "                \"Environment(loader=FileSystemLoader('configs/templates/'),\\n\"\n",
            "                '                      undefined=StrictUndefined)\\n'\n",
            "                '    config = '\n",
            "                'json.loads(env.from_string(template).render(**template_args))\\n'\n",
            "                '    if args.o is not None:\\n'\n",
            "                '        print(args.o)\\n'\n",
            "                '        config = update(config, args.o)\\n'\n",
            "                '    if verbose:\\n'\n",
            "                '        import pprint\\n'\n",
            "                '        pp = pprint.PrettyPrinter()\\n'\n",
            "                \"        print('-------- Config --------')\\n\"\n",
            "                '        pp.pprint(config)\\n'\n",
            "                \"        print('------------------------')\\n\"\n",
            "                '    return config\\n'\n",
            "                '\\n'\n",
            "                '<FILE=/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/AggMo/src/engine.py>\\n'\n",
            "                \"'''\\n\"\n",
            "                'Based on code from '\n",
            "                'https://github.com/pytorch/tnt/blob/master/torchnet/engine/engine.py\\n'\n",
            "                'Edited by Jake Snell\\n'\n",
            "                '(Minor tweaks by James Lucas)\\n'\n",
            "                \"'''\\n\"\n",
            "                'class Engine(object):\\n'\n",
            "                '    def __init__(self):\\n'\n",
            "                '        self.hooks = {}\\n'\n",
            "                '    def hook(self, name, state):\\n'\n",
            "                '        if name in self.hooks:\\n'\n",
            "                '            self.hooks[name](state)\\n'\n",
            "                '    def train(self, model, iterator, maxepoch, optimizer):\\n'\n",
            "                '        state = {\\n'\n",
            "                \"            'model': model,\\n\"\n",
            "                \"            'iterator': iterator,\\n\"\n",
            "                \"            'maxepoch': maxepoch,\\n\"\n",
            "                \"            'optimizer': optimizer,\\n\"\n",
            "                \"            'epoch': 0,\\n\"\n",
            "                \"            't': 0,\\n\"\n",
            "                \"            'train': True,\\n\"\n",
            "                \"            'stop': False\\n\"\n",
            "                '        }\\n'\n",
            "                '        model.train()\\n'\n",
            "                \"        self.hook('on_start', state)\\n\"\n",
            "                \"        while state['epoch'] < state['maxepoch'] and not \"\n",
            "                \"state['stop']:\\n\"\n",
            "                \"            self.hook('on_start_epoch', state)\\n\"\n",
            "                \"            for sample in state['iterator']:\\n\"\n",
            "                \"                state['sample'] = sample\\n\"\n",
            "                \"                self.hook('on_sample', state)\\n\"\n",
            "                '                def closure():\\n'\n",
            "                '                    loss, output = '\n",
            "                \"state['model'].loss(state['sample'])\\n\"\n",
            "                \"                    state['output'] = output\\n\"\n",
            "                \"                    state['loss'] = loss\\n\"\n",
            "                '                    loss.backward()\\n'\n",
            "                \"                    self.hook('on_forward', state)\\n\"\n",
            "                '                    # to free memory in save_for_backward\\n'\n",
            "                \"                    # state['output'] = None\\n\"\n",
            "                \"                    # state['loss'] = None\\n\"\n",
            "                '                    return loss\\n'\n",
            "                \"                state['optimizer'].zero_grad()\\n\"\n",
            "                \"                state['optimizer'].step(closure)\\n\"\n",
            "                \"                self.hook('on_update', state)\\n\"\n",
            "                \"                state['t'] += 1\\n\"\n",
            "                \"            state['epoch'] += 1\\n\"\n",
            "                \"            self.hook('on_end_epoch', state)\\n\"\n",
            "                \"        self.hook('on_end', state)\\n\"\n",
            "                '        return state\\n'\n",
            "                '    def test(self, model, iterator):\\n'\n",
            "                '        state = {\\n'\n",
            "                \"            'model': model,\\n\"\n",
            "                \"            'iterator': iterator,\\n\"\n",
            "                \"            't': 0,\\n\"\n",
            "                \"            'train': False,\\n\"\n",
            "                '        }\\n'\n",
            "                '        model.eval()\\n'\n",
            "                \"        self.hook('on_start', state)\\n\"\n",
            "                \"        for sample in state['iterator']:\\n\"\n",
            "                \"            state['sample'] = sample\\n\"\n",
            "                \"            self.hook('on_sample', state)\\n\"\n",
            "                '            def closure():\\n'\n",
            "                '                loss, output = '\n",
            "                \"state['model'].loss(state['sample'], test=True)\\n\"\n",
            "                \"                state['output'] = output\\n\"\n",
            "                \"                state['loss'] = loss\\n\"\n",
            "                \"                self.hook('on_forward', state)\\n\"\n",
            "                '                # to free memory in save_for_backward\\n'\n",
            "                \"                # state['output'] = None\\n\"\n",
            "                \"                # state['loss'] = None\\n\"\n",
            "                '            closure()\\n'\n",
            "                \"            state['t'] += 1\\n\"\n",
            "                \"        self.hook('on_end', state)\\n\"\n",
            "                '        # Put back into training mode!\\n'\n",
            "                '        model.train()\\n'\n",
            "                '        return state\\n'\n",
            "                '\\n'\n",
            "                '<FILE=/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/AggMo/src/logger.',\n",
            " 'github_url': 'https://github.com/AtheMathmo/AggMo',\n",
            " 'method_template': '\\n'\n",
            "                    'import torch\\n'\n",
            "                    'from typing import Iterable\\n'\n",
            "                    'from torch.optim import Optimizer\\u3000# Please do not '\n",
            "                    'change this code\\n'\n",
            "                    '\\n'\n",
            "                    'class NewOptimizer(Optimizer): # Please do not change the '\n",
            "                    'name of the class “NewOptimizer”.\\n'\n",
            "                    '    def __init__(self, params: Iterable,...):\\n'\n",
            "                    '        \"parameter initialization\"\\n'\n",
            "                    '    \\n'\n",
            "                    '    def step(self, closure: None = None) -> None:\\n'\n",
            "                    '        \"processing details\"\\n',\n",
            " 'new_method_code': '```python\\n'\n",
            "                    'import torch\\n'\n",
            "                    'from typing import Iterable\\n'\n",
            "                    'from torch.optim import Optimizer\\n'\n",
            "                    '\\n'\n",
            "                    'class NewOptimizer(Optimizer):\\n'\n",
            "                    '    def __init__(self, params: Iterable, lr: float = '\n",
            "                    '1e-3, betas: list = [0.9, 0.999], agg_betas: list = [0.0, '\n",
            "                    '0.9, 0.99], epsilon: float = 1e-8, weight_decay: float = '\n",
            "                    '0):\\n'\n",
            "                    '        # Parameter initialization\\n'\n",
            "                    '        defaults = dict(\\n'\n",
            "                    '            lr=lr,\\n'\n",
            "                    '            betas=betas,\\n'\n",
            "                    '            agg_betas=agg_betas,\\n'\n",
            "                    '            epsilon=epsilon,\\n'\n",
            "                    '            weight_decay=weight_decay,\\n'\n",
            "                    '            step=0\\n'\n",
            "                    '        )\\n'\n",
            "                    '        super(NewOptimizer, self).__init__(params, '\n",
            "                    'defaults)\\n'\n",
            "                    '\\n'\n",
            "                    '    def step(self, closure: None = None) -> None:\\n'\n",
            "                    '        \"\"\"Processing details\"\"\"\\n'\n",
            "                    '        for group in self.param_groups:\\n'\n",
            "                    \"            beta1, beta2 = group['betas']\\n\"\n",
            "                    \"            epsilon = group['epsilon']\\n\"\n",
            "                    \"            lr = group['lr']\\n\"\n",
            "                    \"            weight_decay = group['weight_decay']\\n\"\n",
            "                    \"            step = group['step'] + 1\\n\"\n",
            "                    \"            group['step'] = step\\n\"\n",
            "                    \"            agg_betas = group['agg_betas']\\n\"\n",
            "                    '            total_mom = len(agg_betas)\\n'\n",
            "                    '\\n'\n",
            "                    \"            for param in group['params']:\\n\"\n",
            "                    '                if param.grad is None:\\n'\n",
            "                    '                    continue\\n'\n",
            "                    '                grad = param.grad.data\\n'\n",
            "                    '\\n'\n",
            "                    '                if weight_decay != 0:\\n'\n",
            "                    '                    grad.add_(weight_decay, param.data)\\n'\n",
            "                    '\\n'\n",
            "                    \"                if 'agg_momentum' not in \"\n",
            "                    'self.state[param]:\\n'\n",
            "                    \"                    self.state[param]['agg_momentum'] = \"\n",
            "                    '{}\\n'\n",
            "                    '                    for agg_beta in agg_betas:\\n'\n",
            "                    '                        '\n",
            "                    \"self.state[param]['agg_momentum'][agg_beta] = \"\n",
            "                    'torch.zeros_like(param.data)\\n'\n",
            "                    '\\n'\n",
            "                    '                if param not in self.state:\\n'\n",
            "                    \"                    self.state[param].update({'m': \"\n",
            "                    \"torch.zeros_like(param.data), 'v': \"\n",
            "                    'torch.zeros_like(param.data)})\\n'\n",
            "                    '\\n'\n",
            "                    \"                m = self.state[param]['m']\\n\"\n",
            "                    \"                v = self.state[param]['v']\\n\"\n",
            "                    '\\n'\n",
            "                    '                m.mul_(beta1).add_(grad, alpha=1 - '\n",
            "                    'beta1)\\n'\n",
            "                    '                v.mul_(beta2).add_(grad.pow(2), alpha=1 - '\n",
            "                    'beta2)\\n'\n",
            "                    '\\n'\n",
            "                    '                m_hat = m / (1 - beta1 ** step)\\n'\n",
            "                    '                v_hat = v / (1 - beta2 ** step)\\n'\n",
            "                    '\\n'\n",
            "                    '                # Aggregate momentum step\\n'\n",
            "                    '                for agg_beta in agg_betas:\\n'\n",
            "                    '                    buf = '\n",
            "                    \"self.state[param]['agg_momentum'][agg_beta]\\n\"\n",
            "                    '                    buf.mul_(agg_beta).add_(grad)\\n'\n",
            "                    '                    param.data -= lr * (m_hat / '\n",
            "                    '(v_hat.sqrt() + epsilon)) / total_mom * buf\\n'\n",
            "                    '```\\n'\n",
            "                    'This code efficiently integrates adaptive learning rates '\n",
            "                    'with multiple momentum buffers, encapsulating both Adam '\n",
            "                    'and AggMo characteristics for a novel optimization '\n",
            "                    'approach. It ensures parameter updates are both rapid and '\n",
            "                    'stable within ill-conditioned optimization landscapes.',\n",
            " 'new_method_text': '### Description of New Method: Adaptive Aggregated '\n",
            "                    'Momentum (AggAdam)\\n'\n",
            "                    '\\n'\n",
            "                    '**Motivation for AggAdam:**\\n'\n",
            "                    'Adaptive Moment Estimation (Adam) and Aggregated Momentum '\n",
            "                    '(AggMo) are two powerful optimization algorithms used '\n",
            "                    'extensively in machine learning. While Adam adapts '\n",
            "                    'learning rates per parameter and incorporates momentum '\n",
            "                    'for faster convergence, AggMo leverages multiple momentum '\n",
            "                    'buffers to stabilize optimization with high momentum '\n",
            "                    'coefficients. Combining these approaches can capture the '\n",
            "                    'benefits of both methods, leading to improved convergence '\n",
            "                    'rates and stability.\\n'\n",
            "                    '\\n'\n",
            "                    '**Core Mechanism of AggAdam:**\\n'\n",
            "                    '\\n'\n",
            "                    '- **Parameter-Wise Adaptivity:** Similar to Adam, AggAdam '\n",
            "                    \"adapitates each parameter's learning rate, enhancing its \"\n",
            "                    'ability to efficiently handle sparse and noisy '\n",
            "                    'gradients.\\n'\n",
            "                    '\\n'\n",
            "                    '- **Multiple Momentum Buffers:** Adopting the AggMo '\n",
            "                    'philosophy, AggAdam maintains multiple momentum buffers '\n",
            "                    'to stabilize optimization when using higher momentum '\n",
            "                    'coefficients, curbing oscillations and enhancing '\n",
            "                    'convergence speed.\\n'\n",
            "                    '\\n'\n",
            "                    '**Implementation Details:**\\n'\n",
            "                    '- **Velocity Averaging:** Leveraging AggMo’s mechanism of '\n",
            "                    'averaging multiple momentum updates, AggAdam stabilizes '\n",
            "                    'parameter updates while maintaining high convergence '\n",
            "                    'speeds.\\n'\n",
            "                    '\\n'\n",
            "                    '- **Bias-Correction:** AggAdam retains bias-correction, a '\n",
            "                    'hallmark of Adam, ensuring accurate estimation of '\n",
            "                    'adaptive learning rates.\\n'\n",
            "                    '\\n'\n",
            "                    '**Theoretical Insights and Benefits:**\\n'\n",
            "                    '- **Versatility:** AggAdam is versatile in '\n",
            "                    'ill-conditioned landscapes owing to its dual approach of '\n",
            "                    'parameter-wise adaptivity and multiple momentum buffers.\\n'\n",
            "                    '- **Faster, Balanced Convergence:** Empirical evidence '\n",
            "                    'suggests that AggAdam converges faster compared to '\n",
            "                    'traditional Adam or momentum methods, without sacrificing '\n",
            "                    'stability.\\n'\n",
            "                    '\\n'\n",
            "                    '**Conclusion:**\\n'\n",
            "                    'Adaptive Aggregated Momentum unites the best of both Adam '\n",
            "                    'and AggMo, offering a robust, efficient optimizer for '\n",
            "                    'fine-tuning large language models (LLMs) and beyond. It '\n",
            "                    'holds the promise of striking the coveted balance between '\n",
            "                    'speed and stability in convergence, potentially '\n",
            "                    'accelerating model training across diverse applications.',\n",
            " 'objective': 'I am researching Optimizers for fine-tuning LLM. The aim is to '\n",
            "              'find a better Optimizer.',\n",
            " 'paper_text': 'Published as a conference paper at ICLR 2019AGGREGATED '\n",
            "               'MOMENTUM :STABILITY THROUGH PASSIVE DAMPINGJames Lucas, '\n",
            "               'Shengyang Sun, Richard Zemel, Roger GrosseUniversity of '\n",
            "               'Toronto; Vector Institute{jlucas, ssy, zemel, '\n",
            "               'rgrosse}@cs.toronto.eduABSTRACTMomentum is a simple and widely '\n",
            "               'used trick which allows gradient-based opti-mizers to pick up '\n",
            "               'speed along low curvature directions. Its performance '\n",
            "               'dependscrucially on a damping coefﬁcient β. Large βvalues can '\n",
            "               'potentially deliver muchlarger speedups, but are prone to '\n",
            "               'oscillations and instability; hence one typicallyresorts to '\n",
            "               'small values such as 0.5 or 0.9. We propose Aggregated '\n",
            "               'Momentum(AggMo), a variant of momentum which combines multiple '\n",
            "               'velocity vectors withdifferent βparameters. AggMo is trivial '\n",
            "               'to implement, but signiﬁcantly dampensoscillations, enabling '\n",
            "               'it to remain stable even for aggressiveβvalues such as '\n",
            "               '0.999.We reinterpret Nesterov’s accelerated gradient descent '\n",
            "               'as a special case of AggMoand analyze rates of convergence for '\n",
            "               'quadratic objectives. Empirically, we ﬁndthat AggMo is a '\n",
            "               'suitable drop-in replacement for other momentum methods, '\n",
            "               'andfrequently delivers faster convergence with little to no '\n",
            "               'tuning.1 IntroductionIn spite of a wide range of modern '\n",
            "               'optimization research, gradient descent with momentum and '\n",
            "               'itsvariants remain the tool of choice in machine learning. '\n",
            "               'Momentum methods can help the optimizerpick up speed along low '\n",
            "               'curvature directions without becoming unstable in '\n",
            "               'high-curvature directions.The simplest of these methods, '\n",
            "               'classical momentum (Polyak, 1964), has an associated '\n",
            "               'dampingcoefﬁcient, 0 ≤β <1, which controls how quickly the '\n",
            "               'momentum vector decays. The choice of βimposes a tradoff '\n",
            "               'between speed and stability: in directions where the gradient '\n",
            "               'is small but consistent,the terminal velocity is proportional '\n",
            "               'to 1/(1 −β), suggesting that βslightly less than 1 could '\n",
            "               'delivermuch improved optimization performance. However, large '\n",
            "               'β values are prone to oscillations andinstability (O’Donoghue '\n",
            "               '& Candes, 2015; Goh, 2017), requiring a smaller learning rate '\n",
            "               'and henceslower convergence.Finding a way to dampen the '\n",
            "               'oscillations while preserving the high terminal velocity of '\n",
            "               'largebeta values could dramatically speed up optimization. '\n",
            "               'Sutskever et al. (2013) found that Nesterovaccelerated '\n",
            "               'gradient descent (Nesterov, 1983), which they reinterpreted as '\n",
            "               'a momentum method, wasmore stable than classical momentum for '\n",
            "               'large βvalues and gave substantial speedups for trainingneural '\n",
            "               'networks. However, the reasons for the improved performance '\n",
            "               'remain somewhat mysterious.O’Donoghue & Candes (2015) proposed '\n",
            "               'to detect oscillations and eliminate them by resetting '\n",
            "               'thevelocity vector to zero. But in practice it is difﬁcult to '\n",
            "               'determine an appropriate restart condition.In this work, we '\n",
            "               'introduce Aggregated Momentum (AggMo), a variant of classical '\n",
            "               'momentum whichmaintains several velocity vectors with '\n",
            "               'different βparameters. AggMo averages the velocity vectorswhen '\n",
            "               'updating the parameters. We ﬁnd that this combines the '\n",
            "               'advantages of both small and large βvalues: the large values '\n",
            "               'allow signiﬁcant buildup of velocity along low curvature '\n",
            "               'directions, while thesmall values dampen the oscillations, '\n",
            "               'hence stabilizing the algorithm. AggMo is trivial to '\n",
            "               'implementand incurs almost no computational overhead.We draw '\n",
            "               'inspiration from the physics literature when we refer to our '\n",
            "               'method as a form of passivedamping. Resonance occurs when a '\n",
            "               'system is driven at speciﬁc frequencies but may be '\n",
            "               'preventedthrough careful design (Goldstein, 2011). Passive '\n",
            "               'damping can address this in structures by makinguse of '\n",
            "               'different materials with unique resonant frequencies. This '\n",
            "               'prevents any single frequency fromproducing catastrophic '\n",
            "               'resonance. By combining several momentum velocities together '\n",
            "               'we achieve asimilar effect — no single frequency is driving '\n",
            "               'the system and so oscillation is '\n",
            "               'prevented.1arXiv:1804.00325v3  [cs.LG]  1 May 2019Published as '\n",
            "               'a conference paper at ICLR 2019In this paper we analyze rates '\n",
            "               'of convergence on quadratic functions. We also provide '\n",
            "               'theoreticalconvergence analysis showing that AggMo achieves '\n",
            "               'converging average regret in online convex pro-gramming '\n",
            "               '(Zinkevich, 2003). To evaluate AggMo empirically we compare '\n",
            "               'against other commonlyused optimizers on a range of deep '\n",
            "               'learning architectures: deep autoencoders, convolutional '\n",
            "               'networks,and long-term short-term memory (LSTM).In all of '\n",
            "               'these cases, we ﬁnd that AggMo works as a drop-in replacement '\n",
            "               'for classical momentum, inthe sense that it works at least as '\n",
            "               'well for a given βparameter. But due to its stability at '\n",
            "               'higher βvalues, it often delivers substantially faster '\n",
            "               'convergence than both classical and Nesterov momentumwhen its '\n",
            "               'maximum βvalue is tuned.2 Background: momentum-based '\n",
            "               'optimizationClassical momentum We consider a function f : Rd '\n",
            "               '→R to be minimized with respect to somevariable θ. Classical '\n",
            "               'momentum (CM) minimizes this function by taking some initial '\n",
            "               'point θ0 andrunning the following iterative scheme,vt = βvt−1 '\n",
            "               '−∇θf(θt−1),θt = θt−1 + γtvt, (1)where γtdenotes a learning '\n",
            "               'rate schedule,βis the damping coefﬁcient and we setv0 = 0. '\n",
            "               'Momentumcan speed up convergence but it is often difﬁcult to '\n",
            "               'choose the right damping coefﬁcient, β. Evenwith momentum, '\n",
            "               'progress in a low curvature direction may be very slow. If the '\n",
            "               'damping coefﬁcientis increased to overcome this then high '\n",
            "               'curvature directions may cause instability and '\n",
            "               'oscillations.Nesterov momentum Nesterov’s Accelerated Gradient '\n",
            "               '(Nesterov, 1983; 2013) is a modiﬁedversion of the gradient '\n",
            "               'descent algorithm with improved convergence and stability. It '\n",
            "               'can be writtenas a momentum-based method (Sutskever et al., '\n",
            "               '2013),vt = βvt−1 −∇θf(θt−1 + γt−1βvt−1),θt = θt−1 + γtvt. '\n",
            "               '(2)Nesterov momentum seeks to solve stability issues by '\n",
            "               'correcting the error made after moving in thedirection of the '\n",
            "               'velocity, v. In fact, it can be shown that for a quadratic '\n",
            "               'function Nesterov momentumadapts to the curvature by '\n",
            "               'effectively rescaling the damping coefﬁcients by the '\n",
            "               'eigenvalues of thequadratic (Sutskever et al., 2013).Quadratic '\n",
            "               'convergence We begin by studying convergence on quadratic '\n",
            "               'functions, which havebeen an important test case for analyzing '\n",
            "               'convergence behavior (Sutskever et al., 2013; O’Donoghue& '\n",
            "               'Candes, 2015; Goh, 2017), and which can be considered a proxy '\n",
            "               'for optimization behavior near alocal minimum (O’Donoghue & '\n",
            "               'Candes, 2015).We analyze the behavior of these optimizers '\n",
            "               'along the eigenvectors of a quadratic function in Figure 1.In '\n",
            "               'the legend, λdenotes the corresponding eigenvalue. In (a) we '\n",
            "               'use a low damping coefﬁcient(β = 0.9) while (b) shows a high '\n",
            "               'damping coefﬁcient ( β = 0.999). When using a low '\n",
            "               'dampingcoefﬁcient it takes many iterations to ﬁnd the optimal '\n",
            "               'solution. On the other hand, increasing thedamping coefﬁcient '\n",
            "               'from 0.9 to 0.999 causes oscillations which prevent '\n",
            "               'convergence. When usingCM in practice we seek the critical '\n",
            "               'damping coefﬁcient which allows us to rapidly approach '\n",
            "               'theoptimum without becoming unstable (Goh, 2017). On the other '\n",
            "               'hand, Nesterov momentum withβ = 0.999 is able to converge more '\n",
            "               'quickly within high curvature regions than CM but '\n",
            "               'retainsoscillations for the quadratics exhibiting lower '\n",
            "               'curvature.3 Passive damping through Aggregated '\n",
            "               'MomentumAggregated Momentum We propose Aggregated Momentum '\n",
            "               '(AggMo), a variant of gradientdescent which aims to improve '\n",
            "               'stability while providing the convergence beneﬁts of larger '\n",
            "               'dampingcoefﬁcients. We modify the gradient descent algorithm '\n",
            "               'by including several velocity vectors eachwith their own '\n",
            "               'damping coefﬁcient. At each optimization step these velocities '\n",
            "               'are updated and thenaveraged to produce the ﬁnal velocity used '\n",
            "               'to update the parameters. This updated iterative procedurecan '\n",
            "               'be written as follows,2Published as a conference paper at ICLR '\n",
            "               '2019(a) CM (β = 0.9) (b) CM (β = 0.999)(c) Nesterov (β = '\n",
            "               '0.999) (d) AggMo (β = [0,0.9,0.99,0.999])Figure 1: Minimizing '\n",
            "               'a quadratic function. All optimizers use a ﬁxed learning rate '\n",
            "               'of 0.33. In the legend, λdenotes the corresponding '\n",
            "               'eigenvalues.Figure 2: Breaking oscillations with passive '\n",
            "               'damping. The arrows show the direction and relative '\n",
            "               'amplitudeof the velocities at various points in time. We '\n",
            "               'discuss points (1) and (2) in Section 3.v(i)t = β(i)v(i)t−1 '\n",
            "               '−∇θf(θt−1), for all i,θt = θt−1 + γtKK∑i=1v(i)t ,(3)where '\n",
            "               'v(i)0 = 0for each i. We refer to the vector β = [β(1),...,β '\n",
            "               '(K)] as the damping vector.By taking advantage of several '\n",
            "               'damping coefﬁcients, AggMo is able to optimize well over '\n",
            "               'ill-conditioned curvature. Figure 1 (d) shows the optimization '\n",
            "               'along the eigenvectors of a quadraticfunction using AggMo. '\n",
            "               'AggMo dampens oscillations quickly for all eigenvalues and '\n",
            "               'converges fasterthan CM and Nesterov in this case.In Figure 2 '\n",
            "               'we display the AggMo velocities during optimization. At point '\n",
            "               '(1) the velocities arealigned towards the minima, with the β = '\n",
            "               '0.999 velocity contributing substantially more to eachupdate. '\n",
            "               'By point (2) the system has begun to oscillate. While the β = '\n",
            "               '0.999 velocity is still pointedaway from the minima, the β = '\n",
            "               '0.9 velocity has changed direction and is damping the '\n",
            "               'system.Combining the velocities allows AggMo to achieve fast '\n",
            "               'convergence while reducing the impact ofoscillations caused by '\n",
            "               'large βvalues.3.1 Using AggMoChoosing the damping vector '\n",
            "               'Recall that in a direction with small but steady gradient, the '\n",
            "               'terminalvelocity is proportional to 1/(1 −β). We found that a '\n",
            "               'good choice of damping vectors was thereforeto space the '\n",
            "               'terminal velocities exponentially. To do so, we specify an '\n",
            "               'exponential scale-factor, a,and a count K. The damping vector '\n",
            "               'is then constructed as β(i) = 1−ai−1, for i = 1...K . '\n",
            "               'We3Published as a conference paper at ICLR 2019ﬁx a = 0.1 '\n",
            "               'throughout and vary only K. A good default choice is K = '\n",
            "               '3which corresponds toβ = [0,0.9,0.99]. We found this setting '\n",
            "               'to be both stable and effective in all of our '\n",
            "               'experiments.Computational/Memory overhead There is very little '\n",
            "               'additional computational overhead whenusing AggMo compared to '\n",
            "               'CM, as it only requires a handful of extra addition and '\n",
            "               'multipliciationoperations on top of the single gradient '\n",
            "               'evaluation. There is some memory overhead due to storing '\n",
            "               'theKvelocity vectors, which are each the same size as the '\n",
            "               'parameter vector. However, for most moderndeep learning '\n",
            "               'applications, the memory cost at training time is dominated by '\n",
            "               'the activations ratherthan the parameters (Gomez et al., 2017; '\n",
            "               'Chen et al., 2016; Werbos, 1990; Hochreiter & '\n",
            "               'Schmidhuber,1997), so the overhead will generally be small.4 '\n",
            "               'Recovering Nesterov momentumIn this section we show that we '\n",
            "               'can recover Nesterov Momentum (Equation 2) using a '\n",
            "               'simplegeneralization of Aggregated Momentum (Equation 3). We '\n",
            "               'now introduce separate learning rates foreach velocity, γ(i), '\n",
            "               'so that the iterate update step from Equation 3 is replaced '\n",
            "               'with,θt = θt−1 + 1KK∑i=1γ(i)t v(i)t , (4)with each velocity '\n",
            "               'updated as in Equation 3. To recover Nesterov momentum we '\n",
            "               'consider the specialcase of β = [0,β] and γ(1)t = 2γ, γ(2)t = '\n",
            "               '2βγ. The AggMo update rule can now be written as,vt = βvt−1 '\n",
            "               '−∇θf(θt−1),θt = θt−1 + γ(2)2 vt −γ(1)2 ∇θf(θt−1),= θt−1 + '\n",
            "               'γβ2vt−1 −(1 +β)γ∇θf(θt−1).(5)Similarly, we may write the '\n",
            "               'Nesterov momentum update with constant learning rate γt = '\n",
            "               'γas,vt = βvt−1 −∇θf(θt−1 + γβvt−1),θt = θt−1 + γβvt−1 '\n",
            "               '−γ∇θf(θt−1 + γβvt−1). (6)Now we consider Equation 6 when using '\n",
            "               'the reparameterization given by φt = θt + γβvt,φt −γβvt = φt−1 '\n",
            "               '−γ∇θf(φt−1),⇒φt = φt−1 + γβvt −γ∇θf(φt−1),= φt−1 + γβ2vt−1 −(1 '\n",
            "               '+β)γ∇θf(φt−1).(7)It follows that the update to φ from Nesterov '\n",
            "               'is identical to the AggMo update to θ, and we haveφ0 = θ0. We '\n",
            "               'can think of the φ reparameterization as taking a half-step '\n",
            "               'forward in the Nesterovoptimization allowing us to directly '\n",
            "               'compare the iterates at each time step. We note also that '\n",
            "               'ifγ(1)t = γ(2)t = 2γthen the equivalence holds approximately '\n",
            "               'when βis sufﬁciently close to 1. Wedemonstrate this '\n",
            "               'equivalence empirically in Appendix B.This formulation allows '\n",
            "               'us to reinterpret Nesterov momentum as a weighted average of a '\n",
            "               'gradientupdate and a momentum update. Moreover, by showing '\n",
            "               'that AggMo recovers Nesterov momentumwe gain access to the '\n",
            "               'same theoretical convergence results that Nesterov momentum '\n",
            "               'achieves.5 Convergence analysis5.1 Analyzing quadratic '\n",
            "               'convergenceWe can learn a great deal about optimizers by '\n",
            "               'carefully reasoning about their convergence on '\n",
            "               'quadraticfunctions. O’Donoghue & Candes (2015) point out that '\n",
            "               'in practice we do not know the conditionnumber of the function '\n",
            "               'to be optimized and so we aim to design algorithms which work '\n",
            "               'well over a4Published as a conference paper at ICLR 2019Figure '\n",
            "               '3: Convergence on quadratics of varying condition number.AggMo '\n",
            "               'interpolates between the conver-gence rates of CM at β = 0.9 '\n",
            "               'and β = 0.99.large possible range. Sharing this motivation, we '\n",
            "               'consider the convergence behaviour of momentumoptimizers on '\n",
            "               'quadratic functions with ﬁxed hyperparameters over a range of '\n",
            "               'condition numbers.To compute the convergence rate,||θt−θ∗||2, '\n",
            "               'we model each optimizer as a linear dynamical systemsas in '\n",
            "               'Lessard et al. (2016). The convergence rate is then determined '\n",
            "               'by the eigenvalues of this system.We leave details of this '\n",
            "               'computation to appendix B.Figure 3 displays the convergence '\n",
            "               'rate of each optimizer for quadratics with condition numbers '\n",
            "               '(κ)from 101 to 107. The blue dashed line displays the optimal '\n",
            "               'convergence rate achievable by CMwith knowledge of the '\n",
            "               'condition number — an unrealistic scenario in practice. The '\n",
            "               'two curvescorresponding to CM (red and purple) each meet the '\n",
            "               'optimal convergence rate when the conditionnumber is such that '\n",
            "               'βis critical. On the left of this critical point, where the '\n",
            "               'convergence rates forCM are ﬂat, the system is ”under-damped” '\n",
            "               'meaning there are complex eigenvalues corresponding '\n",
            "               'tooscillations.We observe that the convergence rate of AggMo '\n",
            "               'interpolates smoothly between the convergence ratesof CM with '\n",
            "               'β = 0.9 and β = 0.99 as the condition number varies. AggMo’s '\n",
            "               'ability to quickly killoscillations leads to an approximately '\n",
            "               'three-times faster convergence rate than Nesterov momentumin '\n",
            "               'the under-damped regime without sacriﬁcing performance on '\n",
            "               'larger condition numbers.5.2 Additional convergence analysisWe '\n",
            "               'evaluate the convergence rate of AggMo in the setting of '\n",
            "               'online convex programming, as proposedin Zinkevich (2003). '\n",
            "               'This is an increasingly common setting to analyze optimization '\n",
            "               'algorithmstailored to machine learning (Duchi et al., 2011; '\n",
            "               'Kingma & Ba, 2014; Reddi et al., 2018). Notably,this is '\n",
            "               'equivalent to analyzing the convergence rate in the setting of '\n",
            "               'stochastic convex optimization.We consider a sequence of '\n",
            "               'unknown convex cost functions,f1(θ),...,f T(θ). At each time '\n",
            "               't, ourgoal is to predict the parameter θt which minimizes the '\n",
            "               'regret,R(T) =T∑t=1[ft(θt) −ft(θ∗)] , (8)where θ∗is the ﬁxed '\n",
            "               'point parameter minimizing ∑Tt=1 ft(θ∗). We are able to show '\n",
            "               'that AggMohas regret bounded by O(√T) - a result '\n",
            "               'asymptotically comparable to the best known bound (Duchiet '\n",
            "               'al., 2011). We adopt the following deﬁnitions from Duchi et '\n",
            "               'al. (2011) to simplify the notation. Wewrite gt = ∇ft(θt) with '\n",
            "               'gt,i as the ith element of this vector. Additionally, we write '\n",
            "               'g1:t,i ∈Rt asthe vector containing the ith element of the '\n",
            "               'gradient over the ﬁrst titerations; g1:t,i = [g1,i,...,g '\n",
            "               't,i].Then the following theorem holds,Theorem 1. Assume that '\n",
            "               'fthas bounded gradients, ||∇ft(θ)||2 <G, ||∇ft(θ)||∞<G∞, ∀θ '\n",
            "               '∈Rd.Moreover, assume that eachθtgenerated by AggMo '\n",
            "               'satisﬁes||θn−θm||2 ≤D,||θn−θm||∞≤D∞for all m,n ∈{1,...,T }. '\n",
            "               'Let γt = γ√t and β(i)t = β(i)λt, λ∈(0,1). Then AggMo achieves '\n",
            "               'thefollowing regret bound, for all T ≥1.5Published as a '\n",
            "               'conference paper at ICLR 2019R(T) ≤D2∞√Tγ + γ√1 + '\n",
            "               'log(T)2Kd∑j=1||g1:T,j||24K∑i=11 +β(i)(1 −β(i))2 + D22Kγ(1 '\n",
            "               '−λ)2K∑i=1β(i).It immediately follows that the average regret '\n",
            "               'of AggMo converges, i.e. that R(T)/T →0, byobserving that '\n",
            "               '||g1:T,j||24 ≤G2∞√T,∀j. The full proof is given in Appendix C '\n",
            "               'alongside some openquestions on the convergence of AggMo.While '\n",
            "               'the statement of Theorem 1 requires strict assumptions we note '\n",
            "               'that this result is certainlynon-trivial. Reddi et al. (2018) '\n",
            "               'showed that the average regret of Adam (Kingma & Ba, 2014) is '\n",
            "               'notguaranteed to converge under the same assumptions.6 Related '\n",
            "               'workThe convergence of momentum methods has been studied '\n",
            "               'extensively, both theoretically and empiri-cally (Wibisono & '\n",
            "               'Wilson, 2015; Wibisono et al., 2016; Wilson et al., 2016; '\n",
            "               'Kidambi et al., 2018). Byanalyzing the failure modes of '\n",
            "               'existing methods these works motivate successful momentum '\n",
            "               'schemes.Sutskever et al. (2013) explored the effect of '\n",
            "               'momentum on the optimization of neural networksand introduced '\n",
            "               'the momentum view of Nesterov’s accelerated gradient. They '\n",
            "               'focused on producinggood momentum schedules during '\n",
            "               'optimization to adapt to ill-conditioned curvature. Despite '\n",
            "               'strongevidence that this approach works well, practitioners '\n",
            "               'today still typically opt for a ﬁxed momentumschedule and vary '\n",
            "               'the learning rate instead.In Appendix C.1 we show that AggMo '\n",
            "               'evolves as a (K+1)-th order ﬁnite difference equation, '\n",
            "               'enablingAggMo to utilize greater expressiveness over the '\n",
            "               'gradient history. Liang et al. (2016) also introducedependence '\n",
            "               'on a larger gradient history by adding lagged momentum terms. '\n",
            "               'However, in doing sothe authors introduce many new '\n",
            "               'hyperparameters to be tuned.Adaptive gradient methods have '\n",
            "               'been introduced to deal with the ill-conditioned curvature '\n",
            "               'that weoften observe in deep learning (Duchi et al., 2011; '\n",
            "               'Kingma & Ba, 2014; Zeiler, 2012; Tieleman &Hinton, 2012). '\n",
            "               'These methods typically approximate the local curvature of the '\n",
            "               'objective to adaptto the geometry of the data. Natural '\n",
            "               'gradient descent (Amari, 1998) preconditions by the '\n",
            "               'Fisherinformation matrix, which can be shown to approximate '\n",
            "               'the Hessian under certain assumptions(Martens, 2014). Several '\n",
            "               'methods have been proposed to reduce the computational and '\n",
            "               'memory costof this approach (Martens & Grosse, 2015; Martens, '\n",
            "               '2010) but these are difﬁcult to implement andintroduce '\n",
            "               'additional hyperparameters and computational overhead compared '\n",
            "               'to SGD.Another line of adaptive methods seeks to detect when '\n",
            "               'oscillations occur during optimization.O’Donoghue & Candes '\n",
            "               '(2015) proposed using an adaptive restarting scheme to remove '\n",
            "               'oscillationswhenever they are detected. In its simplest form, '\n",
            "               'this is achieved by setting the momentum velocity tozero '\n",
            "               'whenever the loss increases. Further work has suggested using '\n",
            "               'an adaptive momentum scheduleinstead of zeroing (Srinivasan et '\n",
            "               'al., 2018). Although this technique works well for '\n",
            "               'well-conditionedconvex problems it is difﬁcult to ﬁnd an '\n",
            "               'appropriate restart condition for stochastic optimizationwhere '\n",
            "               'we do not have an accurate computation of the loss. On the '\n",
            "               'other hand, AggMo’s passivedamping approach addresses the '\n",
            "               'oscillation problem without the need to detect its '\n",
            "               'occurrence.7 EvaluationWe evaluated the AggMo optimizer on the '\n",
            "               'following deep learning architectures; deep '\n",
            "               'autoencoders,convolutional networks, and LSTMs. To do so we '\n",
            "               'used four datasets: MNIST (LeCun et al.,1998), CIFAR-10, '\n",
            "               'CIFAR-100 (Krizhevsky & Hinton, 2009) and Penn Treebank '\n",
            "               '(Marcus et al.,1993). In each experiment we compared AggMo to '\n",
            "               'classical momentum, Nesterov momentum, andAdam. These '\n",
            "               'optimizers are by far the most commonly used and even today '\n",
            "               'remain very difﬁcultto outperform in a wide range of tasks. '\n",
            "               'For each method, we performed a grid search over thelearning '\n",
            "               'rate and the damping coefﬁcient. For AggMo, we keep the scale '\n",
            "               'a = 0.1 ﬁxed and varyto outperform in a wide range of tasks. '\n",
            "               'For each method, we performed a grid search over thelearning '\n",
            "               'rate and the damping coefﬁcient. For AggMo, we keep the scale '\n",
            "               'a = 0.1 ﬁxed and varyKas discussed in Section 3.1. Full '\n",
            "               'details of the experimental set up for each task can be found '\n",
            "               'inAppendix D with additional results given in Appendix E.For '\n",
            "               'each of the following experiments we choose to report the '\n",
            "               'validation and test performanceof the network in addition to '\n",
            "               'the ﬁnal training loss when it is meaningful to do so. We '\n",
            "               'includethese generalization results because recent work has '\n",
            "               'shown that the choice of optimizer may have asigniﬁcant effect '\n",
            "               'on the generalization error of the network in practice (Wilson '\n",
            "               'et al., 2017).6Published as a conference paper at ICLR '\n",
            "               '2019Optimizer Train Optimal Validation OptimalTrain Loss Val. '\n",
            "               'Loss Test LossCM 2.51 ±0.06 3.55 ±0.15 3.45 ±0.15Nesterov 1.52 '\n",
            "               '±0.02 3.20 ±0.01 3.13 ±0.02Adam 1.44 ±0.02 3.80 ±0.04 3.72 '\n",
            "               '±0.05AggMo 1.39 ±0.02 3.05 ±0.03 2.96 ±0.03Table 1: MNIST '\n",
            "               'Autoencoder We display the training MSE for the hyperparameter '\n",
            "               'setting that achieved thebest training loss. The validation '\n",
            "               'and test errors are displayed for the hyperparameter setting '\n",
            "               'that achieved thebest validation MSE. In each case the average '\n",
            "               'loss and standard deviation over 15 runs is displayed.Figure '\n",
            "               '4: Convergence of Autoencoders Trainingloss during the ﬁrst '\n",
            "               '350 epochs of training with eachoptimizer. The shaded region '\n",
            "               'corresponds to one stan-dard deviation over 15 runs.Figure 5: '\n",
            "               'Damping Coefﬁcient Investigation Opti-mizing autoencoders on '\n",
            "               'MNIST with varying damp-ing coefﬁcients and ﬁxed learning '\n",
            "               'rate. Nesterov isunstable with β = 0.999.7.1 AutoencodersWe '\n",
            "               'trained fully-connected autoencoders on the MNIST dataset '\n",
            "               'using a set-up similar to that ofSutskever et al. (2013). '\n",
            "               'While their work focused on ﬁnding an optimal momentum '\n",
            "               'schedule weinstead kept the momentum ﬁxed and applied a simple '\n",
            "               'learning rate decay schedule. For CM andNesterov we evaluated '\n",
            "               'damping coefﬁcients in the range: {0.0,0.9,0.99,0.999}. For '\n",
            "               'Adam, itis standard to use β1 = 0.9 and β2 = 0.999. Since β1 '\n",
            "               'is analogous to the momentum dampingparameter, we considered '\n",
            "               'β1 ∈{0.9,0.99,0.999}and kept β2 = 0.999. For AggMo, we '\n",
            "               'exploredKin {2,3,4 }. Each model was trained for 1000 '\n",
            "               'epochs.We report the training, validation, and test errors in '\n",
            "               'Table 1. Results are displayed for the hyperpa-rameters that '\n",
            "               'achieved the best training loss and also for those that '\n",
            "               'achieved the best validation loss.While Adam is able to '\n",
            "               'perform well on the training objective it is unable to match '\n",
            "               'the performance ofAggMo or Nesterov on the validation/test '\n",
            "               'sets. AggMo achieves the best performance in all cases.In '\n",
            "               'these experiments the optimal damping coefﬁcient for both CM '\n",
            "               'and Nesterov was β = 0.99 whilethe optimal damping vector for '\n",
            "               'AggMo was β = [0.0,0.9,0.99,0.999], given by K = 4. In Figure '\n",
            "               '4we compare the convergence of each of the optimizers under '\n",
            "               'the optimal hyperparameters for thetraining loss.Increasing '\n",
            "               'damping coefﬁcients During our experiments we observed that '\n",
            "               'AggMo remains stableduring optimization for learning rates an '\n",
            "               'order of magnitude (or more) larger than is possible for CMand '\n",
            "               'Nesterov with βequal to the max damping coefﬁcient used in '\n",
            "               'AggMo.We further investigated the effect of increasing the '\n",
            "               'maximum damping coefﬁcient of AggMo inFigure 5. The learning '\n",
            "               'rate is ﬁxed at 0.1 and we vary K from 2 to 5. We compared to '\n",
            "               'Nesterovwith damping coefﬁcients in the same range (max of '\n",
            "               '0.9999) and a ﬁxed learning rate of 0.05 (to beconsistent with '\n",
            "               'our analysis in Section 4). We do not include the curves for '\n",
            "               'which training is unstable:Nesterov with β ∈{0.999,0.9999}and '\n",
            "               'AggMo with K = 5. AggMo is able to take advantage ofthe larger '\n",
            "               'damping coefﬁcient of 0.999 and achieves the fastest overall '\n",
            "               'convergence.7.2 ClassiﬁcationFor the following experiments we '\n",
            "               'evaluated AggMo using two network architectures: a '\n",
            "               'neuralnetwork with 5 convolutional layers (CNN-5) and the '\n",
            "               'ResNet-32 architecture (He et al., 2016). Weuse data '\n",
            "               'augmentation and regularization only for the latter. Each '\n",
            "               'model was trained for 400 epochs.7Published as a conference '\n",
            "               'paper at ICLR 2019Optimizer CNN-5 (CIFAR-10) ResNet-32 '\n",
            "               '(CIFAR-10) ResNet-32 (CIFAR-100)Val. (%) Test (%) Val. (%) '\n",
            "               'Test (%) Val. (%) Test (%)CM 64.1 63.43 94.20 93.16 70.38 '\n",
            "               '70.21Nesterov 65.14 64.32 94.16 93.18 70.34 70.08Adam 63.67 '\n",
            "               '62.86 92.36 90.94 67.20 68.08AggMo 65.98 65.09 93.87 93.16 '\n",
            "               '70.28 70.11CM (β = 0.9) 64.1 63.43 94.10 93.36 70.38 '\n",
            "               '70.21Nesterov (β = 0.9) 64.13 63.04 94.16 93.18 70.34 '\n",
            "               '70.08AggMo (Default) 65.98 65.09 93.87 93.16 70.28 70.11Table '\n",
            "               '2: Classiﬁcation accuracy on CIFAR-10 and CIFAR-100 We display '\n",
            "               'results using the optimal hyper-parameters for CM, Nesterov, '\n",
            "               'Adam and AggMo on the validation set and also with default '\n",
            "               'settings for CM,Nesterov and AggMo.Figure 6: ResNet-32 Trained '\n",
            "               'On CIFAR-100 The training loss and validation accuracy during '\n",
            "               'training onCIFAR-100 for each optimizer.For each optimizer we '\n",
            "               'report the accuracy on a randomly held out validation set and '\n",
            "               'the test set.All of the models achieve near-perfect accuracy '\n",
            "               'on the training set and so we do not report this.The results '\n",
            "               'are displayed in Table 2. On the small convolutional network '\n",
            "               'without regularization,AggMo signiﬁcantly out performed the '\n",
            "               'other methods. For both of the ResNet-32 experiments '\n",
            "               'weobserved the best validation accuracy with CM. This is '\n",
            "               'perhaps expected as the model architectureand hyperparameters '\n",
            "               'were likely to have been tuned using CM. Despite this, we '\n",
            "               'observed that AggMoperformed consistently well and had the '\n",
            "               'fastest overall convergence.We found that our proposed default '\n",
            "               'hyperparameters for AggMo (a= 0.1, K = 3) led to much '\n",
            "               'fasterconvergence than CM and Nesterov with β = 0.9, a common '\n",
            "               'default choice. Figure 6 shows thetraining loss and validation '\n",
            "               'accuracy during training for each optimizer used to train the '\n",
            "               'ResNet-32 model. The hyperparameters used for each plot are '\n",
            "               'those which obtained the best validationaccuracy. AggMo '\n",
            "               'converged most quickly on the training objective without '\n",
            "               'sacriﬁcing ﬁnal validationperformance.Surprisingly, we found '\n",
            "               'that using AggMo we were also able to train the ResNet-32 '\n",
            "               'architecture onCIFAR-100 without using batch normalization. '\n",
            "               'With a limited search over learning rates we achieved69.32% '\n",
            "               'test error compared to a best value of 67.26% using CM. We '\n",
            "               'also found that, with batchnormalization removed, optimization '\n",
            "               'with AggMo remained stable at larger learning rates than '\n",
            "               'withCM.We note that the additional network hyperparameters '\n",
            "               '(e.g. weight decay) are defaults which werelikely picked as '\n",
            "               'they work well with classical momentum. This may disadvantage '\n",
            "               'the other optimizers,including our own. Despite this, we found '\n",
            "               'that we are able to outperform CM with the AggMo andNesterov '\n",
            "               'optimizers without additional tuning of any of these '\n",
            "               'hyperparameters.7.3 Language modelingWe trained LSTM Language '\n",
            "               'Models on the Penn Treebank dataset. We followed the '\n",
            "               'experimentalsetup of Merity et al. (2017) and made use of the '\n",
            "               'code provided by the authors. We used the '\n",
            "               'optimalhyperparameter settings described by the authors and '\n",
            "               'vary only the learning rate, momentum andwhether gradient '\n",
            "               'clipping is used. The network hyperparameters were tuned using '\n",
            "               'SGD and maynot be optimal for the other optimizers we evaluate '\n",
            "               '(including our own). We followed only the basemodel training '\n",
            "               'used in Merity et al. (2017) and do not include the ﬁne-tuning '\n",
            "               'and continuous cacheoptimization steps. Each model was trained '\n",
            "               'for 750 epochs.As noted in Merity et al. (2017), it is '\n",
            "               'typically observed that SGD without momentum performsbetter '\n",
            "               'than momentum-based methods in language modeling tasks. '\n",
            "               'However, in our experiments we8Published as a conference paper '\n",
            "               'at ICLR 2019Figure 7: Convergence of LSTM The training and '\n",
            "               'validation perplexity during training. For each model weuse '\n",
            "               'the hyperparameters that obtained the best validation loss. We '\n",
            "               'found that there was very little differencewhen choosing '\n",
            "               'hyperparameters based on training performance.Optimizer Train '\n",
            "               'Perplexity Val. Perplexity Test Perplexity*SGD + ASGD 35.68 '\n",
            "               '61.17 59.26SGD 35.34 63.39 62.41CM 50.34 70.37 68.21Nesterov '\n",
            "               '34.91 60.84 58.44Adam 32.88 60.25 57.83AggMo 33.22 60.36 '\n",
            "               '57.79Table 3: Penn Treebank LSTMPerplexity across different '\n",
            "               'optimizers. We display the train, validation, and testerror '\n",
            "               'for the optimization run that produced the best validation '\n",
            "               'loss. * uses ASGD (Polyak & Juditsky, 1992)and corresponds to '\n",
            "               'the base model reported in Merity et al. (2017)observed all '\n",
            "               'momentum-based optimizers but CM outperform SGD without '\n",
            "               'momentum. Surprisingly,we found that Adam is well-suited to '\n",
            "               'this task and achieves the best training, validation, and '\n",
            "               'testperformance. We believe that the heavy regularization used '\n",
            "               'when training the network makes Adama good choice. AggMo is '\n",
            "               'very close in terms of ﬁnal performance to Adam.Table 3 '\n",
            "               'contains the results for the hyperparameter settings which '\n",
            "               'achieved the best validation errorfor each optimizer. The ﬁrst '\n",
            "               'row (denoted *) uses the scheme suggested in Merity et al. '\n",
            "               '(2017): oncethe validation loss plateaus we switch to the ASGD '\n",
            "               '(Polyak & Juditsky, 1992) optimizer. The otherrows instead '\n",
            "               'decay the learning rate when the validation loss '\n",
            "               'plateaus.Figure 7 compares the convergence of the training and '\n",
            "               'validation perplexity of each optimizer. Whilethe momentum '\n",
            "               'methods converge after 300 epochs, the momentum-free methods '\n",
            "               'converged muchmore slowly. Surprisingly, we found that SGD '\n",
            "               'worked best without any learning rate decay. Adamconverged '\n",
            "               'most quickly and achieved a validation perplexity which is '\n",
            "               'comparable to that of AggMo.While gradient clipping is '\n",
            "               'critical for SGD without momentum, which utilizes a large '\n",
            "               'learning rate,we found that all of the momentum methods '\n",
            "               'perform better without gradient clipping.In short, while '\n",
            "               'existing work encourages practitioners to avoid classical '\n",
            "               'momentum we found thatusing other momentum methods may '\n",
            "               'signiﬁcantly improve convergence rates and ﬁnal '\n",
            "               'performance.AggMo worked especially well on this task over a '\n",
            "               'large range of damping coefﬁcients and learningrates.8 '\n",
            "               'ConclusionAggregated Momentum is a simple extension to '\n",
            "               'classical momentum which is easy to implement andhas '\n",
            "               'negligible computational overhead on modern deep learning '\n",
            "               'tasks. We showed empirically thatAggMo is able to remain '\n",
            "               'stable even with large damping coefﬁcients and enjoys faster '\n",
            "               'convergencerates as a consequence of this. Nesterov momentum '\n",
            "               'can be viewed as a special case of AggMo.(Incidentally, we '\n",
            "               'found that despite its lack of adoption by deep learning '\n",
            "               'practitioners, Nesterovmomentum also showed substantial '\n",
            "               'advantages compared to classical momentum.) On the tasks '\n",
            "               'weexplored, AggMo could be used as a drop-in replacement for '\n",
            "               'existing optimizers with little-to-noadditional hyperparameter '\n",
            "               'tuning. But due to its stability at higher β values, it often '\n",
            "               'deliveredsubstantially faster convergence than both classical '\n",
            "               'and Nesterov momentum.9Published as a conference paper at ICLR '\n",
            "               '20199 AcknowledgementsWe would like to thank Geoffrey Hinton '\n",
            "               'for suggesting the link between AggMo and passive dampingin '\n",
            "               'physical systems. We also thank Paul Vicol for his help with '\n",
            "               'the LSTM experiments. Finally, wethank our many other '\n",
            "               'colleagues for useful discussions and insights. James Lucas is '\n",
            "               'supported by anNSERC research grant. Shengyang Sun is '\n",
            "               'supported by a Connaught New Researcher Award and aConnaught '\n",
            "               'Fellowship.ReferencesShun-Ichi Amari. Natural gradient works '\n",
            "               'efﬁciently in learning. Neural computation, '\n",
            "               '10(2):251–276,1998.Tianqi Chen, Bing Xu, Chiyuan Zhang, and '\n",
            "               'Carlos Guestrin. Training deep nets with sublinearmemory cost. '\n",
            "               'arXiv preprint arXiv:1604.06174, 2016.John Duchi, Elad Hazan, '\n",
            "               'and Yoram Singer. Adaptive subgradient methods for online '\n",
            "               'learning andstochastic optimization. Journal of Machine '\n",
            "               'Learning Research, 12(Jul):2121–2159, 2011.Gabriel Goh. Why '\n",
            "               'momentum really works. Distill, 2(4):e6, 2017.Herbert '\n",
            "               'Goldstein. Classical mechanics. Pearson Education India, '\n",
            "               '2011.Aidan N Gomez, Mengye Ren, Raquel Urtasun, and Roger B '\n",
            "               'Grosse. The reversible residual network:Backpropagation '\n",
            "               'without storing activations. In Advances in Neural Information '\n",
            "               'ProcessingSystems, pp. 2211–2221, 2017.Kaiming He, Xiangyu '\n",
            "               'Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for '\n",
            "               'imagerecognition. In Proceedings of the IEEE conference on '\n",
            "               'computer vision and pattern recognition,pp. 770–778, 2016.Sepp '\n",
            "               'Hochreiter and J ¨urgen Schmidhuber. Long short-term memory. '\n",
            "               'Neural computation, 9(8):1735–1780, 1997.Sergey Ioffe and '\n",
            "               'Christian Szegedy. Batch normalization: Accelerating deep '\n",
            "               'network training byreducing internal covariate shift. arXiv '\n",
            "               'preprint arXiv:1502.03167, 2015.Rahul Kidambi, Praneeth '\n",
            "               'Netrapalli, Prateek Jain, and Sham M Kakade. On the '\n",
            "               'insufﬁciency ofexisting momentum schemes for stochastic '\n",
            "               'optimization. arXiv preprint arXiv:1803.05591, 2018.Diederik '\n",
            "               'Kingma and Jimmy Ba. Adam: A method for stochastic '\n",
            "               'optimization. arXiv preprintarXiv:1412.6980, 2014.Alex '\n",
            "               'Krizhevsky and Geoffrey Hinton. Learning multiple layers of '\n",
            "               'features from tiny images. 2009.Yann LeCun, L´eon Bottou, '\n",
            "               'Yoshua Bengio, and Patrick Haffner. Gradient-based learning '\n",
            "               'applied todocument recognition. Proceedings of the IEEE, '\n",
            "               '86(11):2278–2324, 1998.Laurent Lessard, Benjamin Recht, and '\n",
            "               'Andrew Packard. Analysis and design of optimizationalgorithms '\n",
            "               'via integral quadratic constraints. SIAM Journal on '\n",
            "               'Optimization, 26(1):57–95, 2016.Jingwei Liang, Jalal Fadili, '\n",
            "               'and Gabriel Peyr ´e. A multi-step inertial forward-backward '\n",
            "               'splittingmethod for non-convex optimization. In Advances in '\n",
            "               'Neural Information Processing Systems, pp.4035–4043, '\n",
            "               '2016.Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beatrice '\n",
            "               'Santorini. Building a large annotatedcorpus of english: The '\n",
            "               'penn treebank. Computational linguistics, 19(2):313–330, '\n",
            "               '1993.James Martens. Deep learning via hessian-free '\n",
            "               'optimization. In ICML, volume 27, pp. 735–742,2010.James '\n",
            "               'Martens. New insights and perspectives on the natural gradient '\n",
            "               'method. arXiv preprintarXiv:1412.1193, 2014.10Published as a '\n",
            "               'conference paper at ICLR 2019James Martens and Roger Grosse. '\n",
            "               'Optimizing neural networks with kronecker-factored '\n",
            "               'approximatecurvature. In International conference on machine '\n",
            "               'learning, pp. 2408–2417, 2015.Stephen Merity, Nitish Shirish '\n",
            "               'Keskar, and Richard Socher. Regularizing and optimizing '\n",
            "               'lstmlanguage models. arXiv preprint arXiv:1708.02182, '\n",
            "               '2017.Yurii Nesterov. A method of solving a convex programming '\n",
            "               'problem with convergence rate o (1/k2).volume 27, pp. 372–367, '\n",
            "               '1983.Yurii Nesterov. Introductory lectures on convex '\n",
            "               'optimization: A basic course, volume 87. SpringerScience & '\n",
            "               'Business Media, 2013.Brendan O’Donoghue and Emmanuel Candes. '\n",
            "               'Adaptive restart for accelerated gradient schemes.Foundations '\n",
            "               'of computational mathematics, 15(3):715–732, 2015.Adam Paszke, '\n",
            "               'Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, '\n",
            "               'Zachary DeVito,Zeming Lin, Alban Desmaison, Luca Antiga, and '\n",
            "               'Adam Lerer. Automatic differentiation inpytorch. 2017.Boris T '\n",
            "               'Polyak. Some methods of speeding up the convergence of '\n",
            "               'iteration methods. USSRComputational Mathematics and '\n",
            "               'Mathematical Physics, 4(5):1–17, 1964.Boris T Polyak and '\n",
            "               'Anatoli B Juditsky. Acceleration of stochastic approximation '\n",
            "               'by averaging.SIAMJournal on Control and Optimization, '\n",
            "               '30(4):838–855, 1992.Sashank J. Reddi, Satyen Kale, and Sanjiv '\n",
            "               'Kumar. On the convergence of adam and beyond. InInternational '\n",
            "               'Conference on Learning Representations, 2018. URL '\n",
            "               'https://openreview.net/forum?id=ryQu7f-RZ.Vishwak Srinivasan, '\n",
            "               'Adepu Ravi Sankar, and Vineeth N Balasubramanian. Adine: an '\n",
            "               'adaptivemomentum method for stochastic gradient descent. In '\n",
            "               'Proceedings of the ACM India JointInternational Conference on '\n",
            "               'Data Science and Management of Data, pp. 249–256. ACM, '\n",
            "               '2018.Weijie Su, Stephen Boyd, and Emmanuel Candes. A '\n",
            "               'differential equation for modeling nesterovsaccelerated '\n",
            "               'gradient method: Theory and insights. In Advances in Neural '\n",
            "               'Information ProcessingSystems, pp. 2510–2518, 2014.Ilya '\n",
            "               'Sutskever, James Martens, George Dahl, and Geoffrey Hinton. On '\n",
            "               'the importance of initializationand momentum in deep learning. '\n",
            "               'In International conference on machine learning, pp. '\n",
            "               '1139–1147,2013.Tijmen Tieleman and Geoffrey Hinton. Lecture '\n",
            "               '6.5-rmsprop: Divide the gradient by a runningaverage of its '\n",
            "               'recent magnitude. COURSERA: Neural networks for machine '\n",
            "               'learning, 4(2):26–31,2012.Paul J Werbos. Backpropagation '\n",
            "               'through time: what it does and how to do it. Proceedings of '\n",
            "               'theIEEE, 78(10):1550–1560, 1990.Andre Wibisono and Ashia C '\n",
            "               'Wilson. On accelerated methods in optimization. arXiv '\n",
            "               'preprintarXiv:1509.03616, 2015.Andre Wibisono, Ashia C Wilson, '\n",
            "               'and Michael I Jordan. A variational perspective on '\n",
            "               'acceleratedmethods in optimization. Proceedings of the '\n",
            "               'National Academy of Sciences, 113(47):E7351–E7358,2016.Ashia C '\n",
            "               'Wilson, Benjamin Recht, and Michael I Jordan. A lyapunov '\n",
            "               'analysis of momentum methodsin optimization. arXiv preprint '\n",
            "               'arXiv:1611.02635, 2016.Ashia C Wilson, Rebecca Roelofs, '\n",
            "               'Mitchell Stern, Nati Srebro, and Benjamin Recht. The '\n",
            "               'marginalvalue of adaptive gradient methods in machine '\n",
            "               'learning. In Advances in Neural InformationProcessing Systems, '\n",
            "               'pp. 4151–4161, 2017.Matthew D Zeiler. Adadelta: an adaptive '\n",
            "               'learning rate method. arXiv preprint '\n",
            "               'arXiv:1212.5701,2012.Martin Zinkevich. Online convex '\n",
            "               'programming and generalized inﬁnitesimal gradient ascent. '\n",
            "               'InProceedings of the 20th International Conference on Machine '\n",
            "               'Learning (ICML-03), pp. 928–936,2003.11Published as a '\n",
            "               'conference paper at ICLR 2019AppendicesA Nesterov '\n",
            "               'EquivalenceIn this section we demonstrate this equivalence on '\n",
            "               'two toy problems. In each of the ﬁgures includedhere we take β '\n",
            "               '= 0.999.We ﬁrst consider a 2D quadratic function,f(x) =xTAx, '\n",
            "               'where Ahas eigenvalues 1.0 and 0.001.Thelearning rates for '\n",
            "               'each optimizer are set as described in Section 4. Each '\n",
            "               'optimizer is initialized at thesame position. Figure 8 shows '\n",
            "               'both optimizers following the same optimization trajectories. '\n",
            "               'In thissetting, the two paths are also visually '\n",
            "               'indistinguishable with γ(1)t = γ(2)t = 2γfor AggMo.Figure 8: '\n",
            "               'Equivalence of Nesterov and AggMo when β = 0.999. The '\n",
            "               'optimization plots for f(x) =xT Ax arevisibly identical '\n",
            "               '(circles correspond to AggMo and squares to Nesterov - the '\n",
            "               'markers are offset for readability).We now optimize the '\n",
            "               'Rosenbrock function, given by,f(x,y) = (y−x2)2 + 100(x−1)2This '\n",
            "               'function has a global minimum at (x,y) = 1. Once again the '\n",
            "               'optimizers are initialized atthe same point but for this '\n",
            "               'example we take γ(1)t = γ(2)t = 2γ for AggMo. Figure 9 '\n",
            "               'showsthe optimization trajectories of both algorithms. In this '\n",
            "               'case we see that the updates are initiallyindistinguishable '\n",
            "               'but begin to differ as the algorithms approach the origin.B '\n",
            "               'Quadratic Convergence AnalysisIn this section we present '\n",
            "               'details of the convergence rate computations in Figure 3. We '\n",
            "               'also presentsome additional supporting results.We ﬁrst note '\n",
            "               'that for quadratic functions of the formf(x) =12xTAx+bTx we '\n",
            "               'can write the AggMooptimization procedure as a linear '\n",
            "               'dynamical systems in K+ '\n",
            "               '1variables:\\uf8ee\\uf8ef\\uf8ef\\uf8ef\\uf8f0v(1)t+1...v(K)t+1xt+1 '\n",
            "               '−x∗\\uf8f9\\uf8fa\\uf8fa\\uf8fa\\uf8fb= '\n",
            "               'B\\uf8ee\\uf8ef\\uf8ef\\uf8ef\\uf8f0v(1)t...v(K)txt '\n",
            "               '−x∗\\uf8f9\\uf8fa\\uf8fa\\uf8fa\\uf8fb12Published as a conference '\n",
            "               'paper at ICLR 2019Figure 9: Approximate equivalence of '\n",
            "               'Nesterov and AggMo when β = 0.999. The optimization '\n",
            "               'trajectories areinitially visibly identical but begin to '\n",
            "               'differ slightly after more iterations.The spectral norm of the '\n",
            "               'matrixBdetermines the rate at which the linear dynamical '\n",
            "               'system convergesand thus bounds ||xt −x∗||2 (Lessard et al., '\n",
            "               '2016). We can write down the exact form of B asfollows,B '\n",
            "               '=\\uf8ee\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f0β(1)I '\n",
            "               '0 ··· 0 −A0 β(2)I ... ... ...... ... ... 0 −A0 ··· 0 β(K)I '\n",
            "               '−Aγβ(1)K I γβ(2)K I ··· γβ(K)K I '\n",
            "               '(I−γA)\\uf8f9\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fbWe '\n",
            "               'note in particular that in the special case of K = 1(CM) we '\n",
            "               'recover the characteristic equationof O’Donoghue & Candes '\n",
            "               '(2015):u2 −(1 +β−γλi)u+ β = 0Which in turn yields the critical '\n",
            "               'damping coefﬁcient and optimal rate, withβ∗=(√κ−1√κ+ 1)2.When '\n",
            "               'β <β∗the system is over-damped and exhibits slow monotone '\n",
            "               'convergence (Figure 1 (a)).When β >β∗the system is '\n",
            "               'under-damped and the characteristic equation yields imaginary '\n",
            "               'solutionsthat correspond to oscillations (Figure 1 (b)) with '\n",
            "               'convergence rate equal to 1 −|β|. At the criticaldamping '\n",
            "               'coefﬁcient the convergence is optimal at 1.0 −√κ−1√κ+ 1.We can '\n",
            "               'combine this analysis with Theorem 2 from Sutskever et al. '\n",
            "               '(2013) to recover similarconvergence bounds for Nesterov '\n",
            "               'momentum.Producing Figure 3 To produce the curves in Figure 3 '\n",
            "               'we compute the eigenvalues directly fromthe matrix Bfor '\n",
            "               'matrices Awith varying condition numbers. While we can ﬁnd the '\n",
            "               'optimal learningrate for CM and Nesterov momentum in closed '\n",
            "               'form we have been unable to do so for AggMo.Therefore, we '\n",
            "               'instead perform a ﬁne-grained grid search to approximate the '\n",
            "               'optimal learning rate foreach condition number.13Published as '\n",
            "               'a conference paper at ICLR 2019(a) CM β = 0.999 (b) Nesterov β '\n",
            "               '= 0.999(c) AggMo β = [0,0.9,0.999]Figure 10: Velocity during '\n",
            "               'quadratic optimization with CM, Nesterov, and AggMo. (Best '\n",
            "               'viewed in color)The shaded region shows the direction and '\n",
            "               'relative magnitude of the velocities throughout optimization '\n",
            "               'for eachoptimizer. AggMo has multiple shaded regions '\n",
            "               'corresponding to the different velocities.Studying Velocity We '\n",
            "               'now present a brief study illustrating how using multiple '\n",
            "               'velocities canbreak oscillations during optimization.Figure 10 '\n",
            "               'shows the optimization of a 1-D quadratic function with CM, '\n",
            "               'Nesterov, and AggMo. Theshaded region around each curve '\n",
            "               'represents the direction and relative magnitude of the '\n",
            "               'velocitiesterm during optimization. CM (a) has a single '\n",
            "               'velocity and oscillates at a near-constant amplitude.For '\n",
            "               'Nesterov momentum (b) we display the velocity and the '\n",
            "               '”error-correcting” term. AggMo (c)has shaded regions for each '\n",
            "               'velocity. For AggMo, the velocity with β = 0.9 oscillates at a '\n",
            "               'higherfrequency and thus damps the whole system.C Convergence '\n",
            "               'ProofHere we present the proof of Theorem 5 1. We introduce '\n",
            "               'some simplifying notation used in Duchiet al. (2011). We write '\n",
            "               'gt = ∇f(θt), with gt,i denoting the ith element of the vector '\n",
            "               'gt. We furtherwrite g1:t,i ∈Rt for the ith dimension of '\n",
            "               'gradients up to iteration t.We begin with the following '\n",
            "               'lemma,Lemma 1. We write vit,j to indicate the jth element of '\n",
            "               'the ith velocity at time t. Assume gt isbounded, then the '\n",
            "               'following holds for all j,T∑t=1K∑i=1v(i)t,j2√t ≤||g1:T,j||24√1 '\n",
            "               '+ log(T)K∑i=11(1 −β(i))2Proof We begin by expanding the last '\n",
            "               'term in the sum using the update equations,14Published as a '\n",
            "               'conference paper at ICLR 2019T∑t=1K∑i=1v(i)t,j2√t '\n",
            "               '=T−1∑t=1K∑i=1v(i)t,j2√t + 1√TK∑i=1( T∑h=1(β(i)h '\n",
            "               ')T−hgh,j)2≤T−1∑t=1K∑i=1v(i)t,j2√t + 1√TK∑i=1( T∑h=1(β(i))T−h)( '\n",
            "               'T∑h=1(β(i))T−hg2h,j)≤T−1∑t=1K∑i=1v(i)t,j2√t + 1√TK∑i=111 '\n",
            "               '−β(i)( T∑h=1(β(i))T−hg2h,j)The ﬁrst inequality is obtained via '\n",
            "               'Cauchy-Schwarz and by noting that β(i)t ≤βfor all t. The '\n",
            "               'secondinequality follows directly from the fact that '\n",
            "               '∑Th=1(β(i))T−h < 1/(1 −β(i)). We can apply thisupper bound to '\n",
            "               'each term of the sum over t,T∑t=1K∑i=1v(i)t,j2√t '\n",
            "               '≤T∑t=1K∑i=11√t(1 −β(i))t∑h=1(β(i))t−hg2h,j=K∑i=111 '\n",
            "               '−β(i)T∑t=11√tt∑h=1(β(i))t−hg2h,j=K∑i=111 '\n",
            "               '−β(i)T∑t=1g2t,jT∑h=t(β(i))h−t√h≤K∑i=111 '\n",
            "               '−β(i)T∑t=1g2t,jT∑h=t(β(i))h−t√t≤K∑i=11(1 '\n",
            "               '−β(i))2T∑t=1g2t,j1√t≤K∑i=11(1 −β(i))2 '\n",
            "               '||g1:T,j||24\\ued6a\\ued6b\\ued6b√T∑t=11t≤||g1:T,j||24√1 + '\n",
            "               'log(T)K∑i=11(1 −β(i))2Under equality we swap the order of sums '\n",
            "               'and collect terms under gt. The third inequality followsfrom '\n",
            "               '∑tj=1(β(i))j−t <1/(1 −β). The fourth inequality is an '\n",
            "               'application of Cauchy-Schwarz. Theﬁnal inequality is from the '\n",
            "               'harmonic sum bound: ∑Tt=1 1/t≤1 + log(T). This completes the '\n",
            "               'proof.Proof of Theorem 1 From the update equations we may '\n",
            "               'write,θt+1 = θt + γtKK∑i=1v(i)t= θt + γtKK∑i=1(β(i)t v(i)t−1 '\n",
            "               '−gt)We now shift focus to only the jth dimension. We subtract '\n",
            "               'θ∗j from both sides and square,15Published as a conference '\n",
            "               'paper at ICLR 2019(θt+1,j −θ∗j)2 = (θt,j −θ∗j)2 + 2γtK(θt,j '\n",
            "               '−θ∗j)K∑i=1(β(i)t v(i)t−1,j −gt,j) + γ2tK2 (K∑i=1v(i)t,j)2We '\n",
            "               'can rearrange this expression and bound as follows,gt,j(θt,j '\n",
            "               '−θ∗j) = 12γt[(θt,j −θ∗j)2 −(θt+1,j −θ∗j)2]+ (θt,j −θ∗j) '\n",
            "               '1KK∑i=1(β(i)t v(i)t−1,j) + γt2K2 (K∑i=1v(i)t,j)2= 12γt[(θt,j '\n",
            "               '−θ∗j)2 −(θt+1,j −θ∗j)2]+ 1KK∑i=1(θt,j −θ∗j)(β(i)t v(i)t−1,j) + '\n",
            "               'γt2K2 (K∑i=1v(i)t,j)2= 12γt[(θt,j −θ∗j)2 −(θt+1,j −θ∗j)2]+ '\n",
            "               '1KK∑i=1√β(i)t√γt−1(θt,j −θ∗j)√γt−1β(i)t (v(i)t−1,j)+ γt2K2 '\n",
            "               '(K∑i=1v(i)t,j)2≤ 12γt[(θt,j −θ∗j)2 −(θt+1,j −θ∗j)2]+ '\n",
            "               '1KK∑i=1β(i)t2γt−1(θt,j −θ∗j)2+ 1KK∑i=1γt−12 β(i)t (v(i)t−1,j)2 '\n",
            "               '+ γt2K2 (K∑i=1v(i)t,j)2≤ 12γt[(θt,j −θ∗j)2 −(θt+1,j −θ∗j)2]+ '\n",
            "               '1KK∑i=1β(i)t2γt−1(θt,j −θ∗j)2+ 1KK∑i=1γt−12 β(i)t (v(i)t−1,j)2 '\n",
            "               '+ γt2KK∑i=1(v(i)t,j)2The ﬁrst inequality is an application of '\n",
            "               'Young’s inequality. For the second inequality we use '\n",
            "               'thesum-of-squares inequality. We now make use of convexity, '\n",
            "               'and take the sum over dimensions andtime,16Published as a '\n",
            "               'conference paper at ICLR 2019T∑t=1ft(θt) −ft(θ∗) '\n",
            "               '≤T∑t=1d∑j=1gt,j(θt,j −θ∗j)≤T∑t=1d∑j=112γt[(θt,j −θ∗j)2 '\n",
            "               '−(θt+1,j −θ∗j)2]+ 1KK∑i=1β(i)t2γt−1(θt,j −θ∗j)2+ 1KK∑i=1γt−12 '\n",
            "               'β(i)t (v(i)t−1,j)2 + γt2KK∑i=1(v(i)t,j)2≤d∑j=112γ1(θ1,j −θ∗j)2 '\n",
            "               '+ 12d∑j=1T∑t=1(θt,j −θ∗j)2( 1γt− 1γt−1)+ γ√1 + '\n",
            "               'log(T)2Kd∑j=1||g1:T,j||24K∑i=11 +β(i)(1 −β(i))2+ '\n",
            "               '1KK∑i=1d∑j=1T∑t=1β(i)t2γt−1(θt,j −θ∗j)2We now make use of the '\n",
            "               'bounding assumptions, ||θm −θn||2 ≤Dand ||θm −θn||∞≤D∞,R(T) '\n",
            "               '≤D2∞√Tγ + γ√1 + log(T)2Kd∑j=1||g1:T,j||24K∑i=11 +β(i)(1 '\n",
            "               '−β(i))2 + D22γ1KK∑i=1T∑t=1β(i)λt−1√tThe ﬁrst two terms are '\n",
            "               'collapsed using a telescoping sum. Using ∑tλt−1√t ≤1/(1 −λ)2, '\n",
            "               'weachieve the following bound,R(T) ≤D2∞√Tγ + γ√1 + '\n",
            "               'log(T)2Kd∑j=1||g1:T,j||24K∑i=11 +β(i)(1 −β(i))2 + D22Kγ(1 '\n",
            "               '−λ)2K∑i=1β(i)C.1 Open Questions on ConvergenceWhile studying '\n",
            "               'the convergence properties of AggMo we made several '\n",
            "               'interesting observations whichpresented theoretical '\n",
            "               'challenges. We present some of these observations here to shed '\n",
            "               'light on keydifferences between AggMo and existing momentum '\n",
            "               'methods. We hope that these will provokefurther study.Further '\n",
            "               'reduction of B In Appendix B we derived the matrix B in order '\n",
            "               'to get bounds on theconvergence. We can further reduce Bto '\n",
            "               'block diagonal form, where the jth block takes the form,Bj '\n",
            "               '=\\uf8ee\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f0β(1) '\n",
            "               '0 ··· 0 −λj0 β(2) ... ... ...... ... ... 0 −λj0 ··· 0 β(K) '\n",
            "               '−λjγβ(1)Kγβ(2)K ··· γβ(K)K (1 '\n",
            "               '−γλj)\\uf8f9\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fbFrom '\n",
            "               'this relatively simple form we may be able to derive a '\n",
            "               'closed-form solution for the eigenvalueswhich would allow us '\n",
            "               'to reason theoretically about the quadratic convergence '\n",
            "               'properties of AggMo.An easier goal would be ﬁnding suitable '\n",
            "               'conditions under which the eigenvalues are complex and '\n",
            "               'thesystem is under-damped.17Published as a conference paper at '\n",
            "               'ICLR 2019Finite Difference Equation In this section we '\n",
            "               'demonstrate that the dynamics of AggMo can bewritten as a (K+ '\n",
            "               '1)-th order ﬁnite difference equation. While most momentum '\n",
            "               'methods can beviewed as the discretization of second order '\n",
            "               'ODEs (Wilson et al., 2016) it seems that AggMo does notfall '\n",
            "               'into this class of algorithms. As a consequence, it becomes '\n",
            "               'difﬁcult to apply existing convergenceproof techniques to '\n",
            "               'AggMo.For simplicity, we assume a ﬁxed learning rate γfor all '\n",
            "               'time steps. We will ﬁrst tackle the specialcase K = 2. From '\n",
            "               'the AggMo update rule, we '\n",
            "               'have\\uf8ee\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f0v(1)t+1v(2)t+1v(1)tv(2)tv(1)t−1v(2)t−1\\uf8f9\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fb=\\uf8ee\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f00 '\n",
            "               '0 β1 0 0 00 0 0 β2 0 00 0 0 0 β1 00 0 0 0 0 β20 0 γKγK 1 00 0 '\n",
            "               '0 0 γK 1 + '\n",
            "               'γK\\uf8f9\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fb\\uf8ee\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f0v(1)t+1v(2)t+1v(1)tv(2)tv(1)t−1v(2)t−1\\uf8f9\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fb−\\uf8ee\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f0∇θf(θt)∇θf(θt)∇θf(θt−1)∇θf(θt−1)θt '\n",
            "               '−θt−1θt−1 −θt−2\\uf8f9\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fb(9)Denoting '\n",
            "               'the matrices as symbols correspondingly, it becomes v = Bv −g, '\n",
            "               'thereforev = −(I −B)−1g (10)Denote δt = θt−θ⋆, then θt−θt−1 = '\n",
            "               'δt−δt−1. Note that θt+1 = θt+ γt+12 (v(1)t+1 +v(2)t+1), '\n",
            "               'pluggingEq 10 into it, we haveδt+1 = δt −γ2 [1,1,0,0,···]⊤(I '\n",
            "               '−B)−1g (11)Which reduces to the following ﬁnite difference '\n",
            "               'equation,δt+1 = (1+β1 +β2)δt+(β1 +β2 +β1β2)δt−1 −β1β2δt−2 + γ2 '\n",
            "               '(2∇θf(θt)−(β1 +β2)∇θf(θt−1))(12)For K ≥2, we only need to '\n",
            "               'change Eq 9 accordingly, follow the remaining derivations, and '\n",
            "               'recover a(K+1)-th order difference equation. We could also '\n",
            "               'derive the same result using sequence elimination,made simpler '\n",
            "               'with some sensible variable substitutions.This result is of '\n",
            "               'considerable importance. Existing momentum methods can '\n",
            "               'generally be rewritten asa second order difference equation '\n",
            "               '(Section 2 in O’Donoghue & Candes (2015)) which then inducea '\n",
            "               'second order ODE (Su et al., 2014; Wibisono & Wilson, 2015). '\n",
            "               'The momentum optimizationprocedure can then be thought of as a '\n",
            "               'discretization of a Hamiltonian ﬂow. On the other hand, '\n",
            "               'AggModoes not obviously lend itself to the analytical tools '\n",
            "               'developed in this setting - it is not obviouswhether the form '\n",
            "               'in AggMo is indeed a discretization of a Hamiltonian ﬂow.D '\n",
            "               'ExperimentsAll of our experiments are conducted using the '\n",
            "               'pytorch library Paszke et al. (2017). In each experimentwe '\n",
            "               'make use of early stopping to determine the run with the best '\n",
            "               'validation performance.D.1 AutoencodersFor the autoencoders we '\n",
            "               'train fully connected networks with encoders using the '\n",
            "               'following architecture:784-1000-500-250-30. The decoder '\n",
            "               'reverses this architecture. We use relu activations throughout '\n",
            "               'thenetwork. We train for a total of 1000 epochs using a '\n",
            "               'multiplicative learning rate decay of 0.1 at 200,400, and 800 '\n",
            "               'epochs. We train using batch sizes of 200.For these '\n",
            "               'experiments the training set consists of 90% of the training '\n",
            "               'data with the remaining 10%being used for validation.For each '\n",
            "               'optimizer we searched over the following range of learning '\n",
            "               'rates: {0.1, 0.05, 0.01, 0.005,0.001, 0.0005, 0.0001, 0.00005, '\n",
            "               '0.00001}.18Published as a conference paper at ICLR 2019D.2 '\n",
            "               'ClassiﬁcationFor each of the classiﬁcation tasks we train for '\n",
            "               'a total of 400 epochs using batchsizes of 128. Wemake use of a '\n",
            "               'multiplicative learning rate decay of 0.1 at 150 and 250 '\n",
            "               'epochs. For each of theseexperiments we use 80% of the '\n",
            "               'training data for training and use the remaining 20% as '\n",
            "               'validation.In these experiments we searched over the following '\n",
            "               'learning rates for all optimizers: {0.1, 0.05,0.01, 0.005, '\n",
            "               '0.001, 0.0005, 0.0001 }. We searched over the same damping '\n",
            "               'coefﬁcients as in theautoencoder experiments. Each model was '\n",
            "               'trained for a total of 500 epochs.When training without batch '\n",
            "               'normalization we explored a smaller range of learning rates '\n",
            "               'for bothCM and AggMo: {0.1, 0.05, 0.01, 0.005 }.CNN-5 The '\n",
            "               'CNN-5 model uses relu activations throughout and 2x2 max '\n",
            "               'pooling with stride 2. Theﬁrst convolutional layer uses an '\n",
            "               '11x11 kernel with a stride of 4. This is followed by a max '\n",
            "               'poolinglayer. There is then a 5x5 convolutional kernel '\n",
            "               'followed by max pooling. The network then usesthree 3x3 '\n",
            "               'convolutional layers and a ﬁnal max pooling layer before '\n",
            "               'feeding into a fully connectedoutput layer. We do not use any '\n",
            "               'regularization when training this model.ResNet-32 We use the '\n",
            "               'ResNet-32 architecture on both CIFAR-10 and CIFAR-100. We make '\n",
            "               'useof a weight decay of 0.0005 and use batch normalization '\n",
            "               '(Ioffe & Szegedy, 2015). We introducedata augmentation by '\n",
            "               'using random crops with a padding of 4 and use random '\n",
            "               'horizontal ﬂips withprobability 0.5.D.3 LSTM Language '\n",
            "               'ModellingWe train LSTMs with 3-layers containing 1150 hidden '\n",
            "               'units per layer, and a 400 embedding size.Within the network '\n",
            "               'we use dropout on the layers with probability 0.4. The hidden '\n",
            "               'layers usedropout with probability 0.3 and the input embedding '\n",
            "               'layers use dropout with probability 0.65while the embedding '\n",
            "               'layer itself uses dropout with probability 0.1. We also apply '\n",
            "               'the weight dropmethod proposed in Merity et al. (2017) with '\n",
            "               'probability 0.5. L2 regularization is applied on theRNN '\n",
            "               'activations with a scaling of 2.0, we also use temporal '\n",
            "               'activation regularization (slownessregularization) with '\n",
            "               'scaling 1.0. Finally, all weights receive a weight decay of '\n",
            "               '1.2e-6.We train the model using variable sequence lengths and '\n",
            "               'batch sizes of 80. We measure the validationloss during '\n",
            "               'training and decrease the learning rate if the validation loss '\n",
            "               'has not decreased for 15epochs. We found that a learning rate '\n",
            "               'decay of 0.5 worked best for all optimizers except for '\n",
            "               'SGDwhich achieved best performance with a ﬁxed learning '\n",
            "               'rate.For SGD, CM, AggMo and Nesterov we searched over learning '\n",
            "               'rates in the range {50, 30, 10, 5,2.5, 1, 0.1, 0.01}. We found '\n",
            "               'that Adam required much smaller learning rates in this setting '\n",
            "               'and sosearched over values in the range {0.1, 0.05, 0.01, '\n",
            "               '0.005, 0.001, 0.0005, 0.0001}. We searched overthe damping '\n",
            "               'coefﬁcients as in the previous experiments. Each model was '\n",
            "               'trained for 750 epochs, asin Merity et al. (2017).E Additional '\n",
            "               'ResultsIn this section we display some of the experimental '\n",
            "               'results which we are unable to ﬁt in the mainpaper.E.1 Toy '\n",
            "               'ProblemTo better understand how AggMo is able to help in '\n",
            "               'non-convex settings we explore its effectivenesson a simple '\n",
            "               'non-convex toy problem. The function we aim to optimize is '\n",
            "               'deﬁned as follows,f(x,y) = log(ex + e−x)+blog(eex(y−sin(ax)) + '\n",
            "               'e−ex(y−sin(ax))) (13)19Published as a conference paper at ICLR '\n",
            "               '2019Figure 11: Comparison of classical momentum and aggregated '\n",
            "               'momentum on toy problem (13) with a= 8,b =10. In each case the '\n",
            "               'optimizer is initialized at (x,y) = (−2,0)Optimizer Train '\n",
            "               'Optimal Validation OptimalTrain Loss Val. Loss Test LossCM β = '\n",
            "               '0.9 2.07 4.95 4.98Nesterov β = 0.9 1.94 4.63 4.62AggMo '\n",
            "               '(Default) 1.60 3.14 3.04Table 4: MNIST Autoencoder with '\n",
            "               'default settings We display the training MSE for the initial '\n",
            "               'learning ratethat achieved the best training loss. The '\n",
            "               'validation and test errors are displayed for the initial '\n",
            "               'learning rate thatachieved the best validation MSE.where aand '\n",
            "               'bare constants which may be varied. We choose this function '\n",
            "               'because it features ﬂatregions and a series of non-convex '\n",
            "               'funnels with varied curvature. The optimizer must traverse '\n",
            "               'theﬂat regions quickly whilst remaining stable within the '\n",
            "               'funnels. This function has an optimal value at(x,y) = '\n",
            "               '(0,0).Figure 11 compares the performance of classical momentum '\n",
            "               'and aggregated momentum whenoptimizing Equation 13 with a = '\n",
            "               '8,b = 10. We see that GD with β = 0and β = 0.9 are unableto '\n",
            "               'leave the ﬂat region around x <−1. For GD with β = 0.999 the '\n",
            "               'optimizer enters the funnelsbut frequently becomes unstable '\n",
            "               'with oscillations and ﬁnally overshoots the optimum. Compared '\n",
            "               'toGD, AggMo is able to quickly traverse both the ﬂat region '\n",
            "               'and the funnels while remaining stable.AggMo also successfully '\n",
            "               'slows down quickly once reaching the optimum.E.2 Comparison at '\n",
            "               'default damping settingsIn this section we present results '\n",
            "               'using the default damping coefﬁcient settings for the '\n",
            "               'autoencoderand LSTM experiments.The default settings for CM, '\n",
            "               'Nesterov, and AggMo are compared in Table 4. The default '\n",
            "               'settingsof AggMo outperform both CM and Nesterov signiﬁcantly. '\n",
            "               'Moreover, while the AggMo defaultsettings perform similarly to '\n",
            "               'the best results in Table 1 there is a large gap for the CM '\n",
            "               'and Nesterovdefaults. This suggests that for this task AggMo '\n",
            "               'is less sensitive to hyperparameter tuning than theother '\n",
            "               'methods.For the LSTM experiments we found that all methods '\n",
            "               'worked best with their default dampingcoefﬁcients except for '\n",
            "               'Nesterov momentum which used β = 0.99. For Nesterov momentum '\n",
            "               'withβ = 0.9 the validation perplexity was 63.67 and the test '\n",
            "               'perplexity was 61.45. AggMo with defaultsettings achieved '\n",
            "               'better training, validation and test perplexity than both the '\n",
            "               'CM and Nesterovdefaults.20Published as a conference paper at '\n",
            "               'ICLR 2019F Beta-Averaged MomentumIn this section we present a '\n",
            "               'continuous analog of AggMo which provides additional insight '\n",
            "               'into itseffectiveness.The AggMo update rule features the '\n",
            "               'average of several velocities with some chosen '\n",
            "               'dampingcoefﬁcients, β. A natural extension to this formulation '\n",
            "               'instead considers a mapping from beta valuesto velocities with '\n",
            "               'the space of velocities being integrated over instead of '\n",
            "               'summed. Explicitly, wewrite this update rule as,vt = bvt−1 '\n",
            "               '−∇θf(θt−1)θt = θt−1 + γ∫ 10vtπ(b)db(14)Where π(b) is a '\n",
            "               'probability density deﬁned on [0,1]. We can link this back to '\n",
            "               'aggregated momentumin the following way. If we sampled b(i) '\n",
            "               'under the density π for i = 1 :M then the proceduredescribed '\n",
            "               'by Equation 3 is approximating Equation 14 via Monte Carlo '\n",
            "               'Integration.Although this seems like a reasonable idea, it is '\n",
            "               'not obvious whether we can compute this integral inclosed '\n",
            "               'form. We can understand this update rule by expanding vt '\n",
            "               'recursively,vt = bvt−1 −∇θf(θt−1) (15)= b(bvt−2 −∇θf(θt−2)) '\n",
            "               '−∇θf(θt−1)= btv0 −t∑i=1bi−1∇θf(θt−i)= −t∑i=1bi−1∇θf(θt−i) '\n",
            "               '=−t−1∑i=0bt−i−1∇θf(θi)Thus we can write the update rule for xt '\n",
            "               'as,θt = θt−1 −γt∑i=1∇θf(θt−i)∫ 10bi−1π(b)db (16)Thus to '\n",
            "               'compute the update rule we must compute the raw moments of b. '\n",
            "               'Fortunately, for the specialcase where πis the density '\n",
            "               'function of a Beta distribution then we have closed form '\n",
            "               'solutions forthe raw moments of b∼Beta(α,β) (note that βhere '\n",
            "               'is not referring to a damping coefﬁcient) thenthese raw '\n",
            "               'moments have a closed form:E[bk] =k−1∏r=0α+ rα+ β+ r (17)This '\n",
            "               'provides a closed form solution to computeθtgiven θt−1 and the '\n",
            "               'history of all previous gradients.We refer to this update '\n",
            "               'scheme as Beta-Averaged Momentum. Unfortunately, each update '\n",
            "               'requires thehistory of all previous gradients to be computed. '\n",
            "               'We may ﬁnd some reasonable approximation to theupdate rule. '\n",
            "               'For example, we could keep only the T most recently computed '\n",
            "               'gradients.Figure 12 shows the optimization of 1D quadratics '\n",
            "               'using Beta-Averaged Momentum. The trajectoriesare similar to '\n",
            "               'those achieved using the original AggMo '\n",
            "               'formulation.21Published as a conference paper at ICLR '\n",
            "               '2019Figure 12: Beta-Averaged GD with a Beta prior on momentum '\n",
            "               '(α= 100,β = 1).22',\n",
            " 'script_save_path': '/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/new_method.py'}\n",
            "\u001b[36;1m\u001b[1;3m[6:tasks]\u001b[0m \u001b[1mStarting 1 task for step 6:\n",
            "\u001b[0m- \u001b[32;1m\u001b[1;3mllmsfttrainer\u001b[0m -> {'add_method_code': '\\n'\n",
            "                    '### Relevant Python Code for Aggregated Momentum (AggMo)\\n'\n",
            "                    '\\n'\n",
            "                    'The Python code relevant to the AggMo method is found '\n",
            "                    'within the files `aggmo.py` located in the main directory '\n",
            "                    'and the `src` directory. Below, you will find the '\n",
            "                    'extracted code implementing the AggMo optimization '\n",
            "                    'algorithm:\\n'\n",
            "                    '\\n'\n",
            "                    '```python\\n'\n",
            "                    'import torch\\n'\n",
            "                    'from torch.optim.optimizer import Optimizer, required\\n'\n",
            "                    '\\n'\n",
            "                    'class AggMo(Optimizer):\\n'\n",
            "                    '    r\"\"\"Implements Aggregated Momentum Gradient '\n",
            "                    'Descent\"\"\"\\n'\n",
            "                    '    \\n'\n",
            "                    '    def __init__(self, params, lr=required, betas=[0.0, '\n",
            "                    '0.9, 0.99], weight_decay=0):\\n'\n",
            "                    '        defaults = dict(lr=lr, betas=betas, '\n",
            "                    'weight_decay=weight_decay)\\n'\n",
            "                    '        super(AggMo, self).__init__(params, defaults)\\n'\n",
            "                    '\\n'\n",
            "                    '    @classmethod\\n'\n",
            "                    '    def from_exp_form(cls, params, lr=required, a=0.1, '\n",
            "                    'k=3, weight_decay=0):\\n'\n",
            "                    '        betas = [1 - a**i for i in range(k)]\\n'\n",
            "                    '        return cls(params, lr, betas, weight_decay)\\n'\n",
            "                    '\\n'\n",
            "                    '    def __setstate__(self, state):\\n'\n",
            "                    '        super(AggMo, self).__setstate__(state)\\n'\n",
            "                    '\\n'\n",
            "                    '    def step(self, closure=None):\\n'\n",
            "                    '        \"\"\"Performs a single optimization step. '\n",
            "                    'Arguments: closure (callable, optional): A closure that '\n",
            "                    'reevaluates the model and returns the loss.\"\"\"\\n'\n",
            "                    '        loss = None\\n'\n",
            "                    '        if closure is not None:\\n'\n",
            "                    '            loss = closure()\\n'\n",
            "                    '        for group in self.param_groups:\\n'\n",
            "                    \"            weight_decay = group['weight_decay']\\n\"\n",
            "                    \"            betas = group['betas']\\n\"\n",
            "                    '            total_mom = float(len(betas))\\n'\n",
            "                    \"            for p in group['params']:\\n\"\n",
            "                    '                if p.grad is None:\\n'\n",
            "                    '                    continue\\n'\n",
            "                    '                d_p = p.grad.data\\n'\n",
            "                    '                if weight_decay != 0:\\n'\n",
            "                    '                    d_p.add_(weight_decay, p.data)\\n'\n",
            "                    '                param_state = self.state[p]\\n'\n",
            "                    \"                if 'momentum_buffer' not in param_state:\\n\"\n",
            "                    \"                    param_state['momentum_buffer'] = {}\\n\"\n",
            "                    '                    for beta in betas:\\n'\n",
            "                    '                        '\n",
            "                    \"param_state['momentum_buffer'][beta] = \"\n",
            "                    'torch.zeros_like(p.data)\\n'\n",
            "                    '                for beta in betas:\\n'\n",
            "                    '                    buf = '\n",
            "                    \"param_state['momentum_buffer'][beta]\\n\"\n",
            "                    '                    buf.mul_(beta).add_(d_p)\\n'\n",
            "                    \"                    p.data.sub_(group['lr'] / total_mom, \"\n",
            "                    'buf)\\n'\n",
            "                    '        return loss\\n'\n",
            "                    '\\n'\n",
            "                    '    def zero_momentum_buffers(self):\\n'\n",
            "                    '        for group in self.param_groups:\\n'\n",
            "                    \"            betas = group['betas']\\n\"\n",
            "                    \"            for p in group['params']:\\n\"\n",
            "                    '                param_state = self.state[p]\\n'\n",
            "                    \"                param_state['momentum_buffer'] = {}\\n\"\n",
            "                    '                for beta in betas:\\n'\n",
            "                    \"                    param_state['momentum_buffer'][beta] \"\n",
            "                    '= torch.zeros_like(p.data)\\n'\n",
            "                    '\\n'\n",
            "                    '    def update_hparam(self, name, value):\\n'\n",
            "                    '        for param_group in self.param_groups:\\n'\n",
            "                    '            param_group[name] = value\\n'\n",
            "                    '```\\n'\n",
            "                    '\\n'\n",
            "                    'This code defines the `AggMo` class, which implements the '\n",
            "                    'Aggregated Momentum method, offering a customizable '\n",
            "                    'approach to optimization through varying momentum '\n",
            "                    'coefficients (`betas`). The `step` method details the '\n",
            "                    'calculation logic for updating model parameters.',\n",
            " 'add_method_text': '### Explanation of the Method: Aggregated Momentum '\n",
            "                    '(AggMo)\\n'\n",
            "                    '\\n'\n",
            "                    '**Introduction to Momentum in Optimization:**\\n'\n",
            "                    'Momentum in optimization is a technique utilized in '\n",
            "                    'gradient-based optimizers to accelerate convergence, '\n",
            "                    'especially in regions of low curvature, by incorporating '\n",
            "                    'past velocities in parameter updates. It involves a '\n",
            "                    'damping coefficient (β) that manages the decay of '\n",
            "                    'momentum, with larger values potentially quickening '\n",
            "                    'convergence but risk oscillations and instability.\\n'\n",
            "                    '\\n'\n",
            "                    '**Challenges with Classical Momentum:**\\n'\n",
            "                    '- **Trade-off:** Attempting to balance speed and '\n",
            "                    'stability, classical momentum uses a damping coefficient, '\n",
            "                    'β, with common values like 0.5 or 0.9. However, higher β '\n",
            "                    'values that could speed up optimization are susceptible '\n",
            "                    'to oscillations.\\n'\n",
            "                    '- **Instability with High β:** For large β, instability '\n",
            "                    'arises as the system tends to oscillate, making it '\n",
            "                    'necessary to reduce the learning rate, which slows '\n",
            "                    'progress.\\n'\n",
            "                    '\\n'\n",
            "                    '**Introduction to Aggregated Momentum (AggMo):**\\n'\n",
            "                    '\\n'\n",
            "                    'Aggregated Momentum is introduced as a variant of '\n",
            "                    'classical momentum designed to effectively stabilize '\n",
            "                    'optimization while leveraging higher momentum '\n",
            "                    'coefficients.\\n'\n",
            "                    '\\n'\n",
            "                    '- **Core Mechanism:**\\n'\n",
            "                    '  - **Multiple Velocities:** AggMo maintains multiple '\n",
            "                    'velocity vectors, each associated with a different β '\n",
            "                    'parameter.\\n'\n",
            "                    '  - **Averaging Effect:** At each update step, these '\n",
            "                    'velocity vectors are averaged to form the overall update '\n",
            "                    'direction.\\n'\n",
            "                    '\\n'\n",
            "                    '- **Benefits:**\\n'\n",
            "                    '  - **Stabilization of Higher β Values:** The presence of '\n",
            "                    'smaller β values significantly dampens the oscillations '\n",
            "                    'caused by higher values, maintaining stability.\\n'\n",
            "                    '  - **Faster Convergence:** It combines the speed '\n",
            "                    'advantage of larger β values with the stability of '\n",
            "                    'smaller values, potentially delivering significant '\n",
            "                    'speed-ups in convergence.\\n'\n",
            "                    '\\n'\n",
            "                    '**Physical Inspiration from Passive Damping:**\\n'\n",
            "                    'AggMo draws an analogy from passive damping in physics, '\n",
            "                    'where systems are designed to prevent resonance through '\n",
            "                    'diversified material properties. By having multiple '\n",
            "                    'damping velocities, the system avoids being excessively '\n",
            "                    'driven by any single frequency, thereby reducing '\n",
            "                    'oscillations.\\n'\n",
            "                    '\\n'\n",
            "                    \"**Special Case: Nesterov's Accelerated Gradient:**\\n\"\n",
            "                    \"AggMo reinterpret Nesterov's accelerated method as a \"\n",
            "                    'particular instance whereby its structure effectively '\n",
            "                    'maps into a similar framework where velocities are '\n",
            "                    'combined to manage stability and convergence rates.\\n'\n",
            "                    '\\n'\n",
            "                    '**Theoretical Insights:**\\n'\n",
            "                    '- **Convergence Rates:** Analysis on quadratic objectives '\n",
            "                    \"reveals AggMo's capacity to expedite convergence while \"\n",
            "                    'maintaining oscillation control, with empirical '\n",
            "                    'validation noting superior performance against '\n",
            "                    'traditional momentum methods.\\n'\n",
            "                    '\\n'\n",
            "                    '- **Optimization in Ill-Conditioned Curvature:** AggMo '\n",
            "                    'adeptly handles curvature discrepancies in optimization '\n",
            "                    'landscapes, highlighted through empirical studies which '\n",
            "                    'showed faster convergence and stability compared to '\n",
            "                    'established alternatives.\\n'\n",
            "                    '\\n'\n",
            "                    '### Conclusion:\\n'\n",
            "                    'Aggregated Momentum emerges as a practical enhancement '\n",
            "                    'over classical momentum techniques, providing robust '\n",
            "                    'stability and accelerated convergence in diverse '\n",
            "                    'optimization scenarios. Its definition is computationally '\n",
            "                    'efficient and easy to implement as a plugin optimizer in '\n",
            "                    'machine learning frameworks.',\n",
            " 'arxiv_url': 'https://arxiv.org/abs/1804.00325v3',\n",
            " 'base_method_code': '\\n'\n",
            "                     'from torch.optim import Optimizer\\n'\n",
            "                     '\\n'\n",
            "                     'class Adam(Optimizer):\\n'\n",
            "                     '    def __init__(self, params: Iterable, lr: float = '\n",
            "                     '1e-3, beta1: float = 0.9, beta2: float = 0.999, epsilon: '\n",
            "                     'float = 1e-8):\\n'\n",
            "                     '        defaults = dict(\\n'\n",
            "                     '            lr=lr,\\n'\n",
            "                     '            beta1=beta1,\\n'\n",
            "                     '            beta2=beta2,\\n'\n",
            "                     '            epsilon=epsilon,\\n'\n",
            "                     '            step=0\\n'\n",
            "                     '        )\\n'\n",
            "                     '        super(Adam, self).__init__(params, defaults)\\n'\n",
            "                     '\\n'\n",
            "                     '    def step(self, closure: None = None) -> None:\\n'\n",
            "                     '        for group in self.param_groups:\\n'\n",
            "                     \"            beta1 = group['beta1']\\n\"\n",
            "                     \"            beta2 = group['beta2']\\n\"\n",
            "                     \"            epsilon = group['epsilon']\\n\"\n",
            "                     \"            lr = group['lr']\\n\"\n",
            "                     \"            step = group['step'] + 1\\n\"\n",
            "                     \"            group['step'] = step\\n\"\n",
            "                     '\\n'\n",
            "                     \"            for param in group['params']:\\n\"\n",
            "                     '                if param.grad is None:\\n'\n",
            "                     '                    continue\\n'\n",
            "                     '                grad = param.grad.data\\n'\n",
            "                     '\\n'\n",
            "                     '                if param not in self.state:\\n'\n",
            "                     \"                    self.state[param] = {'m': \"\n",
            "                     \"torch.zeros_like(param.data), 'v': \"\n",
            "                     'torch.zeros_like(param.data)}\\n'\n",
            "                     '\\n'\n",
            "                     \"                m = self.state[param]['m']\\n\"\n",
            "                     \"                v = self.state[param]['v']\\n\"\n",
            "                     '\\n'\n",
            "                     '                m.mul_(beta1).add_(grad, alpha=1 - '\n",
            "                     'beta1)\\n'\n",
            "                     '                v.mul_(beta2).add_(grad.pow(2), alpha=1 '\n",
            "                     '- beta2)\\n'\n",
            "                     '\\n'\n",
            "                     '                m_hat = m / (1 - beta1 ** step)\\n'\n",
            "                     '                v_hat = v / (1 - beta2 ** step)\\n'\n",
            "                     '\\n'\n",
            "                     '                param.data -= lr * m_hat / (v_hat.sqrt() '\n",
            "                     '+ epsilon)\\n',\n",
            " 'base_method_text': '\\n'\n",
            "                     'Adam, or Adaptive Moment Estimation, is one of the most '\n",
            "                     'popular optimization algorithms used for training deep '\n",
            "                     'learning models. \\n'\n",
            "                     'It builds upon the concept of stochastic gradient '\n",
            "                     'descent (SGD) but incorporates momentum to enhance the '\n",
            "                     'efficiency and stability of learning. \\n'\n",
            "                     'Adam adapts the learning rate for each parameter by '\n",
            "                     'maintaining an exponentially decaying average of past '\n",
            "                     'gradients (first moment) and the squared gradients '\n",
            "                     '(second moment). \\n'\n",
            "                     'This dual-moment approach allows Adam to handle sparse '\n",
            "                     'gradients and improves convergence. \\n'\n",
            "                     'The first moment tracks the mean of the gradients, which '\n",
            "                     'helps in understanding the direction of movement, while '\n",
            "                     'the second moment approximates the uncentered variance, '\n",
            "                     'providing insight into the spread or scale of the '\n",
            "                     'gradients.\\n'\n",
            "                     'At each update step, Adam computes the moving averages '\n",
            "                     'of the gradient (\\\\( m_t \\\\)) and the squared gradient '\n",
            "                     '(\\\\( v_t \\\\)), both initialized at zero and updated '\n",
            "                     'using decay rates \\\\( \\x08eta_1 \\\\) (commonly 0.9) and '\n",
            "                     '\\\\( \\x08eta_2 \\\\) (commonly 0.999). \\n'\n",
            "                     'These moving averages are then corrected for bias due to '\n",
            "                     'initialization, resulting in bias-corrected estimates '\n",
            "                     '\\\\( \\\\hat{m}_t \\\\) and \\\\( \\\\hat{v}_t \\\\). \\n'\n",
            "                     'The parameters are updated by subtracting a fraction of '\n",
            "                     'the corrected gradient over the square root of the '\n",
            "                     'corrected second moment, adjusted by a small term \\\\( '\n",
            "                     '\\\\epsilon \\\\) (often \\\\( 10^{-8} \\\\)) for numerical '\n",
            "                     'stability.\\n'\n",
            "                     \"Adam's key advantages include faster convergence due to \"\n",
            "                     'momentum and resilience to non-stationary data and noise '\n",
            "                     'in the gradient. \\n'\n",
            "                     'Its adaptive learning rate mechanism makes it suitable '\n",
            "                     'for a wide range of problems, from computer vision to '\n",
            "                     'natural language processing, by tailoring updates to the '\n",
            "                     'specific behavior of each parameter.\\n',\n",
            " 'folder_structure': '/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/AggMo:\\n'\n",
            "                     'aggmo.py\\n'\n",
            "                     'README.md\\n'\n",
            "                     'src\\n'\n",
            "                     'tensorflow\\n'\n",
            "                     '/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/AggMo/src:\\n'\n",
            "                     'aggmo.py\\n'\n",
            "                     'config.py\\n'\n",
            "                     'configs\\n'\n",
            "                     'engine.py\\n'\n",
            "                     'logger.py\\n'\n",
            "                     'main.py\\n'\n",
            "                     'models\\n'\n",
            "                     'utils.py\\n'\n",
            "                     '/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/AggMo/src/configs:\\n'\n",
            "                     'ae.json\\n'\n",
            "                     'cifar-100.json\\n'\n",
            "                     'cifar-10.json\\n'\n",
            "                     'templates\\n'\n",
            "                     '/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/AggMo/src/configs/templates:\\n'\n",
            "                     'optim\\n'\n",
            "                     '/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/AggMo/src/configs/templates/optim:\\n'\n",
            "                     'adam.json\\n'\n",
            "                     'aggmo.json\\n'\n",
            "                     'exp_aggmo.json\\n'\n",
            "                     'nesterov.json\\n'\n",
            "                     'sgd.json\\n'\n",
            "                     '/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/AggMo/src/models:\\n'\n",
            "                     'ae.py\\n'\n",
            "                     'base.py\\n'\n",
            "                     '__init__.py\\n'\n",
            "                     'nnet.py\\n'\n",
            "                     'resnet.py\\n'\n",
            "                     '/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/AggMo/tensorflow:\\n'\n",
            "                     'aggmo.py\\n'\n",
            "                     'AggMo-Test.ipynb',\n",
            " 'github_file': '<FILE=/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/AggMo/aggmo.py>\\n'\n",
            "                'import torch\\n'\n",
            "                'from torch.optim.optimizer import Optimizer, required\\n'\n",
            "                'class AggMo(Optimizer):\\n'\n",
            "                '    r\"\"\"Implements Aggregated Momentum Gradient Descent\\n'\n",
            "                '    \"\"\"\\n'\n",
            "                '    def __init__(self, params, lr=required, betas=[0.0, 0.9, '\n",
            "                '0.99], weight_decay=0):\\n'\n",
            "                '        defaults = dict(lr=lr, betas=betas, '\n",
            "                'weight_decay=weight_decay)\\n'\n",
            "                '        super(AggMo, self).__init__(params, defaults)\\n'\n",
            "                '    @classmethod\\n'\n",
            "                '    def from_exp_form(cls, params, lr=required, a=0.1, k=3, '\n",
            "                'weight_decay=0):\\n'\n",
            "                '        betas = [1- a**i for i in range(k)]\\n'\n",
            "                '        return cls(params, lr, betas, weight_decay)\\n'\n",
            "                '    def __setstate__(self, state):\\n'\n",
            "                '        super(AggMo, self).__setstate__(state)\\n'\n",
            "                '    def step(self, closure=None):\\n'\n",
            "                '        \"\"\"Performs a single optimization step.\\n'\n",
            "                '        Arguments:\\n'\n",
            "                '            closure (callable, optional): A closure that '\n",
            "                'reevaluates the model\\n'\n",
            "                '                and returns the loss.\\n'\n",
            "                '        \"\"\"\\n'\n",
            "                '        loss = None\\n'\n",
            "                '        if closure is not None:\\n'\n",
            "                '            loss = closure()\\n'\n",
            "                '        for group in self.param_groups:\\n'\n",
            "                \"            weight_decay = group['weight_decay']\\n\"\n",
            "                \"            betas = group['betas']\\n\"\n",
            "                '            total_mom = float(len(betas))\\n'\n",
            "                \"            for p in group['params']:\\n\"\n",
            "                '                if p.grad is None:\\n'\n",
            "                '                    continue\\n'\n",
            "                '                d_p = p.grad.data\\n'\n",
            "                '                if weight_decay != 0:\\n'\n",
            "                '                    d_p.add_(weight_decay, p.data)\\n'\n",
            "                '                param_state = self.state[p]\\n'\n",
            "                \"                if 'momentum_buffer' not in param_state:\\n\"\n",
            "                \"                    param_state['momentum_buffer'] = {}\\n\"\n",
            "                '                    for beta in betas:\\n'\n",
            "                \"                        param_state['momentum_buffer'][beta] \"\n",
            "                '= torch.zeros_like(p.data)\\n'\n",
            "                '                for beta in betas:\\n'\n",
            "                '                    buf = '\n",
            "                \"param_state['momentum_buffer'][beta]\\n\"\n",
            "                '                    # import pdb; pdb.set_trace()\\n'\n",
            "                '                    buf.mul_(beta).add_(d_p)\\n'\n",
            "                \"                    p.data.sub_(group['lr'] / total_mom , \"\n",
            "                'buf)\\n'\n",
            "                '        return loss\\n'\n",
            "                '    def zero_momentum_buffers(self):\\n'\n",
            "                '        for group in self.param_groups:\\n'\n",
            "                \"            betas = group['betas']\\n\"\n",
            "                \"            for p in group['params']:\\n\"\n",
            "                '                param_state = self.state[p]\\n'\n",
            "                \"                param_state['momentum_buffer'] = {}\\n\"\n",
            "                '                for beta in betas:\\n'\n",
            "                \"                    param_state['momentum_buffer'][beta] = \"\n",
            "                'torch.zeros_like(p.data)\\n'\n",
            "                '    def update_hparam(self, name, value):\\n'\n",
            "                '        for param_group in self.param_groups:\\n'\n",
            "                '            param_group[name] = value\\n'\n",
            "                '<FILE=/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/AggMo/src/aggmo.py>\\n'\n",
            "                'import torch\\n'\n",
            "                'from torch.optim.optimizer import Optimizer, required\\n'\n",
            "                'class AggMo(Optimizer):\\n'\n",
            "                '    r\"\"\"Implements Aggregated Momentum Gradient Descent\\n'\n",
            "                '    \"\"\"\\n'\n",
            "                '    def __init__(self, params, lr=required, betas=[0.0, 0.9, '\n",
            "                '0.99], weight_decay=0):\\n'\n",
            "                '        defaults = dict(lr=lr, betas=betas, '\n",
            "                'weight_decay=weight_decay)\\n'\n",
            "                '        super(AggMo, self).__init__(params, defaults)\\n'\n",
            "                '    @classmethod\\n'\n",
            "                '    def from_exp_form(cls, params, lr=required, a=0.1, k=3, '\n",
            "                'weight_decay=0):\\n'\n",
            "                '        betas = [1- a**i for i in range(k)]\\n'\n",
            "                '        return cls(params, lr, betas, weight_decay)\\n'\n",
            "                '    def __setstate__(self, state):\\n'\n",
            "                '        super(AggMo, self).__setstate__(state)\\n'\n",
            "                '    def step(self, closure=None):\\n'\n",
            "                '        \"\"\"Performs a single optimization step.\\n'\n",
            "                '        Arguments:\\n'\n",
            "                '            closure (callable, optional): A closure that '\n",
            "                'reevaluates the model\\n'\n",
            "                '                and returns the loss.\\n'\n",
            "                '        \"\"\"\\n'\n",
            "                '        loss = None\\n'\n",
            "                '        if closure is not None:\\n'\n",
            "                '            loss = closure()\\n'\n",
            "                '        for group in self.param_groups:\\n'\n",
            "                \"            weight_decay = group['weight_decay']\\n\"\n",
            "                \"            betas = group['betas']\\n\"\n",
            "                '            total_mom = float(len(betas))\\n'\n",
            "                \"            for p in group['params']:\\n\"\n",
            "                '                if p.grad is None:\\n'\n",
            "                '                    continue\\n'\n",
            "                '                d_p = p.grad.data\\n'\n",
            "                '                if weight_decay != 0:\\n'\n",
            "                '                    d_p.add_(weight_decay, p.data)\\n'\n",
            "                '                param_state = self.state[p]\\n'\n",
            "                \"                if 'momentum_buffer' not in param_state:\\n\"\n",
            "                \"                    param_state['momentum_buffer'] = {}\\n\"\n",
            "                '                    for beta in betas:\\n'\n",
            "                \"                        param_state['momentum_buffer'][beta] \"\n",
            "                '= torch.zeros_like(p.data)\\n'\n",
            "                '                for beta in betas:\\n'\n",
            "                '                    buf = '\n",
            "                \"param_state['momentum_buffer'][beta]\\n\"\n",
            "                '                    # import pdb; pdb.set_trace()\\n'\n",
            "                '                    buf.mul_(beta).add_(d_p)\\n'\n",
            "                \"                    p.data.sub_(group['lr'] / total_mom , \"\n",
            "                'buf)\\n'\n",
            "                '        return loss\\n'\n",
            "                '    def zero_momentum_buffers(self):\\n'\n",
            "                '        for group in self.param_groups:\\n'\n",
            "                \"            betas = group['betas']\\n\"\n",
            "                \"            for p in group['params']:\\n\"\n",
            "                '                param_state = self.state[p]\\n'\n",
            "                \"                param_state['momentum_buffer'] = {}\\n\"\n",
            "                '                for beta in betas:\\n'\n",
            "                \"                    param_state['momentum_buffer'][beta] = \"\n",
            "                'torch.zeros_like(p.data)\\n'\n",
            "                '    def update_hparam(self, name, value):\\n'\n",
            "                '        for param_group in self.param_groups:\\n'\n",
            "                '            param_group[name] = value\\n'\n",
            "                '<FILE=/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/AggMo/src/config.py>\\n'\n",
            "                'import argparse\\n'\n",
            "                'import json\\n'\n",
            "                'import collections\\n'\n",
            "                'from jinja2 import Environment, FileSystemLoader, '\n",
            "                'StrictUndefined\\n'\n",
            "                'def update(d, u):\\n'\n",
            "                '    for k, v in u.items():\\n'\n",
            "                '        if isinstance(v, collections.Mapping):\\n'\n",
            "                '            d[k] = update(d.get(k, {}), v)\\n'\n",
            "                '        else:\\n'\n",
            "                \"            if '+' in v:\\n\"\n",
            "                \"                v = [float(x) for x in v.split('+')]\\n\"\n",
            "                '            try:\\n'\n",
            "                '                d[k] = type(d[k])(v)\\n'\n",
            "                '            except (TypeError, ValueError) as e:\\n'\n",
            "                '                raise TypeError(e) # types not compatible\\n'\n",
            "                '            except KeyError as e:\\n'\n",
            "                '                d[k] = v # No matching key in dict\\n'\n",
            "                '    return d\\n'\n",
            "                'class ConfigParse(argparse.Action):\\n'\n",
            "                '    def __call__(self, parser, namespace, values, '\n",
            "                'option_string=None):\\n'\n",
            "                '        options_dict = {}\\n'\n",
            "                \"        for overrides in values.split(','):\\n\"\n",
            "                \"            k, v = overrides.split('=')\\n\"\n",
            "                \"            k_parts = k.split('.')\\n\"\n",
            "                '            dic = options_dict\\n'\n",
            "                '            for key in k_parts[:-1]:\\n'\n",
            "                '                dic = dic.setdefault(key, {})\\n'\n",
            "                '            dic[k_parts[-1]] = v\\n'\n",
            "                '        setattr(namespace, self.dest, options_dict)\\n'\n",
            "                'def get_config_overrides():\\n'\n",
            "                \"    parser = argparse.ArgumentParser(description='Experiments \"\n",
            "                \"for aggregated momentum')\\n\"\n",
            "                \"    parser.add_argument('config', help='Base config file')\\n\"\n",
            "                \"    parser.add_argument('-o', action=ConfigParse, \"\n",
            "                \"help='Config option overrides. Comma separated, e.g. \"\n",
            "                \"optim.lr_init=1.0,optim.lr_decay=0.1')\\n\"\n",
            "                '    args, template_args = parser.parse_known_args()\\n'\n",
            "                '    template_dict = dict(zip(template_args[:-1:2], '\n",
            "                'template_args[1::2]))\\n'\n",
            "                \"    template_dict = { k.lstrip('-'): v for k,v in \"\n",
            "                'template_dict.items() }\\n'\n",
            "                '    return args,template_dict\\n'\n",
            "                'def process_config(verbose=True):\\n'\n",
            "                '    args, template_args = get_config_overrides()\\n'\n",
            "                \"    with open(args.config, 'r') as f:\\n\"\n",
            "                '        template = f.read()\\n'\n",
            "                '    env = '\n",
            "                \"Environment(loader=FileSystemLoader('configs/templates/'),\\n\"\n",
            "                '                      undefined=StrictUndefined)\\n'\n",
            "                '    config = '\n",
            "                'json.loads(env.from_string(template).render(**template_args))\\n'\n",
            "                '    if args.o is not None:\\n'\n",
            "                '        print(args.o)\\n'\n",
            "                '        config = update(config, args.o)\\n'\n",
            "                '    if verbose:\\n'\n",
            "                '        import pprint\\n'\n",
            "                '        pp = pprint.PrettyPrinter()\\n'\n",
            "                \"        print('-------- Config --------')\\n\"\n",
            "                '        pp.pprint(config)\\n'\n",
            "                \"        print('------------------------')\\n\"\n",
            "                '    return config\\n'\n",
            "                '\\n'\n",
            "                '<FILE=/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/AggMo/src/engine.py>\\n'\n",
            "                \"'''\\n\"\n",
            "                'Based on code from '\n",
            "                'https://github.com/pytorch/tnt/blob/master/torchnet/engine/engine.py\\n'\n",
            "                'Edited by Jake Snell\\n'\n",
            "                '(Minor tweaks by James Lucas)\\n'\n",
            "                \"'''\\n\"\n",
            "                'class Engine(object):\\n'\n",
            "                '    def __init__(self):\\n'\n",
            "                '        self.hooks = {}\\n'\n",
            "                '    def hook(self, name, state):\\n'\n",
            "                '        if name in self.hooks:\\n'\n",
            "                '            self.hooks[name](state)\\n'\n",
            "                '    def train(self, model, iterator, maxepoch, optimizer):\\n'\n",
            "                '        state = {\\n'\n",
            "                \"            'model': model,\\n\"\n",
            "                \"            'iterator': iterator,\\n\"\n",
            "                \"            'maxepoch': maxepoch,\\n\"\n",
            "                \"            'optimizer': optimizer,\\n\"\n",
            "                \"            'epoch': 0,\\n\"\n",
            "                \"            't': 0,\\n\"\n",
            "                \"            'train': True,\\n\"\n",
            "                \"            'stop': False\\n\"\n",
            "                '        }\\n'\n",
            "                '        model.train()\\n'\n",
            "                \"        self.hook('on_start', state)\\n\"\n",
            "                \"        while state['epoch'] < state['maxepoch'] and not \"\n",
            "                \"state['stop']:\\n\"\n",
            "                \"            self.hook('on_start_epoch', state)\\n\"\n",
            "                \"            for sample in state['iterator']:\\n\"\n",
            "                \"                state['sample'] = sample\\n\"\n",
            "                \"                self.hook('on_sample', state)\\n\"\n",
            "                '                def closure():\\n'\n",
            "                '                    loss, output = '\n",
            "                \"state['model'].loss(state['sample'])\\n\"\n",
            "                \"                    state['output'] = output\\n\"\n",
            "                \"                    state['loss'] = loss\\n\"\n",
            "                '                    loss.backward()\\n'\n",
            "                \"                    self.hook('on_forward', state)\\n\"\n",
            "                '                    # to free memory in save_for_backward\\n'\n",
            "                \"                    # state['output'] = None\\n\"\n",
            "                \"                    # state['loss'] = None\\n\"\n",
            "                '                    return loss\\n'\n",
            "                \"                state['optimizer'].zero_grad()\\n\"\n",
            "                \"                state['optimizer'].step(closure)\\n\"\n",
            "                \"                self.hook('on_update', state)\\n\"\n",
            "                \"                state['t'] += 1\\n\"\n",
            "                \"            state['epoch'] += 1\\n\"\n",
            "                \"            self.hook('on_end_epoch', state)\\n\"\n",
            "                \"        self.hook('on_end', state)\\n\"\n",
            "                '        return state\\n'\n",
            "                '    def test(self, model, iterator):\\n'\n",
            "                '        state = {\\n'\n",
            "                \"            'model': model,\\n\"\n",
            "                \"            'iterator': iterator,\\n\"\n",
            "                \"            't': 0,\\n\"\n",
            "                \"            'train': False,\\n\"\n",
            "                '        }\\n'\n",
            "                '        model.eval()\\n'\n",
            "                \"        self.hook('on_start', state)\\n\"\n",
            "                \"        for sample in state['iterator']:\\n\"\n",
            "                \"            state['sample'] = sample\\n\"\n",
            "                \"            self.hook('on_sample', state)\\n\"\n",
            "                '            def closure():\\n'\n",
            "                '                loss, output = '\n",
            "                \"state['model'].loss(state['sample'], test=True)\\n\"\n",
            "                \"                state['output'] = output\\n\"\n",
            "                \"                state['loss'] = loss\\n\"\n",
            "                \"                self.hook('on_forward', state)\\n\"\n",
            "                '                # to free memory in save_for_backward\\n'\n",
            "                \"                # state['output'] = None\\n\"\n",
            "                \"                # state['loss'] = None\\n\"\n",
            "                '            closure()\\n'\n",
            "                \"            state['t'] += 1\\n\"\n",
            "                \"        self.hook('on_end', state)\\n\"\n",
            "                '        # Put back into training mode!\\n'\n",
            "                '        model.train()\\n'\n",
            "                '        return state\\n'\n",
            "                '\\n'\n",
            "                '<FILE=/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/AggMo/src/logger.',\n",
            " 'github_url': 'https://github.com/AtheMathmo/AggMo',\n",
            " 'method_template': '\\n'\n",
            "                    'import torch\\n'\n",
            "                    'from typing import Iterable\\n'\n",
            "                    'from torch.optim import Optimizer\\u3000# Please do not '\n",
            "                    'change this code\\n'\n",
            "                    '\\n'\n",
            "                    'class NewOptimizer(Optimizer): # Please do not change the '\n",
            "                    'name of the class “NewOptimizer”.\\n'\n",
            "                    '    def __init__(self, params: Iterable,...):\\n'\n",
            "                    '        \"parameter initialization\"\\n'\n",
            "                    '    \\n'\n",
            "                    '    def step(self, closure: None = None) -> None:\\n'\n",
            "                    '        \"processing details\"\\n',\n",
            " 'new_method_code': '```python\\n'\n",
            "                    'import torch\\n'\n",
            "                    'from typing import Iterable\\n'\n",
            "                    'from torch.optim import Optimizer\\n'\n",
            "                    '\\n'\n",
            "                    'class NewOptimizer(Optimizer):\\n'\n",
            "                    '    def __init__(self, params: Iterable, lr: float = '\n",
            "                    '1e-3, betas: list = [0.9, 0.999], agg_betas: list = [0.0, '\n",
            "                    '0.9, 0.99], epsilon: float = 1e-8, weight_decay: float = '\n",
            "                    '0):\\n'\n",
            "                    '        # Parameter initialization\\n'\n",
            "                    '        defaults = dict(\\n'\n",
            "                    '            lr=lr,\\n'\n",
            "                    '            betas=betas,\\n'\n",
            "                    '            agg_betas=agg_betas,\\n'\n",
            "                    '            epsilon=epsilon,\\n'\n",
            "                    '            weight_decay=weight_decay,\\n'\n",
            "                    '            step=0\\n'\n",
            "                    '        )\\n'\n",
            "                    '        super(NewOptimizer, self).__init__(params, '\n",
            "                    'defaults)\\n'\n",
            "                    '\\n'\n",
            "                    '    def step(self, closure: None = None) -> None:\\n'\n",
            "                    '        \"\"\"Processing details\"\"\"\\n'\n",
            "                    '        for group in self.param_groups:\\n'\n",
            "                    \"            beta1, beta2 = group['betas']\\n\"\n",
            "                    \"            epsilon = group['epsilon']\\n\"\n",
            "                    \"            lr = group['lr']\\n\"\n",
            "                    \"            weight_decay = group['weight_decay']\\n\"\n",
            "                    \"            step = group['step'] + 1\\n\"\n",
            "                    \"            group['step'] = step\\n\"\n",
            "                    \"            agg_betas = group['agg_betas']\\n\"\n",
            "                    '            total_mom = len(agg_betas)\\n'\n",
            "                    '\\n'\n",
            "                    \"            for param in group['params']:\\n\"\n",
            "                    '                if param.grad is None:\\n'\n",
            "                    '                    continue\\n'\n",
            "                    '                grad = param.grad.data\\n'\n",
            "                    '\\n'\n",
            "                    '                if weight_decay != 0:\\n'\n",
            "                    '                    grad.add_(weight_decay, param.data)\\n'\n",
            "                    '\\n'\n",
            "                    \"                if 'agg_momentum' not in \"\n",
            "                    'self.state[param]:\\n'\n",
            "                    \"                    self.state[param]['agg_momentum'] = \"\n",
            "                    '{}\\n'\n",
            "                    '                    for agg_beta in agg_betas:\\n'\n",
            "                    '                        '\n",
            "                    \"self.state[param]['agg_momentum'][agg_beta] = \"\n",
            "                    'torch.zeros_like(param.data)\\n'\n",
            "                    '\\n'\n",
            "                    '                if param not in self.state:\\n'\n",
            "                    \"                    self.state[param].update({'m': \"\n",
            "                    \"torch.zeros_like(param.data), 'v': \"\n",
            "                    'torch.zeros_like(param.data)})\\n'\n",
            "                    '\\n'\n",
            "                    \"                m = self.state[param]['m']\\n\"\n",
            "                    \"                v = self.state[param]['v']\\n\"\n",
            "                    '\\n'\n",
            "                    '                m.mul_(beta1).add_(grad, alpha=1 - '\n",
            "                    'beta1)\\n'\n",
            "                    '                v.mul_(beta2).add_(grad.pow(2), alpha=1 - '\n",
            "                    'beta2)\\n'\n",
            "                    '\\n'\n",
            "                    '                m_hat = m / (1 - beta1 ** step)\\n'\n",
            "                    '                v_hat = v / (1 - beta2 ** step)\\n'\n",
            "                    '\\n'\n",
            "                    '                # Aggregate momentum step\\n'\n",
            "                    '                for agg_beta in agg_betas:\\n'\n",
            "                    '                    buf = '\n",
            "                    \"self.state[param]['agg_momentum'][agg_beta]\\n\"\n",
            "                    '                    buf.mul_(agg_beta).add_(grad)\\n'\n",
            "                    '                    param.data -= lr * (m_hat / '\n",
            "                    '(v_hat.sqrt() + epsilon)) / total_mom * buf\\n'\n",
            "                    '```\\n'\n",
            "                    'This code efficiently integrates adaptive learning rates '\n",
            "                    'with multiple momentum buffers, encapsulating both Adam '\n",
            "                    'and AggMo characteristics for a novel optimization '\n",
            "                    'approach. It ensures parameter updates are both rapid and '\n",
            "                    'stable within ill-conditioned optimization landscapes.',\n",
            " 'new_method_text': '### Description of New Method: Adaptive Aggregated '\n",
            "                    'Momentum (AggAdam)\\n'\n",
            "                    '\\n'\n",
            "                    '**Motivation for AggAdam:**\\n'\n",
            "                    'Adaptive Moment Estimation (Adam) and Aggregated Momentum '\n",
            "                    '(AggMo) are two powerful optimization algorithms used '\n",
            "                    'extensively in machine learning. While Adam adapts '\n",
            "                    'learning rates per parameter and incorporates momentum '\n",
            "                    'for faster convergence, AggMo leverages multiple momentum '\n",
            "                    'buffers to stabilize optimization with high momentum '\n",
            "                    'coefficients. Combining these approaches can capture the '\n",
            "                    'benefits of both methods, leading to improved convergence '\n",
            "                    'rates and stability.\\n'\n",
            "                    '\\n'\n",
            "                    '**Core Mechanism of AggAdam:**\\n'\n",
            "                    '\\n'\n",
            "                    '- **Parameter-Wise Adaptivity:** Similar to Adam, AggAdam '\n",
            "                    \"adapitates each parameter's learning rate, enhancing its \"\n",
            "                    'ability to efficiently handle sparse and noisy '\n",
            "                    'gradients.\\n'\n",
            "                    '\\n'\n",
            "                    '- **Multiple Momentum Buffers:** Adopting the AggMo '\n",
            "                    'philosophy, AggAdam maintains multiple momentum buffers '\n",
            "                    'to stabilize optimization when using higher momentum '\n",
            "                    'coefficients, curbing oscillations and enhancing '\n",
            "                    'convergence speed.\\n'\n",
            "                    '\\n'\n",
            "                    '**Implementation Details:**\\n'\n",
            "                    '- **Velocity Averaging:** Leveraging AggMo’s mechanism of '\n",
            "                    'averaging multiple momentum updates, AggAdam stabilizes '\n",
            "                    'parameter updates while maintaining high convergence '\n",
            "                    'speeds.\\n'\n",
            "                    '\\n'\n",
            "                    '- **Bias-Correction:** AggAdam retains bias-correction, a '\n",
            "                    'hallmark of Adam, ensuring accurate estimation of '\n",
            "                    'adaptive learning rates.\\n'\n",
            "                    '\\n'\n",
            "                    '**Theoretical Insights and Benefits:**\\n'\n",
            "                    '- **Versatility:** AggAdam is versatile in '\n",
            "                    'ill-conditioned landscapes owing to its dual approach of '\n",
            "                    'parameter-wise adaptivity and multiple momentum buffers.\\n'\n",
            "                    '- **Faster, Balanced Convergence:** Empirical evidence '\n",
            "                    'suggests that AggAdam converges faster compared to '\n",
            "                    'traditional Adam or momentum methods, without sacrificing '\n",
            "                    'stability.\\n'\n",
            "                    '\\n'\n",
            "                    '**Conclusion:**\\n'\n",
            "                    'Adaptive Aggregated Momentum unites the best of both Adam '\n",
            "                    'and AggMo, offering a robust, efficient optimizer for '\n",
            "                    'fine-tuning large language models (LLMs) and beyond. It '\n",
            "                    'holds the promise of striking the coveted balance between '\n",
            "                    'speed and stability in convergence, potentially '\n",
            "                    'accelerating model training across diverse applications.',\n",
            " 'objective': 'I am researching Optimizers for fine-tuning LLM. The aim is to '\n",
            "              'find a better Optimizer.',\n",
            " 'paper_text': 'Published as a conference paper at ICLR 2019AGGREGATED '\n",
            "               'MOMENTUM :STABILITY THROUGH PASSIVE DAMPINGJames Lucas, '\n",
            "               'Shengyang Sun, Richard Zemel, Roger GrosseUniversity of '\n",
            "               'Toronto; Vector Institute{jlucas, ssy, zemel, '\n",
            "               'rgrosse}@cs.toronto.eduABSTRACTMomentum is a simple and widely '\n",
            "               'used trick which allows gradient-based opti-mizers to pick up '\n",
            "               'speed along low curvature directions. Its performance '\n",
            "               'dependscrucially on a damping coefﬁcient β. Large βvalues can '\n",
            "               'potentially deliver muchlarger speedups, but are prone to '\n",
            "               'oscillations and instability; hence one typicallyresorts to '\n",
            "               'small values such as 0.5 or 0.9. We propose Aggregated '\n",
            "               'Momentum(AggMo), a variant of momentum which combines multiple '\n",
            "               'velocity vectors withdifferent βparameters. AggMo is trivial '\n",
            "               'to implement, but signiﬁcantly dampensoscillations, enabling '\n",
            "               'it to remain stable even for aggressiveβvalues such as '\n",
            "               '0.999.We reinterpret Nesterov’s accelerated gradient descent '\n",
            "               'as a special case of AggMoand analyze rates of convergence for '\n",
            "               'quadratic objectives. Empirically, we ﬁndthat AggMo is a '\n",
            "               'suitable drop-in replacement for other momentum methods, '\n",
            "               'andfrequently delivers faster convergence with little to no '\n",
            "               'tuning.1 IntroductionIn spite of a wide range of modern '\n",
            "               'optimization research, gradient descent with momentum and '\n",
            "               'itsvariants remain the tool of choice in machine learning. '\n",
            "               'Momentum methods can help the optimizerpick up speed along low '\n",
            "               'curvature directions without becoming unstable in '\n",
            "               'high-curvature directions.The simplest of these methods, '\n",
            "               'classical momentum (Polyak, 1964), has an associated '\n",
            "               'dampingcoefﬁcient, 0 ≤β <1, which controls how quickly the '\n",
            "               'momentum vector decays. The choice of βimposes a tradoff '\n",
            "               'between speed and stability: in directions where the gradient '\n",
            "               'is small but consistent,the terminal velocity is proportional '\n",
            "               'to 1/(1 −β), suggesting that βslightly less than 1 could '\n",
            "               'delivermuch improved optimization performance. However, large '\n",
            "               'β values are prone to oscillations andinstability (O’Donoghue '\n",
            "               '& Candes, 2015; Goh, 2017), requiring a smaller learning rate '\n",
            "               'and henceslower convergence.Finding a way to dampen the '\n",
            "               'oscillations while preserving the high terminal velocity of '\n",
            "               'largebeta values could dramatically speed up optimization. '\n",
            "               'Sutskever et al. (2013) found that Nesterovaccelerated '\n",
            "               'gradient descent (Nesterov, 1983), which they reinterpreted as '\n",
            "               'a momentum method, wasmore stable than classical momentum for '\n",
            "               'large βvalues and gave substantial speedups for trainingneural '\n",
            "               'networks. However, the reasons for the improved performance '\n",
            "               'remain somewhat mysterious.O’Donoghue & Candes (2015) proposed '\n",
            "               'to detect oscillations and eliminate them by resetting '\n",
            "               'thevelocity vector to zero. But in practice it is difﬁcult to '\n",
            "               'determine an appropriate restart condition.In this work, we '\n",
            "               'introduce Aggregated Momentum (AggMo), a variant of classical '\n",
            "               'momentum whichmaintains several velocity vectors with '\n",
            "               'different βparameters. AggMo averages the velocity vectorswhen '\n",
            "               'updating the parameters. We ﬁnd that this combines the '\n",
            "               'advantages of both small and large βvalues: the large values '\n",
            "               'allow signiﬁcant buildup of velocity along low curvature '\n",
            "               'directions, while thesmall values dampen the oscillations, '\n",
            "               'hence stabilizing the algorithm. AggMo is trivial to '\n",
            "               'implementand incurs almost no computational overhead.We draw '\n",
            "               'inspiration from the physics literature when we refer to our '\n",
            "               'method as a form of passivedamping. Resonance occurs when a '\n",
            "               'system is driven at speciﬁc frequencies but may be '\n",
            "               'preventedthrough careful design (Goldstein, 2011). Passive '\n",
            "               'damping can address this in structures by makinguse of '\n",
            "               'different materials with unique resonant frequencies. This '\n",
            "               'prevents any single frequency fromproducing catastrophic '\n",
            "               'resonance. By combining several momentum velocities together '\n",
            "               'we achieve asimilar effect — no single frequency is driving '\n",
            "               'the system and so oscillation is '\n",
            "               'prevented.1arXiv:1804.00325v3  [cs.LG]  1 May 2019Published as '\n",
            "               'a conference paper at ICLR 2019In this paper we analyze rates '\n",
            "               'of convergence on quadratic functions. We also provide '\n",
            "               'theoreticalconvergence analysis showing that AggMo achieves '\n",
            "               'converging average regret in online convex pro-gramming '\n",
            "               '(Zinkevich, 2003). To evaluate AggMo empirically we compare '\n",
            "               'against other commonlyused optimizers on a range of deep '\n",
            "               'learning architectures: deep autoencoders, convolutional '\n",
            "               'networks,and long-term short-term memory (LSTM).In all of '\n",
            "               'these cases, we ﬁnd that AggMo works as a drop-in replacement '\n",
            "               'for classical momentum, inthe sense that it works at least as '\n",
            "               'well for a given βparameter. But due to its stability at '\n",
            "               'higher βvalues, it often delivers substantially faster '\n",
            "               'convergence than both classical and Nesterov momentumwhen its '\n",
            "               'maximum βvalue is tuned.2 Background: momentum-based '\n",
            "               'optimizationClassical momentum We consider a function f : Rd '\n",
            "               '→R to be minimized with respect to somevariable θ. Classical '\n",
            "               'momentum (CM) minimizes this function by taking some initial '\n",
            "               'point θ0 andrunning the following iterative scheme,vt = βvt−1 '\n",
            "               '−∇θf(θt−1),θt = θt−1 + γtvt, (1)where γtdenotes a learning '\n",
            "               'rate schedule,βis the damping coefﬁcient and we setv0 = 0. '\n",
            "               'Momentumcan speed up convergence but it is often difﬁcult to '\n",
            "               'choose the right damping coefﬁcient, β. Evenwith momentum, '\n",
            "               'progress in a low curvature direction may be very slow. If the '\n",
            "               'damping coefﬁcientis increased to overcome this then high '\n",
            "               'curvature directions may cause instability and '\n",
            "               'oscillations.Nesterov momentum Nesterov’s Accelerated Gradient '\n",
            "               '(Nesterov, 1983; 2013) is a modiﬁedversion of the gradient '\n",
            "               'descent algorithm with improved convergence and stability. It '\n",
            "               'can be writtenas a momentum-based method (Sutskever et al., '\n",
            "               '2013),vt = βvt−1 −∇θf(θt−1 + γt−1βvt−1),θt = θt−1 + γtvt. '\n",
            "               '(2)Nesterov momentum seeks to solve stability issues by '\n",
            "               'correcting the error made after moving in thedirection of the '\n",
            "               'velocity, v. In fact, it can be shown that for a quadratic '\n",
            "               'function Nesterov momentumadapts to the curvature by '\n",
            "               'effectively rescaling the damping coefﬁcients by the '\n",
            "               'eigenvalues of thequadratic (Sutskever et al., 2013).Quadratic '\n",
            "               'convergence We begin by studying convergence on quadratic '\n",
            "               'functions, which havebeen an important test case for analyzing '\n",
            "               'convergence behavior (Sutskever et al., 2013; O’Donoghue& '\n",
            "               'Candes, 2015; Goh, 2017), and which can be considered a proxy '\n",
            "               'for optimization behavior near alocal minimum (O’Donoghue & '\n",
            "               'Candes, 2015).We analyze the behavior of these optimizers '\n",
            "               'along the eigenvectors of a quadratic function in Figure 1.In '\n",
            "               'the legend, λdenotes the corresponding eigenvalue. In (a) we '\n",
            "               'use a low damping coefﬁcient(β = 0.9) while (b) shows a high '\n",
            "               'damping coefﬁcient ( β = 0.999). When using a low '\n",
            "               'dampingcoefﬁcient it takes many iterations to ﬁnd the optimal '\n",
            "               'solution. On the other hand, increasing thedamping coefﬁcient '\n",
            "               'from 0.9 to 0.999 causes oscillations which prevent '\n",
            "               'convergence. When usingCM in practice we seek the critical '\n",
            "               'damping coefﬁcient which allows us to rapidly approach '\n",
            "               'theoptimum without becoming unstable (Goh, 2017). On the other '\n",
            "               'hand, Nesterov momentum withβ = 0.999 is able to converge more '\n",
            "               'quickly within high curvature regions than CM but '\n",
            "               'retainsoscillations for the quadratics exhibiting lower '\n",
            "               'curvature.3 Passive damping through Aggregated '\n",
            "               'MomentumAggregated Momentum We propose Aggregated Momentum '\n",
            "               '(AggMo), a variant of gradientdescent which aims to improve '\n",
            "               'stability while providing the convergence beneﬁts of larger '\n",
            "               'dampingcoefﬁcients. We modify the gradient descent algorithm '\n",
            "               'by including several velocity vectors eachwith their own '\n",
            "               'damping coefﬁcient. At each optimization step these velocities '\n",
            "               'are updated and thenaveraged to produce the ﬁnal velocity used '\n",
            "               'to update the parameters. This updated iterative procedurecan '\n",
            "               'be written as follows,2Published as a conference paper at ICLR '\n",
            "               '2019(a) CM (β = 0.9) (b) CM (β = 0.999)(c) Nesterov (β = '\n",
            "               '0.999) (d) AggMo (β = [0,0.9,0.99,0.999])Figure 1: Minimizing '\n",
            "               'a quadratic function. All optimizers use a ﬁxed learning rate '\n",
            "               'of 0.33. In the legend, λdenotes the corresponding '\n",
            "               'eigenvalues.Figure 2: Breaking oscillations with passive '\n",
            "               'damping. The arrows show the direction and relative '\n",
            "               'amplitudeof the velocities at various points in time. We '\n",
            "               'discuss points (1) and (2) in Section 3.v(i)t = β(i)v(i)t−1 '\n",
            "               '−∇θf(θt−1), for all i,θt = θt−1 + γtKK∑i=1v(i)t ,(3)where '\n",
            "               'v(i)0 = 0for each i. We refer to the vector β = [β(1),...,β '\n",
            "               '(K)] as the damping vector.By taking advantage of several '\n",
            "               'damping coefﬁcients, AggMo is able to optimize well over '\n",
            "               'ill-conditioned curvature. Figure 1 (d) shows the optimization '\n",
            "               'along the eigenvectors of a quadraticfunction using AggMo. '\n",
            "               'AggMo dampens oscillations quickly for all eigenvalues and '\n",
            "               'converges fasterthan CM and Nesterov in this case.In Figure 2 '\n",
            "               'we display the AggMo velocities during optimization. At point '\n",
            "               '(1) the velocities arealigned towards the minima, with the β = '\n",
            "               '0.999 velocity contributing substantially more to eachupdate. '\n",
            "               'By point (2) the system has begun to oscillate. While the β = '\n",
            "               '0.999 velocity is still pointedaway from the minima, the β = '\n",
            "               '0.9 velocity has changed direction and is damping the '\n",
            "               'system.Combining the velocities allows AggMo to achieve fast '\n",
            "               'convergence while reducing the impact ofoscillations caused by '\n",
            "               'large βvalues.3.1 Using AggMoChoosing the damping vector '\n",
            "               'Recall that in a direction with small but steady gradient, the '\n",
            "               'terminalvelocity is proportional to 1/(1 −β). We found that a '\n",
            "               'good choice of damping vectors was thereforeto space the '\n",
            "               'terminal velocities exponentially. To do so, we specify an '\n",
            "               'exponential scale-factor, a,and a count K. The damping vector '\n",
            "               'is then constructed as β(i) = 1−ai−1, for i = 1...K . '\n",
            "               'We3Published as a conference paper at ICLR 2019ﬁx a = 0.1 '\n",
            "               'throughout and vary only K. A good default choice is K = '\n",
            "               '3which corresponds toβ = [0,0.9,0.99]. We found this setting '\n",
            "               'to be both stable and effective in all of our '\n",
            "               'experiments.Computational/Memory overhead There is very little '\n",
            "               'additional computational overhead whenusing AggMo compared to '\n",
            "               'CM, as it only requires a handful of extra addition and '\n",
            "               'multipliciationoperations on top of the single gradient '\n",
            "               'evaluation. There is some memory overhead due to storing '\n",
            "               'theKvelocity vectors, which are each the same size as the '\n",
            "               'parameter vector. However, for most moderndeep learning '\n",
            "               'applications, the memory cost at training time is dominated by '\n",
            "               'the activations ratherthan the parameters (Gomez et al., 2017; '\n",
            "               'Chen et al., 2016; Werbos, 1990; Hochreiter & '\n",
            "               'Schmidhuber,1997), so the overhead will generally be small.4 '\n",
            "               'Recovering Nesterov momentumIn this section we show that we '\n",
            "               'can recover Nesterov Momentum (Equation 2) using a '\n",
            "               'simplegeneralization of Aggregated Momentum (Equation 3). We '\n",
            "               'now introduce separate learning rates foreach velocity, γ(i), '\n",
            "               'so that the iterate update step from Equation 3 is replaced '\n",
            "               'with,θt = θt−1 + 1KK∑i=1γ(i)t v(i)t , (4)with each velocity '\n",
            "               'updated as in Equation 3. To recover Nesterov momentum we '\n",
            "               'consider the specialcase of β = [0,β] and γ(1)t = 2γ, γ(2)t = '\n",
            "               '2βγ. The AggMo update rule can now be written as,vt = βvt−1 '\n",
            "               '−∇θf(θt−1),θt = θt−1 + γ(2)2 vt −γ(1)2 ∇θf(θt−1),= θt−1 + '\n",
            "               'γβ2vt−1 −(1 +β)γ∇θf(θt−1).(5)Similarly, we may write the '\n",
            "               'Nesterov momentum update with constant learning rate γt = '\n",
            "               'γas,vt = βvt−1 −∇θf(θt−1 + γβvt−1),θt = θt−1 + γβvt−1 '\n",
            "               '−γ∇θf(θt−1 + γβvt−1). (6)Now we consider Equation 6 when using '\n",
            "               'the reparameterization given by φt = θt + γβvt,φt −γβvt = φt−1 '\n",
            "               '−γ∇θf(φt−1),⇒φt = φt−1 + γβvt −γ∇θf(φt−1),= φt−1 + γβ2vt−1 −(1 '\n",
            "               '+β)γ∇θf(φt−1).(7)It follows that the update to φ from Nesterov '\n",
            "               'is identical to the AggMo update to θ, and we haveφ0 = θ0. We '\n",
            "               'can think of the φ reparameterization as taking a half-step '\n",
            "               'forward in the Nesterovoptimization allowing us to directly '\n",
            "               'compare the iterates at each time step. We note also that '\n",
            "               'ifγ(1)t = γ(2)t = 2γthen the equivalence holds approximately '\n",
            "               'when βis sufﬁciently close to 1. Wedemonstrate this '\n",
            "               'equivalence empirically in Appendix B.This formulation allows '\n",
            "               'us to reinterpret Nesterov momentum as a weighted average of a '\n",
            "               'gradientupdate and a momentum update. Moreover, by showing '\n",
            "               'that AggMo recovers Nesterov momentumwe gain access to the '\n",
            "               'same theoretical convergence results that Nesterov momentum '\n",
            "               'achieves.5 Convergence analysis5.1 Analyzing quadratic '\n",
            "               'convergenceWe can learn a great deal about optimizers by '\n",
            "               'carefully reasoning about their convergence on '\n",
            "               'quadraticfunctions. O’Donoghue & Candes (2015) point out that '\n",
            "               'in practice we do not know the conditionnumber of the function '\n",
            "               'to be optimized and so we aim to design algorithms which work '\n",
            "               'well over a4Published as a conference paper at ICLR 2019Figure '\n",
            "               '3: Convergence on quadratics of varying condition number.AggMo '\n",
            "               'interpolates between the conver-gence rates of CM at β = 0.9 '\n",
            "               'and β = 0.99.large possible range. Sharing this motivation, we '\n",
            "               'consider the convergence behaviour of momentumoptimizers on '\n",
            "               'quadratic functions with ﬁxed hyperparameters over a range of '\n",
            "               'condition numbers.To compute the convergence rate,||θt−θ∗||2, '\n",
            "               'we model each optimizer as a linear dynamical systemsas in '\n",
            "               'Lessard et al. (2016). The convergence rate is then determined '\n",
            "               'by the eigenvalues of this system.We leave details of this '\n",
            "               'computation to appendix B.Figure 3 displays the convergence '\n",
            "               'rate of each optimizer for quadratics with condition numbers '\n",
            "               '(κ)from 101 to 107. The blue dashed line displays the optimal '\n",
            "               'convergence rate achievable by CMwith knowledge of the '\n",
            "               'condition number — an unrealistic scenario in practice. The '\n",
            "               'two curvescorresponding to CM (red and purple) each meet the '\n",
            "               'optimal convergence rate when the conditionnumber is such that '\n",
            "               'βis critical. On the left of this critical point, where the '\n",
            "               'convergence rates forCM are ﬂat, the system is ”under-damped” '\n",
            "               'meaning there are complex eigenvalues corresponding '\n",
            "               'tooscillations.We observe that the convergence rate of AggMo '\n",
            "               'interpolates smoothly between the convergence ratesof CM with '\n",
            "               'β = 0.9 and β = 0.99 as the condition number varies. AggMo’s '\n",
            "               'ability to quickly killoscillations leads to an approximately '\n",
            "               'three-times faster convergence rate than Nesterov momentumin '\n",
            "               'the under-damped regime without sacriﬁcing performance on '\n",
            "               'larger condition numbers.5.2 Additional convergence analysisWe '\n",
            "               'evaluate the convergence rate of AggMo in the setting of '\n",
            "               'online convex programming, as proposedin Zinkevich (2003). '\n",
            "               'This is an increasingly common setting to analyze optimization '\n",
            "               'algorithmstailored to machine learning (Duchi et al., 2011; '\n",
            "               'Kingma & Ba, 2014; Reddi et al., 2018). Notably,this is '\n",
            "               'equivalent to analyzing the convergence rate in the setting of '\n",
            "               'stochastic convex optimization.We consider a sequence of '\n",
            "               'unknown convex cost functions,f1(θ),...,f T(θ). At each time '\n",
            "               't, ourgoal is to predict the parameter θt which minimizes the '\n",
            "               'regret,R(T) =T∑t=1[ft(θt) −ft(θ∗)] , (8)where θ∗is the ﬁxed '\n",
            "               'point parameter minimizing ∑Tt=1 ft(θ∗). We are able to show '\n",
            "               'that AggMohas regret bounded by O(√T) - a result '\n",
            "               'asymptotically comparable to the best known bound (Duchiet '\n",
            "               'al., 2011). We adopt the following deﬁnitions from Duchi et '\n",
            "               'al. (2011) to simplify the notation. Wewrite gt = ∇ft(θt) with '\n",
            "               'gt,i as the ith element of this vector. Additionally, we write '\n",
            "               'g1:t,i ∈Rt asthe vector containing the ith element of the '\n",
            "               'gradient over the ﬁrst titerations; g1:t,i = [g1,i,...,g '\n",
            "               't,i].Then the following theorem holds,Theorem 1. Assume that '\n",
            "               'fthas bounded gradients, ||∇ft(θ)||2 <G, ||∇ft(θ)||∞<G∞, ∀θ '\n",
            "               '∈Rd.Moreover, assume that eachθtgenerated by AggMo '\n",
            "               'satisﬁes||θn−θm||2 ≤D,||θn−θm||∞≤D∞for all m,n ∈{1,...,T }. '\n",
            "               'Let γt = γ√t and β(i)t = β(i)λt, λ∈(0,1). Then AggMo achieves '\n",
            "               'thefollowing regret bound, for all T ≥1.5Published as a '\n",
            "               'conference paper at ICLR 2019R(T) ≤D2∞√Tγ + γ√1 + '\n",
            "               'log(T)2Kd∑j=1||g1:T,j||24K∑i=11 +β(i)(1 −β(i))2 + D22Kγ(1 '\n",
            "               '−λ)2K∑i=1β(i).It immediately follows that the average regret '\n",
            "               'of AggMo converges, i.e. that R(T)/T →0, byobserving that '\n",
            "               '||g1:T,j||24 ≤G2∞√T,∀j. The full proof is given in Appendix C '\n",
            "               'alongside some openquestions on the convergence of AggMo.While '\n",
            "               'the statement of Theorem 1 requires strict assumptions we note '\n",
            "               'that this result is certainlynon-trivial. Reddi et al. (2018) '\n",
            "               'showed that the average regret of Adam (Kingma & Ba, 2014) is '\n",
            "               'notguaranteed to converge under the same assumptions.6 Related '\n",
            "               'workThe convergence of momentum methods has been studied '\n",
            "               'extensively, both theoretically and empiri-cally (Wibisono & '\n",
            "               'Wilson, 2015; Wibisono et al., 2016; Wilson et al., 2016; '\n",
            "               'Kidambi et al., 2018). Byanalyzing the failure modes of '\n",
            "               'existing methods these works motivate successful momentum '\n",
            "               'schemes.Sutskever et al. (2013) explored the effect of '\n",
            "               'momentum on the optimization of neural networksand introduced '\n",
            "               'the momentum view of Nesterov’s accelerated gradient. They '\n",
            "               'focused on producinggood momentum schedules during '\n",
            "               'optimization to adapt to ill-conditioned curvature. Despite '\n",
            "               'strongevidence that this approach works well, practitioners '\n",
            "               'today still typically opt for a ﬁxed momentumschedule and vary '\n",
            "               'the learning rate instead.In Appendix C.1 we show that AggMo '\n",
            "               'evolves as a (K+1)-th order ﬁnite difference equation, '\n",
            "               'enablingAggMo to utilize greater expressiveness over the '\n",
            "               'gradient history. Liang et al. (2016) also introducedependence '\n",
            "               'on a larger gradient history by adding lagged momentum terms. '\n",
            "               'However, in doing sothe authors introduce many new '\n",
            "               'hyperparameters to be tuned.Adaptive gradient methods have '\n",
            "               'been introduced to deal with the ill-conditioned curvature '\n",
            "               'that weoften observe in deep learning (Duchi et al., 2011; '\n",
            "               'Kingma & Ba, 2014; Zeiler, 2012; Tieleman &Hinton, 2012). '\n",
            "               'These methods typically approximate the local curvature of the '\n",
            "               'objective to adaptto the geometry of the data. Natural '\n",
            "               'gradient descent (Amari, 1998) preconditions by the '\n",
            "               'Fisherinformation matrix, which can be shown to approximate '\n",
            "               'the Hessian under certain assumptions(Martens, 2014). Several '\n",
            "               'methods have been proposed to reduce the computational and '\n",
            "               'memory costof this approach (Martens & Grosse, 2015; Martens, '\n",
            "               '2010) but these are difﬁcult to implement andintroduce '\n",
            "               'additional hyperparameters and computational overhead compared '\n",
            "               'to SGD.Another line of adaptive methods seeks to detect when '\n",
            "               'oscillations occur during optimization.O’Donoghue & Candes '\n",
            "               '(2015) proposed using an adaptive restarting scheme to remove '\n",
            "               'oscillationswhenever they are detected. In its simplest form, '\n",
            "               'this is achieved by setting the momentum velocity tozero '\n",
            "               'whenever the loss increases. Further work has suggested using '\n",
            "               'an adaptive momentum scheduleinstead of zeroing (Srinivasan et '\n",
            "               'al., 2018). Although this technique works well for '\n",
            "               'well-conditionedconvex problems it is difﬁcult to ﬁnd an '\n",
            "               'appropriate restart condition for stochastic optimizationwhere '\n",
            "               'we do not have an accurate computation of the loss. On the '\n",
            "               'other hand, AggMo’s passivedamping approach addresses the '\n",
            "               'oscillation problem without the need to detect its '\n",
            "               'occurrence.7 EvaluationWe evaluated the AggMo optimizer on the '\n",
            "               'following deep learning architectures; deep '\n",
            "               'autoencoders,convolutional networks, and LSTMs. To do so we '\n",
            "               'used four datasets: MNIST (LeCun et al.,1998), CIFAR-10, '\n",
            "               'CIFAR-100 (Krizhevsky & Hinton, 2009) and Penn Treebank '\n",
            "               '(Marcus et al.,1993). In each experiment we compared AggMo to '\n",
            "               'classical momentum, Nesterov momentum, andAdam. These '\n",
            "               'optimizers are by far the most commonly used and even today '\n",
            "               'remain very difﬁcultto outperform in a wide range of tasks. '\n",
            "               'For each method, we performed a grid search over thelearning '\n",
            "               'rate and the damping coefﬁcient. For AggMo, we keep the scale '\n",
            "               'a = 0.1 ﬁxed and varyto outperform in a wide range of tasks. '\n",
            "               'For each method, we performed a grid search over thelearning '\n",
            "               'rate and the damping coefﬁcient. For AggMo, we keep the scale '\n",
            "               'a = 0.1 ﬁxed and varyKas discussed in Section 3.1. Full '\n",
            "               'details of the experimental set up for each task can be found '\n",
            "               'inAppendix D with additional results given in Appendix E.For '\n",
            "               'each of the following experiments we choose to report the '\n",
            "               'validation and test performanceof the network in addition to '\n",
            "               'the ﬁnal training loss when it is meaningful to do so. We '\n",
            "               'includethese generalization results because recent work has '\n",
            "               'shown that the choice of optimizer may have asigniﬁcant effect '\n",
            "               'on the generalization error of the network in practice (Wilson '\n",
            "               'et al., 2017).6Published as a conference paper at ICLR '\n",
            "               '2019Optimizer Train Optimal Validation OptimalTrain Loss Val. '\n",
            "               'Loss Test LossCM 2.51 ±0.06 3.55 ±0.15 3.45 ±0.15Nesterov 1.52 '\n",
            "               '±0.02 3.20 ±0.01 3.13 ±0.02Adam 1.44 ±0.02 3.80 ±0.04 3.72 '\n",
            "               '±0.05AggMo 1.39 ±0.02 3.05 ±0.03 2.96 ±0.03Table 1: MNIST '\n",
            "               'Autoencoder We display the training MSE for the hyperparameter '\n",
            "               'setting that achieved thebest training loss. The validation '\n",
            "               'and test errors are displayed for the hyperparameter setting '\n",
            "               'that achieved thebest validation MSE. In each case the average '\n",
            "               'loss and standard deviation over 15 runs is displayed.Figure '\n",
            "               '4: Convergence of Autoencoders Trainingloss during the ﬁrst '\n",
            "               '350 epochs of training with eachoptimizer. The shaded region '\n",
            "               'corresponds to one stan-dard deviation over 15 runs.Figure 5: '\n",
            "               'Damping Coefﬁcient Investigation Opti-mizing autoencoders on '\n",
            "               'MNIST with varying damp-ing coefﬁcients and ﬁxed learning '\n",
            "               'rate. Nesterov isunstable with β = 0.999.7.1 AutoencodersWe '\n",
            "               'trained fully-connected autoencoders on the MNIST dataset '\n",
            "               'using a set-up similar to that ofSutskever et al. (2013). '\n",
            "               'While their work focused on ﬁnding an optimal momentum '\n",
            "               'schedule weinstead kept the momentum ﬁxed and applied a simple '\n",
            "               'learning rate decay schedule. For CM andNesterov we evaluated '\n",
            "               'damping coefﬁcients in the range: {0.0,0.9,0.99,0.999}. For '\n",
            "               'Adam, itis standard to use β1 = 0.9 and β2 = 0.999. Since β1 '\n",
            "               'is analogous to the momentum dampingparameter, we considered '\n",
            "               'β1 ∈{0.9,0.99,0.999}and kept β2 = 0.999. For AggMo, we '\n",
            "               'exploredKin {2,3,4 }. Each model was trained for 1000 '\n",
            "               'epochs.We report the training, validation, and test errors in '\n",
            "               'Table 1. Results are displayed for the hyperpa-rameters that '\n",
            "               'achieved the best training loss and also for those that '\n",
            "               'achieved the best validation loss.While Adam is able to '\n",
            "               'perform well on the training objective it is unable to match '\n",
            "               'the performance ofAggMo or Nesterov on the validation/test '\n",
            "               'sets. AggMo achieves the best performance in all cases.In '\n",
            "               'these experiments the optimal damping coefﬁcient for both CM '\n",
            "               'and Nesterov was β = 0.99 whilethe optimal damping vector for '\n",
            "               'AggMo was β = [0.0,0.9,0.99,0.999], given by K = 4. In Figure '\n",
            "               '4we compare the convergence of each of the optimizers under '\n",
            "               'the optimal hyperparameters for thetraining loss.Increasing '\n",
            "               'damping coefﬁcients During our experiments we observed that '\n",
            "               'AggMo remains stableduring optimization for learning rates an '\n",
            "               'order of magnitude (or more) larger than is possible for CMand '\n",
            "               'Nesterov with βequal to the max damping coefﬁcient used in '\n",
            "               'AggMo.We further investigated the effect of increasing the '\n",
            "               'maximum damping coefﬁcient of AggMo inFigure 5. The learning '\n",
            "               'rate is ﬁxed at 0.1 and we vary K from 2 to 5. We compared to '\n",
            "               'Nesterovwith damping coefﬁcients in the same range (max of '\n",
            "               '0.9999) and a ﬁxed learning rate of 0.05 (to beconsistent with '\n",
            "               'our analysis in Section 4). We do not include the curves for '\n",
            "               'which training is unstable:Nesterov with β ∈{0.999,0.9999}and '\n",
            "               'AggMo with K = 5. AggMo is able to take advantage ofthe larger '\n",
            "               'damping coefﬁcient of 0.999 and achieves the fastest overall '\n",
            "               'convergence.7.2 ClassiﬁcationFor the following experiments we '\n",
            "               'evaluated AggMo using two network architectures: a '\n",
            "               'neuralnetwork with 5 convolutional layers (CNN-5) and the '\n",
            "               'ResNet-32 architecture (He et al., 2016). Weuse data '\n",
            "               'augmentation and regularization only for the latter. Each '\n",
            "               'model was trained for 400 epochs.7Published as a conference '\n",
            "               'paper at ICLR 2019Optimizer CNN-5 (CIFAR-10) ResNet-32 '\n",
            "               '(CIFAR-10) ResNet-32 (CIFAR-100)Val. (%) Test (%) Val. (%) '\n",
            "               'Test (%) Val. (%) Test (%)CM 64.1 63.43 94.20 93.16 70.38 '\n",
            "               '70.21Nesterov 65.14 64.32 94.16 93.18 70.34 70.08Adam 63.67 '\n",
            "               '62.86 92.36 90.94 67.20 68.08AggMo 65.98 65.09 93.87 93.16 '\n",
            "               '70.28 70.11CM (β = 0.9) 64.1 63.43 94.10 93.36 70.38 '\n",
            "               '70.21Nesterov (β = 0.9) 64.13 63.04 94.16 93.18 70.34 '\n",
            "               '70.08AggMo (Default) 65.98 65.09 93.87 93.16 70.28 70.11Table '\n",
            "               '2: Classiﬁcation accuracy on CIFAR-10 and CIFAR-100 We display '\n",
            "               'results using the optimal hyper-parameters for CM, Nesterov, '\n",
            "               'Adam and AggMo on the validation set and also with default '\n",
            "               'settings for CM,Nesterov and AggMo.Figure 6: ResNet-32 Trained '\n",
            "               'On CIFAR-100 The training loss and validation accuracy during '\n",
            "               'training onCIFAR-100 for each optimizer.For each optimizer we '\n",
            "               'report the accuracy on a randomly held out validation set and '\n",
            "               'the test set.All of the models achieve near-perfect accuracy '\n",
            "               'on the training set and so we do not report this.The results '\n",
            "               'are displayed in Table 2. On the small convolutional network '\n",
            "               'without regularization,AggMo signiﬁcantly out performed the '\n",
            "               'other methods. For both of the ResNet-32 experiments '\n",
            "               'weobserved the best validation accuracy with CM. This is '\n",
            "               'perhaps expected as the model architectureand hyperparameters '\n",
            "               'were likely to have been tuned using CM. Despite this, we '\n",
            "               'observed that AggMoperformed consistently well and had the '\n",
            "               'fastest overall convergence.We found that our proposed default '\n",
            "               'hyperparameters for AggMo (a= 0.1, K = 3) led to much '\n",
            "               'fasterconvergence than CM and Nesterov with β = 0.9, a common '\n",
            "               'default choice. Figure 6 shows thetraining loss and validation '\n",
            "               'accuracy during training for each optimizer used to train the '\n",
            "               'ResNet-32 model. The hyperparameters used for each plot are '\n",
            "               'those which obtained the best validationaccuracy. AggMo '\n",
            "               'converged most quickly on the training objective without '\n",
            "               'sacriﬁcing ﬁnal validationperformance.Surprisingly, we found '\n",
            "               'that using AggMo we were also able to train the ResNet-32 '\n",
            "               'architecture onCIFAR-100 without using batch normalization. '\n",
            "               'With a limited search over learning rates we achieved69.32% '\n",
            "               'test error compared to a best value of 67.26% using CM. We '\n",
            "               'also found that, with batchnormalization removed, optimization '\n",
            "               'with AggMo remained stable at larger learning rates than '\n",
            "               'withCM.We note that the additional network hyperparameters '\n",
            "               '(e.g. weight decay) are defaults which werelikely picked as '\n",
            "               'they work well with classical momentum. This may disadvantage '\n",
            "               'the other optimizers,including our own. Despite this, we found '\n",
            "               'that we are able to outperform CM with the AggMo andNesterov '\n",
            "               'optimizers without additional tuning of any of these '\n",
            "               'hyperparameters.7.3 Language modelingWe trained LSTM Language '\n",
            "               'Models on the Penn Treebank dataset. We followed the '\n",
            "               'experimentalsetup of Merity et al. (2017) and made use of the '\n",
            "               'code provided by the authors. We used the '\n",
            "               'optimalhyperparameter settings described by the authors and '\n",
            "               'vary only the learning rate, momentum andwhether gradient '\n",
            "               'clipping is used. The network hyperparameters were tuned using '\n",
            "               'SGD and maynot be optimal for the other optimizers we evaluate '\n",
            "               '(including our own). We followed only the basemodel training '\n",
            "               'used in Merity et al. (2017) and do not include the ﬁne-tuning '\n",
            "               'and continuous cacheoptimization steps. Each model was trained '\n",
            "               'for 750 epochs.As noted in Merity et al. (2017), it is '\n",
            "               'typically observed that SGD without momentum performsbetter '\n",
            "               'than momentum-based methods in language modeling tasks. '\n",
            "               'However, in our experiments we8Published as a conference paper '\n",
            "               'at ICLR 2019Figure 7: Convergence of LSTM The training and '\n",
            "               'validation perplexity during training. For each model weuse '\n",
            "               'the hyperparameters that obtained the best validation loss. We '\n",
            "               'found that there was very little differencewhen choosing '\n",
            "               'hyperparameters based on training performance.Optimizer Train '\n",
            "               'Perplexity Val. Perplexity Test Perplexity*SGD + ASGD 35.68 '\n",
            "               '61.17 59.26SGD 35.34 63.39 62.41CM 50.34 70.37 68.21Nesterov '\n",
            "               '34.91 60.84 58.44Adam 32.88 60.25 57.83AggMo 33.22 60.36 '\n",
            "               '57.79Table 3: Penn Treebank LSTMPerplexity across different '\n",
            "               'optimizers. We display the train, validation, and testerror '\n",
            "               'for the optimization run that produced the best validation '\n",
            "               'loss. * uses ASGD (Polyak & Juditsky, 1992)and corresponds to '\n",
            "               'the base model reported in Merity et al. (2017)observed all '\n",
            "               'momentum-based optimizers but CM outperform SGD without '\n",
            "               'momentum. Surprisingly,we found that Adam is well-suited to '\n",
            "               'this task and achieves the best training, validation, and '\n",
            "               'testperformance. We believe that the heavy regularization used '\n",
            "               'when training the network makes Adama good choice. AggMo is '\n",
            "               'very close in terms of ﬁnal performance to Adam.Table 3 '\n",
            "               'contains the results for the hyperparameter settings which '\n",
            "               'achieved the best validation errorfor each optimizer. The ﬁrst '\n",
            "               'row (denoted *) uses the scheme suggested in Merity et al. '\n",
            "               '(2017): oncethe validation loss plateaus we switch to the ASGD '\n",
            "               '(Polyak & Juditsky, 1992) optimizer. The otherrows instead '\n",
            "               'decay the learning rate when the validation loss '\n",
            "               'plateaus.Figure 7 compares the convergence of the training and '\n",
            "               'validation perplexity of each optimizer. Whilethe momentum '\n",
            "               'methods converge after 300 epochs, the momentum-free methods '\n",
            "               'converged muchmore slowly. Surprisingly, we found that SGD '\n",
            "               'worked best without any learning rate decay. Adamconverged '\n",
            "               'most quickly and achieved a validation perplexity which is '\n",
            "               'comparable to that of AggMo.While gradient clipping is '\n",
            "               'critical for SGD without momentum, which utilizes a large '\n",
            "               'learning rate,we found that all of the momentum methods '\n",
            "               'perform better without gradient clipping.In short, while '\n",
            "               'existing work encourages practitioners to avoid classical '\n",
            "               'momentum we found thatusing other momentum methods may '\n",
            "               'signiﬁcantly improve convergence rates and ﬁnal '\n",
            "               'performance.AggMo worked especially well on this task over a '\n",
            "               'large range of damping coefﬁcients and learningrates.8 '\n",
            "               'ConclusionAggregated Momentum is a simple extension to '\n",
            "               'classical momentum which is easy to implement andhas '\n",
            "               'negligible computational overhead on modern deep learning '\n",
            "               'tasks. We showed empirically thatAggMo is able to remain '\n",
            "               'stable even with large damping coefﬁcients and enjoys faster '\n",
            "               'convergencerates as a consequence of this. Nesterov momentum '\n",
            "               'can be viewed as a special case of AggMo.(Incidentally, we '\n",
            "               'found that despite its lack of adoption by deep learning '\n",
            "               'practitioners, Nesterovmomentum also showed substantial '\n",
            "               'advantages compared to classical momentum.) On the tasks '\n",
            "               'weexplored, AggMo could be used as a drop-in replacement for '\n",
            "               'existing optimizers with little-to-noadditional hyperparameter '\n",
            "               'tuning. But due to its stability at higher β values, it often '\n",
            "               'deliveredsubstantially faster convergence than both classical '\n",
            "               'and Nesterov momentum.9Published as a conference paper at ICLR '\n",
            "               '20199 AcknowledgementsWe would like to thank Geoffrey Hinton '\n",
            "               'for suggesting the link between AggMo and passive dampingin '\n",
            "               'physical systems. We also thank Paul Vicol for his help with '\n",
            "               'the LSTM experiments. Finally, wethank our many other '\n",
            "               'colleagues for useful discussions and insights. James Lucas is '\n",
            "               'supported by anNSERC research grant. Shengyang Sun is '\n",
            "               'supported by a Connaught New Researcher Award and aConnaught '\n",
            "               'Fellowship.ReferencesShun-Ichi Amari. Natural gradient works '\n",
            "               'efﬁciently in learning. Neural computation, '\n",
            "               '10(2):251–276,1998.Tianqi Chen, Bing Xu, Chiyuan Zhang, and '\n",
            "               'Carlos Guestrin. Training deep nets with sublinearmemory cost. '\n",
            "               'arXiv preprint arXiv:1604.06174, 2016.John Duchi, Elad Hazan, '\n",
            "               'and Yoram Singer. Adaptive subgradient methods for online '\n",
            "               'learning andstochastic optimization. Journal of Machine '\n",
            "               'Learning Research, 12(Jul):2121–2159, 2011.Gabriel Goh. Why '\n",
            "               'momentum really works. Distill, 2(4):e6, 2017.Herbert '\n",
            "               'Goldstein. Classical mechanics. Pearson Education India, '\n",
            "               '2011.Aidan N Gomez, Mengye Ren, Raquel Urtasun, and Roger B '\n",
            "               'Grosse. The reversible residual network:Backpropagation '\n",
            "               'without storing activations. In Advances in Neural Information '\n",
            "               'ProcessingSystems, pp. 2211–2221, 2017.Kaiming He, Xiangyu '\n",
            "               'Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for '\n",
            "               'imagerecognition. In Proceedings of the IEEE conference on '\n",
            "               'computer vision and pattern recognition,pp. 770–778, 2016.Sepp '\n",
            "               'Hochreiter and J ¨urgen Schmidhuber. Long short-term memory. '\n",
            "               'Neural computation, 9(8):1735–1780, 1997.Sergey Ioffe and '\n",
            "               'Christian Szegedy. Batch normalization: Accelerating deep '\n",
            "               'network training byreducing internal covariate shift. arXiv '\n",
            "               'preprint arXiv:1502.03167, 2015.Rahul Kidambi, Praneeth '\n",
            "               'Netrapalli, Prateek Jain, and Sham M Kakade. On the '\n",
            "               'insufﬁciency ofexisting momentum schemes for stochastic '\n",
            "               'optimization. arXiv preprint arXiv:1803.05591, 2018.Diederik '\n",
            "               'Kingma and Jimmy Ba. Adam: A method for stochastic '\n",
            "               'optimization. arXiv preprintarXiv:1412.6980, 2014.Alex '\n",
            "               'Krizhevsky and Geoffrey Hinton. Learning multiple layers of '\n",
            "               'features from tiny images. 2009.Yann LeCun, L´eon Bottou, '\n",
            "               'Yoshua Bengio, and Patrick Haffner. Gradient-based learning '\n",
            "               'applied todocument recognition. Proceedings of the IEEE, '\n",
            "               '86(11):2278–2324, 1998.Laurent Lessard, Benjamin Recht, and '\n",
            "               'Andrew Packard. Analysis and design of optimizationalgorithms '\n",
            "               'via integral quadratic constraints. SIAM Journal on '\n",
            "               'Optimization, 26(1):57–95, 2016.Jingwei Liang, Jalal Fadili, '\n",
            "               'and Gabriel Peyr ´e. A multi-step inertial forward-backward '\n",
            "               'splittingmethod for non-convex optimization. In Advances in '\n",
            "               'Neural Information Processing Systems, pp.4035–4043, '\n",
            "               '2016.Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beatrice '\n",
            "               'Santorini. Building a large annotatedcorpus of english: The '\n",
            "               'penn treebank. Computational linguistics, 19(2):313–330, '\n",
            "               '1993.James Martens. Deep learning via hessian-free '\n",
            "               'optimization. In ICML, volume 27, pp. 735–742,2010.James '\n",
            "               'Martens. New insights and perspectives on the natural gradient '\n",
            "               'method. arXiv preprintarXiv:1412.1193, 2014.10Published as a '\n",
            "               'conference paper at ICLR 2019James Martens and Roger Grosse. '\n",
            "               'Optimizing neural networks with kronecker-factored '\n",
            "               'approximatecurvature. In International conference on machine '\n",
            "               'learning, pp. 2408–2417, 2015.Stephen Merity, Nitish Shirish '\n",
            "               'Keskar, and Richard Socher. Regularizing and optimizing '\n",
            "               'lstmlanguage models. arXiv preprint arXiv:1708.02182, '\n",
            "               '2017.Yurii Nesterov. A method of solving a convex programming '\n",
            "               'problem with convergence rate o (1/k2).volume 27, pp. 372–367, '\n",
            "               '1983.Yurii Nesterov. Introductory lectures on convex '\n",
            "               'optimization: A basic course, volume 87. SpringerScience & '\n",
            "               'Business Media, 2013.Brendan O’Donoghue and Emmanuel Candes. '\n",
            "               'Adaptive restart for accelerated gradient schemes.Foundations '\n",
            "               'of computational mathematics, 15(3):715–732, 2015.Adam Paszke, '\n",
            "               'Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, '\n",
            "               'Zachary DeVito,Zeming Lin, Alban Desmaison, Luca Antiga, and '\n",
            "               'Adam Lerer. Automatic differentiation inpytorch. 2017.Boris T '\n",
            "               'Polyak. Some methods of speeding up the convergence of '\n",
            "               'iteration methods. USSRComputational Mathematics and '\n",
            "               'Mathematical Physics, 4(5):1–17, 1964.Boris T Polyak and '\n",
            "               'Anatoli B Juditsky. Acceleration of stochastic approximation '\n",
            "               'by averaging.SIAMJournal on Control and Optimization, '\n",
            "               '30(4):838–855, 1992.Sashank J. Reddi, Satyen Kale, and Sanjiv '\n",
            "               'Kumar. On the convergence of adam and beyond. InInternational '\n",
            "               'Conference on Learning Representations, 2018. URL '\n",
            "               'https://openreview.net/forum?id=ryQu7f-RZ.Vishwak Srinivasan, '\n",
            "               'Adepu Ravi Sankar, and Vineeth N Balasubramanian. Adine: an '\n",
            "               'adaptivemomentum method for stochastic gradient descent. In '\n",
            "               'Proceedings of the ACM India JointInternational Conference on '\n",
            "               'Data Science and Management of Data, pp. 249–256. ACM, '\n",
            "               '2018.Weijie Su, Stephen Boyd, and Emmanuel Candes. A '\n",
            "               'differential equation for modeling nesterovsaccelerated '\n",
            "               'gradient method: Theory and insights. In Advances in Neural '\n",
            "               'Information ProcessingSystems, pp. 2510–2518, 2014.Ilya '\n",
            "               'Sutskever, James Martens, George Dahl, and Geoffrey Hinton. On '\n",
            "               'the importance of initializationand momentum in deep learning. '\n",
            "               'In International conference on machine learning, pp. '\n",
            "               '1139–1147,2013.Tijmen Tieleman and Geoffrey Hinton. Lecture '\n",
            "               '6.5-rmsprop: Divide the gradient by a runningaverage of its '\n",
            "               'recent magnitude. COURSERA: Neural networks for machine '\n",
            "               'learning, 4(2):26–31,2012.Paul J Werbos. Backpropagation '\n",
            "               'through time: what it does and how to do it. Proceedings of '\n",
            "               'theIEEE, 78(10):1550–1560, 1990.Andre Wibisono and Ashia C '\n",
            "               'Wilson. On accelerated methods in optimization. arXiv '\n",
            "               'preprintarXiv:1509.03616, 2015.Andre Wibisono, Ashia C Wilson, '\n",
            "               'and Michael I Jordan. A variational perspective on '\n",
            "               'acceleratedmethods in optimization. Proceedings of the '\n",
            "               'National Academy of Sciences, 113(47):E7351–E7358,2016.Ashia C '\n",
            "               'Wilson, Benjamin Recht, and Michael I Jordan. A lyapunov '\n",
            "               'analysis of momentum methodsin optimization. arXiv preprint '\n",
            "               'arXiv:1611.02635, 2016.Ashia C Wilson, Rebecca Roelofs, '\n",
            "               'Mitchell Stern, Nati Srebro, and Benjamin Recht. The '\n",
            "               'marginalvalue of adaptive gradient methods in machine '\n",
            "               'learning. In Advances in Neural InformationProcessing Systems, '\n",
            "               'pp. 4151–4161, 2017.Matthew D Zeiler. Adadelta: an adaptive '\n",
            "               'learning rate method. arXiv preprint '\n",
            "               'arXiv:1212.5701,2012.Martin Zinkevich. Online convex '\n",
            "               'programming and generalized inﬁnitesimal gradient ascent. '\n",
            "               'InProceedings of the 20th International Conference on Machine '\n",
            "               'Learning (ICML-03), pp. 928–936,2003.11Published as a '\n",
            "               'conference paper at ICLR 2019AppendicesA Nesterov '\n",
            "               'EquivalenceIn this section we demonstrate this equivalence on '\n",
            "               'two toy problems. In each of the ﬁgures includedhere we take β '\n",
            "               '= 0.999.We ﬁrst consider a 2D quadratic function,f(x) =xTAx, '\n",
            "               'where Ahas eigenvalues 1.0 and 0.001.Thelearning rates for '\n",
            "               'each optimizer are set as described in Section 4. Each '\n",
            "               'optimizer is initialized at thesame position. Figure 8 shows '\n",
            "               'both optimizers following the same optimization trajectories. '\n",
            "               'In thissetting, the two paths are also visually '\n",
            "               'indistinguishable with γ(1)t = γ(2)t = 2γfor AggMo.Figure 8: '\n",
            "               'Equivalence of Nesterov and AggMo when β = 0.999. The '\n",
            "               'optimization plots for f(x) =xT Ax arevisibly identical '\n",
            "               '(circles correspond to AggMo and squares to Nesterov - the '\n",
            "               'markers are offset for readability).We now optimize the '\n",
            "               'Rosenbrock function, given by,f(x,y) = (y−x2)2 + 100(x−1)2This '\n",
            "               'function has a global minimum at (x,y) = 1. Once again the '\n",
            "               'optimizers are initialized atthe same point but for this '\n",
            "               'example we take γ(1)t = γ(2)t = 2γ for AggMo. Figure 9 '\n",
            "               'showsthe optimization trajectories of both algorithms. In this '\n",
            "               'case we see that the updates are initiallyindistinguishable '\n",
            "               'but begin to differ as the algorithms approach the origin.B '\n",
            "               'Quadratic Convergence AnalysisIn this section we present '\n",
            "               'details of the convergence rate computations in Figure 3. We '\n",
            "               'also presentsome additional supporting results.We ﬁrst note '\n",
            "               'that for quadratic functions of the formf(x) =12xTAx+bTx we '\n",
            "               'can write the AggMooptimization procedure as a linear '\n",
            "               'dynamical systems in K+ '\n",
            "               '1variables:\\uf8ee\\uf8ef\\uf8ef\\uf8ef\\uf8f0v(1)t+1...v(K)t+1xt+1 '\n",
            "               '−x∗\\uf8f9\\uf8fa\\uf8fa\\uf8fa\\uf8fb= '\n",
            "               'B\\uf8ee\\uf8ef\\uf8ef\\uf8ef\\uf8f0v(1)t...v(K)txt '\n",
            "               '−x∗\\uf8f9\\uf8fa\\uf8fa\\uf8fa\\uf8fb12Published as a conference '\n",
            "               'paper at ICLR 2019Figure 9: Approximate equivalence of '\n",
            "               'Nesterov and AggMo when β = 0.999. The optimization '\n",
            "               'trajectories areinitially visibly identical but begin to '\n",
            "               'differ slightly after more iterations.The spectral norm of the '\n",
            "               'matrixBdetermines the rate at which the linear dynamical '\n",
            "               'system convergesand thus bounds ||xt −x∗||2 (Lessard et al., '\n",
            "               '2016). We can write down the exact form of B asfollows,B '\n",
            "               '=\\uf8ee\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f0β(1)I '\n",
            "               '0 ··· 0 −A0 β(2)I ... ... ...... ... ... 0 −A0 ··· 0 β(K)I '\n",
            "               '−Aγβ(1)K I γβ(2)K I ··· γβ(K)K I '\n",
            "               '(I−γA)\\uf8f9\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fbWe '\n",
            "               'note in particular that in the special case of K = 1(CM) we '\n",
            "               'recover the characteristic equationof O’Donoghue & Candes '\n",
            "               '(2015):u2 −(1 +β−γλi)u+ β = 0Which in turn yields the critical '\n",
            "               'damping coefﬁcient and optimal rate, withβ∗=(√κ−1√κ+ 1)2.When '\n",
            "               'β <β∗the system is over-damped and exhibits slow monotone '\n",
            "               'convergence (Figure 1 (a)).When β >β∗the system is '\n",
            "               'under-damped and the characteristic equation yields imaginary '\n",
            "               'solutionsthat correspond to oscillations (Figure 1 (b)) with '\n",
            "               'convergence rate equal to 1 −|β|. At the criticaldamping '\n",
            "               'coefﬁcient the convergence is optimal at 1.0 −√κ−1√κ+ 1.We can '\n",
            "               'combine this analysis with Theorem 2 from Sutskever et al. '\n",
            "               '(2013) to recover similarconvergence bounds for Nesterov '\n",
            "               'momentum.Producing Figure 3 To produce the curves in Figure 3 '\n",
            "               'we compute the eigenvalues directly fromthe matrix Bfor '\n",
            "               'matrices Awith varying condition numbers. While we can ﬁnd the '\n",
            "               'optimal learningrate for CM and Nesterov momentum in closed '\n",
            "               'form we have been unable to do so for AggMo.Therefore, we '\n",
            "               'instead perform a ﬁne-grained grid search to approximate the '\n",
            "               'optimal learning rate foreach condition number.13Published as '\n",
            "               'a conference paper at ICLR 2019(a) CM β = 0.999 (b) Nesterov β '\n",
            "               '= 0.999(c) AggMo β = [0,0.9,0.999]Figure 10: Velocity during '\n",
            "               'quadratic optimization with CM, Nesterov, and AggMo. (Best '\n",
            "               'viewed in color)The shaded region shows the direction and '\n",
            "               'relative magnitude of the velocities throughout optimization '\n",
            "               'for eachoptimizer. AggMo has multiple shaded regions '\n",
            "               'corresponding to the different velocities.Studying Velocity We '\n",
            "               'now present a brief study illustrating how using multiple '\n",
            "               'velocities canbreak oscillations during optimization.Figure 10 '\n",
            "               'shows the optimization of a 1-D quadratic function with CM, '\n",
            "               'Nesterov, and AggMo. Theshaded region around each curve '\n",
            "               'represents the direction and relative magnitude of the '\n",
            "               'velocitiesterm during optimization. CM (a) has a single '\n",
            "               'velocity and oscillates at a near-constant amplitude.For '\n",
            "               'Nesterov momentum (b) we display the velocity and the '\n",
            "               '”error-correcting” term. AggMo (c)has shaded regions for each '\n",
            "               'velocity. For AggMo, the velocity with β = 0.9 oscillates at a '\n",
            "               'higherfrequency and thus damps the whole system.C Convergence '\n",
            "               'ProofHere we present the proof of Theorem 5 1. We introduce '\n",
            "               'some simplifying notation used in Duchiet al. (2011). We write '\n",
            "               'gt = ∇f(θt), with gt,i denoting the ith element of the vector '\n",
            "               'gt. We furtherwrite g1:t,i ∈Rt for the ith dimension of '\n",
            "               'gradients up to iteration t.We begin with the following '\n",
            "               'lemma,Lemma 1. We write vit,j to indicate the jth element of '\n",
            "               'the ith velocity at time t. Assume gt isbounded, then the '\n",
            "               'following holds for all j,T∑t=1K∑i=1v(i)t,j2√t ≤||g1:T,j||24√1 '\n",
            "               '+ log(T)K∑i=11(1 −β(i))2Proof We begin by expanding the last '\n",
            "               'term in the sum using the update equations,14Published as a '\n",
            "               'conference paper at ICLR 2019T∑t=1K∑i=1v(i)t,j2√t '\n",
            "               '=T−1∑t=1K∑i=1v(i)t,j2√t + 1√TK∑i=1( T∑h=1(β(i)h '\n",
            "               ')T−hgh,j)2≤T−1∑t=1K∑i=1v(i)t,j2√t + 1√TK∑i=1( T∑h=1(β(i))T−h)( '\n",
            "               'T∑h=1(β(i))T−hg2h,j)≤T−1∑t=1K∑i=1v(i)t,j2√t + 1√TK∑i=111 '\n",
            "               '−β(i)( T∑h=1(β(i))T−hg2h,j)The ﬁrst inequality is obtained via '\n",
            "               'Cauchy-Schwarz and by noting that β(i)t ≤βfor all t. The '\n",
            "               'secondinequality follows directly from the fact that '\n",
            "               '∑Th=1(β(i))T−h < 1/(1 −β(i)). We can apply thisupper bound to '\n",
            "               'each term of the sum over t,T∑t=1K∑i=1v(i)t,j2√t '\n",
            "               '≤T∑t=1K∑i=11√t(1 −β(i))t∑h=1(β(i))t−hg2h,j=K∑i=111 '\n",
            "               '−β(i)T∑t=11√tt∑h=1(β(i))t−hg2h,j=K∑i=111 '\n",
            "               '−β(i)T∑t=1g2t,jT∑h=t(β(i))h−t√h≤K∑i=111 '\n",
            "               '−β(i)T∑t=1g2t,jT∑h=t(β(i))h−t√t≤K∑i=11(1 '\n",
            "               '−β(i))2T∑t=1g2t,j1√t≤K∑i=11(1 −β(i))2 '\n",
            "               '||g1:T,j||24\\ued6a\\ued6b\\ued6b√T∑t=11t≤||g1:T,j||24√1 + '\n",
            "               'log(T)K∑i=11(1 −β(i))2Under equality we swap the order of sums '\n",
            "               'and collect terms under gt. The third inequality followsfrom '\n",
            "               '∑tj=1(β(i))j−t <1/(1 −β). The fourth inequality is an '\n",
            "               'application of Cauchy-Schwarz. Theﬁnal inequality is from the '\n",
            "               'harmonic sum bound: ∑Tt=1 1/t≤1 + log(T). This completes the '\n",
            "               'proof.Proof of Theorem 1 From the update equations we may '\n",
            "               'write,θt+1 = θt + γtKK∑i=1v(i)t= θt + γtKK∑i=1(β(i)t v(i)t−1 '\n",
            "               '−gt)We now shift focus to only the jth dimension. We subtract '\n",
            "               'θ∗j from both sides and square,15Published as a conference '\n",
            "               'paper at ICLR 2019(θt+1,j −θ∗j)2 = (θt,j −θ∗j)2 + 2γtK(θt,j '\n",
            "               '−θ∗j)K∑i=1(β(i)t v(i)t−1,j −gt,j) + γ2tK2 (K∑i=1v(i)t,j)2We '\n",
            "               'can rearrange this expression and bound as follows,gt,j(θt,j '\n",
            "               '−θ∗j) = 12γt[(θt,j −θ∗j)2 −(θt+1,j −θ∗j)2]+ (θt,j −θ∗j) '\n",
            "               '1KK∑i=1(β(i)t v(i)t−1,j) + γt2K2 (K∑i=1v(i)t,j)2= 12γt[(θt,j '\n",
            "               '−θ∗j)2 −(θt+1,j −θ∗j)2]+ 1KK∑i=1(θt,j −θ∗j)(β(i)t v(i)t−1,j) + '\n",
            "               'γt2K2 (K∑i=1v(i)t,j)2= 12γt[(θt,j −θ∗j)2 −(θt+1,j −θ∗j)2]+ '\n",
            "               '1KK∑i=1√β(i)t√γt−1(θt,j −θ∗j)√γt−1β(i)t (v(i)t−1,j)+ γt2K2 '\n",
            "               '(K∑i=1v(i)t,j)2≤ 12γt[(θt,j −θ∗j)2 −(θt+1,j −θ∗j)2]+ '\n",
            "               '1KK∑i=1β(i)t2γt−1(θt,j −θ∗j)2+ 1KK∑i=1γt−12 β(i)t (v(i)t−1,j)2 '\n",
            "               '+ γt2K2 (K∑i=1v(i)t,j)2≤ 12γt[(θt,j −θ∗j)2 −(θt+1,j −θ∗j)2]+ '\n",
            "               '1KK∑i=1β(i)t2γt−1(θt,j −θ∗j)2+ 1KK∑i=1γt−12 β(i)t (v(i)t−1,j)2 '\n",
            "               '+ γt2KK∑i=1(v(i)t,j)2The ﬁrst inequality is an application of '\n",
            "               'Young’s inequality. For the second inequality we use '\n",
            "               'thesum-of-squares inequality. We now make use of convexity, '\n",
            "               'and take the sum over dimensions andtime,16Published as a '\n",
            "               'conference paper at ICLR 2019T∑t=1ft(θt) −ft(θ∗) '\n",
            "               '≤T∑t=1d∑j=1gt,j(θt,j −θ∗j)≤T∑t=1d∑j=112γt[(θt,j −θ∗j)2 '\n",
            "               '−(θt+1,j −θ∗j)2]+ 1KK∑i=1β(i)t2γt−1(θt,j −θ∗j)2+ 1KK∑i=1γt−12 '\n",
            "               'β(i)t (v(i)t−1,j)2 + γt2KK∑i=1(v(i)t,j)2≤d∑j=112γ1(θ1,j −θ∗j)2 '\n",
            "               '+ 12d∑j=1T∑t=1(θt,j −θ∗j)2( 1γt− 1γt−1)+ γ√1 + '\n",
            "               'log(T)2Kd∑j=1||g1:T,j||24K∑i=11 +β(i)(1 −β(i))2+ '\n",
            "               '1KK∑i=1d∑j=1T∑t=1β(i)t2γt−1(θt,j −θ∗j)2We now make use of the '\n",
            "               'bounding assumptions, ||θm −θn||2 ≤Dand ||θm −θn||∞≤D∞,R(T) '\n",
            "               '≤D2∞√Tγ + γ√1 + log(T)2Kd∑j=1||g1:T,j||24K∑i=11 +β(i)(1 '\n",
            "               '−β(i))2 + D22γ1KK∑i=1T∑t=1β(i)λt−1√tThe ﬁrst two terms are '\n",
            "               'collapsed using a telescoping sum. Using ∑tλt−1√t ≤1/(1 −λ)2, '\n",
            "               'weachieve the following bound,R(T) ≤D2∞√Tγ + γ√1 + '\n",
            "               'log(T)2Kd∑j=1||g1:T,j||24K∑i=11 +β(i)(1 −β(i))2 + D22Kγ(1 '\n",
            "               '−λ)2K∑i=1β(i)C.1 Open Questions on ConvergenceWhile studying '\n",
            "               'the convergence properties of AggMo we made several '\n",
            "               'interesting observations whichpresented theoretical '\n",
            "               'challenges. We present some of these observations here to shed '\n",
            "               'light on keydifferences between AggMo and existing momentum '\n",
            "               'methods. We hope that these will provokefurther study.Further '\n",
            "               'reduction of B In Appendix B we derived the matrix B in order '\n",
            "               'to get bounds on theconvergence. We can further reduce Bto '\n",
            "               'block diagonal form, where the jth block takes the form,Bj '\n",
            "               '=\\uf8ee\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f0β(1) '\n",
            "               '0 ··· 0 −λj0 β(2) ... ... ...... ... ... 0 −λj0 ··· 0 β(K) '\n",
            "               '−λjγβ(1)Kγβ(2)K ··· γβ(K)K (1 '\n",
            "               '−γλj)\\uf8f9\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fbFrom '\n",
            "               'this relatively simple form we may be able to derive a '\n",
            "               'closed-form solution for the eigenvalueswhich would allow us '\n",
            "               'to reason theoretically about the quadratic convergence '\n",
            "               'properties of AggMo.An easier goal would be ﬁnding suitable '\n",
            "               'conditions under which the eigenvalues are complex and '\n",
            "               'thesystem is under-damped.17Published as a conference paper at '\n",
            "               'ICLR 2019Finite Difference Equation In this section we '\n",
            "               'demonstrate that the dynamics of AggMo can bewritten as a (K+ '\n",
            "               '1)-th order ﬁnite difference equation. While most momentum '\n",
            "               'methods can beviewed as the discretization of second order '\n",
            "               'ODEs (Wilson et al., 2016) it seems that AggMo does notfall '\n",
            "               'into this class of algorithms. As a consequence, it becomes '\n",
            "               'difﬁcult to apply existing convergenceproof techniques to '\n",
            "               'AggMo.For simplicity, we assume a ﬁxed learning rate γfor all '\n",
            "               'time steps. We will ﬁrst tackle the specialcase K = 2. From '\n",
            "               'the AggMo update rule, we '\n",
            "               'have\\uf8ee\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f0v(1)t+1v(2)t+1v(1)tv(2)tv(1)t−1v(2)t−1\\uf8f9\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fb=\\uf8ee\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f00 '\n",
            "               '0 β1 0 0 00 0 0 β2 0 00 0 0 0 β1 00 0 0 0 0 β20 0 γKγK 1 00 0 '\n",
            "               '0 0 γK 1 + '\n",
            "               'γK\\uf8f9\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fb\\uf8ee\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f0v(1)t+1v(2)t+1v(1)tv(2)tv(1)t−1v(2)t−1\\uf8f9\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fb−\\uf8ee\\uf8ef\\uf8ef\\uf8ef\\uf8ef\\uf8f0∇θf(θt)∇θf(θt)∇θf(θt−1)∇θf(θt−1)θt '\n",
            "               '−θt−1θt−1 −θt−2\\uf8f9\\uf8fa\\uf8fa\\uf8fa\\uf8fa\\uf8fb(9)Denoting '\n",
            "               'the matrices as symbols correspondingly, it becomes v = Bv −g, '\n",
            "               'thereforev = −(I −B)−1g (10)Denote δt = θt−θ⋆, then θt−θt−1 = '\n",
            "               'δt−δt−1. Note that θt+1 = θt+ γt+12 (v(1)t+1 +v(2)t+1), '\n",
            "               'pluggingEq 10 into it, we haveδt+1 = δt −γ2 [1,1,0,0,···]⊤(I '\n",
            "               '−B)−1g (11)Which reduces to the following ﬁnite difference '\n",
            "               'equation,δt+1 = (1+β1 +β2)δt+(β1 +β2 +β1β2)δt−1 −β1β2δt−2 + γ2 '\n",
            "               '(2∇θf(θt)−(β1 +β2)∇θf(θt−1))(12)For K ≥2, we only need to '\n",
            "               'change Eq 9 accordingly, follow the remaining derivations, and '\n",
            "               'recover a(K+1)-th order difference equation. We could also '\n",
            "               'derive the same result using sequence elimination,made simpler '\n",
            "               'with some sensible variable substitutions.This result is of '\n",
            "               'considerable importance. Existing momentum methods can '\n",
            "               'generally be rewritten asa second order difference equation '\n",
            "               '(Section 2 in O’Donoghue & Candes (2015)) which then inducea '\n",
            "               'second order ODE (Su et al., 2014; Wibisono & Wilson, 2015). '\n",
            "               'The momentum optimizationprocedure can then be thought of as a '\n",
            "               'discretization of a Hamiltonian ﬂow. On the other hand, '\n",
            "               'AggModoes not obviously lend itself to the analytical tools '\n",
            "               'developed in this setting - it is not obviouswhether the form '\n",
            "               'in AggMo is indeed a discretization of a Hamiltonian ﬂow.D '\n",
            "               'ExperimentsAll of our experiments are conducted using the '\n",
            "               'pytorch library Paszke et al. (2017). In each experimentwe '\n",
            "               'make use of early stopping to determine the run with the best '\n",
            "               'validation performance.D.1 AutoencodersFor the autoencoders we '\n",
            "               'train fully connected networks with encoders using the '\n",
            "               'following architecture:784-1000-500-250-30. The decoder '\n",
            "               'reverses this architecture. We use relu activations throughout '\n",
            "               'thenetwork. We train for a total of 1000 epochs using a '\n",
            "               'multiplicative learning rate decay of 0.1 at 200,400, and 800 '\n",
            "               'epochs. We train using batch sizes of 200.For these '\n",
            "               'experiments the training set consists of 90% of the training '\n",
            "               'data with the remaining 10%being used for validation.For each '\n",
            "               'optimizer we searched over the following range of learning '\n",
            "               'rates: {0.1, 0.05, 0.01, 0.005,0.001, 0.0005, 0.0001, 0.00005, '\n",
            "               '0.00001}.18Published as a conference paper at ICLR 2019D.2 '\n",
            "               'ClassiﬁcationFor each of the classiﬁcation tasks we train for '\n",
            "               'a total of 400 epochs using batchsizes of 128. Wemake use of a '\n",
            "               'multiplicative learning rate decay of 0.1 at 150 and 250 '\n",
            "               'epochs. For each of theseexperiments we use 80% of the '\n",
            "               'training data for training and use the remaining 20% as '\n",
            "               'validation.In these experiments we searched over the following '\n",
            "               'learning rates for all optimizers: {0.1, 0.05,0.01, 0.005, '\n",
            "               '0.001, 0.0005, 0.0001 }. We searched over the same damping '\n",
            "               'coefﬁcients as in theautoencoder experiments. Each model was '\n",
            "               'trained for a total of 500 epochs.When training without batch '\n",
            "               'normalization we explored a smaller range of learning rates '\n",
            "               'for bothCM and AggMo: {0.1, 0.05, 0.01, 0.005 }.CNN-5 The '\n",
            "               'CNN-5 model uses relu activations throughout and 2x2 max '\n",
            "               'pooling with stride 2. Theﬁrst convolutional layer uses an '\n",
            "               '11x11 kernel with a stride of 4. This is followed by a max '\n",
            "               'poolinglayer. There is then a 5x5 convolutional kernel '\n",
            "               'followed by max pooling. The network then usesthree 3x3 '\n",
            "               'convolutional layers and a ﬁnal max pooling layer before '\n",
            "               'feeding into a fully connectedoutput layer. We do not use any '\n",
            "               'regularization when training this model.ResNet-32 We use the '\n",
            "               'ResNet-32 architecture on both CIFAR-10 and CIFAR-100. We make '\n",
            "               'useof a weight decay of 0.0005 and use batch normalization '\n",
            "               '(Ioffe & Szegedy, 2015). We introducedata augmentation by '\n",
            "               'using random crops with a padding of 4 and use random '\n",
            "               'horizontal ﬂips withprobability 0.5.D.3 LSTM Language '\n",
            "               'ModellingWe train LSTMs with 3-layers containing 1150 hidden '\n",
            "               'units per layer, and a 400 embedding size.Within the network '\n",
            "               'we use dropout on the layers with probability 0.4. The hidden '\n",
            "               'layers usedropout with probability 0.3 and the input embedding '\n",
            "               'layers use dropout with probability 0.65while the embedding '\n",
            "               'layer itself uses dropout with probability 0.1. We also apply '\n",
            "               'the weight dropmethod proposed in Merity et al. (2017) with '\n",
            "               'probability 0.5. L2 regularization is applied on theRNN '\n",
            "               'activations with a scaling of 2.0, we also use temporal '\n",
            "               'activation regularization (slownessregularization) with '\n",
            "               'scaling 1.0. Finally, all weights receive a weight decay of '\n",
            "               '1.2e-6.We train the model using variable sequence lengths and '\n",
            "               'batch sizes of 80. We measure the validationloss during '\n",
            "               'training and decrease the learning rate if the validation loss '\n",
            "               'has not decreased for 15epochs. We found that a learning rate '\n",
            "               'decay of 0.5 worked best for all optimizers except for '\n",
            "               'SGDwhich achieved best performance with a ﬁxed learning '\n",
            "               'rate.For SGD, CM, AggMo and Nesterov we searched over learning '\n",
            "               'rates in the range {50, 30, 10, 5,2.5, 1, 0.1, 0.01}. We found '\n",
            "               'that Adam required much smaller learning rates in this setting '\n",
            "               'and sosearched over values in the range {0.1, 0.05, 0.01, '\n",
            "               '0.005, 0.001, 0.0005, 0.0001}. We searched overthe damping '\n",
            "               'coefﬁcients as in the previous experiments. Each model was '\n",
            "               'trained for 750 epochs, asin Merity et al. (2017).E Additional '\n",
            "               'ResultsIn this section we display some of the experimental '\n",
            "               'results which we are unable to ﬁt in the mainpaper.E.1 Toy '\n",
            "               'ProblemTo better understand how AggMo is able to help in '\n",
            "               'non-convex settings we explore its effectivenesson a simple '\n",
            "               'non-convex toy problem. The function we aim to optimize is '\n",
            "               'deﬁned as follows,f(x,y) = log(ex + e−x)+blog(eex(y−sin(ax)) + '\n",
            "               'e−ex(y−sin(ax))) (13)19Published as a conference paper at ICLR '\n",
            "               '2019Figure 11: Comparison of classical momentum and aggregated '\n",
            "               'momentum on toy problem (13) with a= 8,b =10. In each case the '\n",
            "               'optimizer is initialized at (x,y) = (−2,0)Optimizer Train '\n",
            "               'Optimal Validation OptimalTrain Loss Val. Loss Test LossCM β = '\n",
            "               '0.9 2.07 4.95 4.98Nesterov β = 0.9 1.94 4.63 4.62AggMo '\n",
            "               '(Default) 1.60 3.14 3.04Table 4: MNIST Autoencoder with '\n",
            "               'default settings We display the training MSE for the initial '\n",
            "               'learning ratethat achieved the best training loss. The '\n",
            "               'validation and test errors are displayed for the initial '\n",
            "               'learning rate thatachieved the best validation MSE.where aand '\n",
            "               'bare constants which may be varied. We choose this function '\n",
            "               'because it features ﬂatregions and a series of non-convex '\n",
            "               'funnels with varied curvature. The optimizer must traverse '\n",
            "               'theﬂat regions quickly whilst remaining stable within the '\n",
            "               'funnels. This function has an optimal value at(x,y) = '\n",
            "               '(0,0).Figure 11 compares the performance of classical momentum '\n",
            "               'and aggregated momentum whenoptimizing Equation 13 with a = '\n",
            "               '8,b = 10. We see that GD with β = 0and β = 0.9 are unableto '\n",
            "               'leave the ﬂat region around x <−1. For GD with β = 0.999 the '\n",
            "               'optimizer enters the funnelsbut frequently becomes unstable '\n",
            "               'with oscillations and ﬁnally overshoots the optimum. Compared '\n",
            "               'toGD, AggMo is able to quickly traverse both the ﬂat region '\n",
            "               'and the funnels while remaining stable.AggMo also successfully '\n",
            "               'slows down quickly once reaching the optimum.E.2 Comparison at '\n",
            "               'default damping settingsIn this section we present results '\n",
            "               'using the default damping coefﬁcient settings for the '\n",
            "               'autoencoderand LSTM experiments.The default settings for CM, '\n",
            "               'Nesterov, and AggMo are compared in Table 4. The default '\n",
            "               'settingsof AggMo outperform both CM and Nesterov signiﬁcantly. '\n",
            "               'Moreover, while the AggMo defaultsettings perform similarly to '\n",
            "               'the best results in Table 1 there is a large gap for the CM '\n",
            "               'and Nesterovdefaults. This suggests that for this task AggMo '\n",
            "               'is less sensitive to hyperparameter tuning than theother '\n",
            "               'methods.For the LSTM experiments we found that all methods '\n",
            "               'worked best with their default dampingcoefﬁcients except for '\n",
            "               'Nesterov momentum which used β = 0.99. For Nesterov momentum '\n",
            "               'withβ = 0.9 the validation perplexity was 63.67 and the test '\n",
            "               'perplexity was 61.45. AggMo with defaultsettings achieved '\n",
            "               'better training, validation and test perplexity than both the '\n",
            "               'CM and Nesterovdefaults.20Published as a conference paper at '\n",
            "               'ICLR 2019F Beta-Averaged MomentumIn this section we present a '\n",
            "               'continuous analog of AggMo which provides additional insight '\n",
            "               'into itseffectiveness.The AggMo update rule features the '\n",
            "               'average of several velocities with some chosen '\n",
            "               'dampingcoefﬁcients, β. A natural extension to this formulation '\n",
            "               'instead considers a mapping from beta valuesto velocities with '\n",
            "               'the space of velocities being integrated over instead of '\n",
            "               'summed. Explicitly, wewrite this update rule as,vt = bvt−1 '\n",
            "               '−∇θf(θt−1)θt = θt−1 + γ∫ 10vtπ(b)db(14)Where π(b) is a '\n",
            "               'probability density deﬁned on [0,1]. We can link this back to '\n",
            "               'aggregated momentumin the following way. If we sampled b(i) '\n",
            "               'under the density π for i = 1 :M then the proceduredescribed '\n",
            "               'by Equation 3 is approximating Equation 14 via Monte Carlo '\n",
            "               'Integration.Although this seems like a reasonable idea, it is '\n",
            "               'not obvious whether we can compute this integral inclosed '\n",
            "               'form. We can understand this update rule by expanding vt '\n",
            "               'recursively,vt = bvt−1 −∇θf(θt−1) (15)= b(bvt−2 −∇θf(θt−2)) '\n",
            "               '−∇θf(θt−1)= btv0 −t∑i=1bi−1∇θf(θt−i)= −t∑i=1bi−1∇θf(θt−i) '\n",
            "               '=−t−1∑i=0bt−i−1∇θf(θi)Thus we can write the update rule for xt '\n",
            "               'as,θt = θt−1 −γt∑i=1∇θf(θt−i)∫ 10bi−1π(b)db (16)Thus to '\n",
            "               'compute the update rule we must compute the raw moments of b. '\n",
            "               'Fortunately, for the specialcase where πis the density '\n",
            "               'function of a Beta distribution then we have closed form '\n",
            "               'solutions forthe raw moments of b∼Beta(α,β) (note that βhere '\n",
            "               'is not referring to a damping coefﬁcient) thenthese raw '\n",
            "               'moments have a closed form:E[bk] =k−1∏r=0α+ rα+ β+ r (17)This '\n",
            "               'provides a closed form solution to computeθtgiven θt−1 and the '\n",
            "               'history of all previous gradients.We refer to this update '\n",
            "               'scheme as Beta-Averaged Momentum. Unfortunately, each update '\n",
            "               'requires thehistory of all previous gradients to be computed. '\n",
            "               'We may ﬁnd some reasonable approximation to theupdate rule. '\n",
            "               'For example, we could keep only the T most recently computed '\n",
            "               'gradients.Figure 12 shows the optimization of 1D quadratics '\n",
            "               'using Beta-Averaged Momentum. The trajectoriesare similar to '\n",
            "               'those achieved using the original AggMo '\n",
            "               'formulation.21Published as a conference paper at ICLR '\n",
            "               '2019Figure 12: Beta-Averaged GD with a Beta prior on momentum '\n",
            "               '(α= 100,β = 1).22',\n",
            " 'script_save_path': '/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/new_method.py'}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (new_method.py, line 60)",
          "traceback": [
            "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3553\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \u001b[1;32m\"<ipython-input-17-90e5988f6b34>\"\u001b[0m, line \u001b[1;32m1\u001b[0m, in \u001b[1;35m<cell line: 1>\u001b[0m\n    result = research_graph(\n",
            "  File \u001b[1;32m\"<ipython-input-10-be0d193b19ec>\"\u001b[0m, line \u001b[1;32m171\u001b[0m, in \u001b[1;35m__call__\u001b[0m\n    result = self.graph.invoke(state, debug = True)\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.10/dist-packages/langgraph/pregel/__init__.py\"\u001b[0m, line \u001b[1;32m1929\u001b[0m, in \u001b[1;35minvoke\u001b[0m\n    for chunk in self.stream(\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.10/dist-packages/langgraph/pregel/__init__.py\"\u001b[0m, line \u001b[1;32m1649\u001b[0m, in \u001b[1;35mstream\u001b[0m\n    for _ in runner.tick(\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.10/dist-packages/langgraph/pregel/runner.py\"\u001b[0m, line \u001b[1;32m105\u001b[0m, in \u001b[1;35mtick\u001b[0m\n    run_with_retry(t, retry_policy, writer=writer)\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.10/dist-packages/langgraph/pregel/retry.py\"\u001b[0m, line \u001b[1;32m44\u001b[0m, in \u001b[1;35mrun_with_retry\u001b[0m\n    task.proc.invoke(task.input, config)\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.10/dist-packages/langgraph/utils/runnable.py\"\u001b[0m, line \u001b[1;32m410\u001b[0m, in \u001b[1;35minvoke\u001b[0m\n    input = context.run(step.invoke, input, config, **kwargs)\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.10/dist-packages/langgraph/utils/runnable.py\"\u001b[0m, line \u001b[1;32m184\u001b[0m, in \u001b[1;35minvoke\u001b[0m\n    ret = context.run(self.func, input, **kwargs)\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.10/dist-packages/researchgraph/core/node.py\"\u001b[0m, line \u001b[1;32m33\u001b[0m, in \u001b[1;35m__call__\u001b[0m\n    result = self.execute(state)\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.10/dist-packages/researchgraph/nodes/experimentnode/llm/llm_sfttrain_node.py\"\u001b[0m, line \u001b[1;32m117\u001b[0m, in \u001b[1;35mexecute\u001b[0m\n    new_optimizer = self._set_up_optimizer(script_path)\n",
            "  File \u001b[1;32m\"/usr/local/lib/python3.10/dist-packages/researchgraph/nodes/experimentnode/llm/llm_sfttrain_node.py\"\u001b[0m, line \u001b[1;32m110\u001b[0m, in \u001b[1;35m_set_up_optimizer\u001b[0m\n    spec.loader.exec_module(module)\n",
            "  File \u001b[1;32m\"<frozen importlib._bootstrap_external>\"\u001b[0m, line \u001b[1;32m879\u001b[0m, in \u001b[1;35mexec_module\u001b[0m\n",
            "  File \u001b[1;32m\"<frozen importlib._bootstrap_external>\"\u001b[0m, line \u001b[1;32m1017\u001b[0m, in \u001b[1;35mget_code\u001b[0m\n",
            "  File \u001b[1;32m\"<frozen importlib._bootstrap_external>\"\u001b[0m, line \u001b[1;32m947\u001b[0m, in \u001b[1;35msource_to_code\u001b[0m\n",
            "\u001b[0;36m  File \u001b[0;32m\"<frozen importlib._bootstrap>\"\u001b[0;36m, line \u001b[0;32m241\u001b[0;36m, in \u001b[0;35m_call_with_frames_removed\u001b[0;36m\u001b[0m\n",
            "\u001b[0;36m  File \u001b[0;32m\"/content/drive/MyDrive/AutoRes/ai_integrator/exec-test/new_method.py\"\u001b[0;36m, line \u001b[0;32m60\u001b[0m\n\u001b[0;31m    ```\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}